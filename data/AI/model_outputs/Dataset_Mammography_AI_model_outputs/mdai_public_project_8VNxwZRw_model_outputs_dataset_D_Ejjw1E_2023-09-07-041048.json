{"id":"8VNxwZRw","createdAt":"2022-02-25T22:24:48.337Z","updatedAt":"2023-08-19T01:21:40.607Z","name":"Emory Test CXR Project","description":"cloned from Education CXR for testing","isPrivate":true,"labelGroups":[{"id":"G_5JEYgd","createdAt":"2023-01-14T06:51:49.526Z","updatedAt":"2023-01-14T06:51:49.533Z","name":"ChexnetLabels","description":null,"type":"STANDARD","labels":[{"id":"L_B7j0z8","parentId":null,"createdAt":"2023-01-14T06:51:49.728Z","updatedAt":"2023-01-14T06:51:49.736Z","name":"Atelectasis","shortName":"","description":"","color":"#7b1fa2","type":"GLOBAL","scope":"INSTANCE","annotationMode":null,"radlexTagIds":[]},{"id":"L_Br91a8","parentId":null,"createdAt":"2023-01-14T06:52:09.653Z","updatedAt":"2023-01-14T06:52:09.663Z","name":"Cardiomegaly","shortName":"","description":"","color":"#fff176","type":"GLOBAL","scope":"INSTANCE","annotationMode":null,"radlexTagIds":[]},{"id":"L_By7mad","parentId":null,"createdAt":"2023-01-14T06:52:23.230Z","updatedAt":"2023-01-14T06:52:23.238Z","name":"Effusion","shortName":"","description":"","color":"#009688","type":"GLOBAL","scope":"INSTANCE","annotationMode":null,"radlexTagIds":[]},{"id":"L_djoG28","parentId":null,"createdAt":"2023-01-14T06:52:34.294Z","updatedAt":"2023-01-14T06:52:34.300Z","name":"Infiltration","shortName":"","description":"","color":"#c2185b","type":"GLOBAL","scope":"INSTANCE","annotationMode":null,"radlexTagIds":[]},{"id":"L_dMrNo8","parentId":null,"createdAt":"2023-01-14T06:52:44.447Z","updatedAt":"2023-01-14T06:52:44.455Z","name":"Mass","shortName":"","description":"","color":"#d1c4e9","type":"GLOBAL","scope":"INSTANCE","annotationMode":null,"radlexTagIds":[]},{"id":"L_89vOnB","parentId":null,"createdAt":"2023-01-14T06:52:56.439Z","updatedAt":"2023-01-14T06:52:56.448Z","name":"Nodule","shortName":"","description":"","color":"#ffe0b2","type":"GLOBAL","scope":"INSTANCE","annotationMode":null,"radlexTagIds":[]},{"id":"L_lzrvwl","parentId":null,"createdAt":"2023-01-14T06:53:06.944Z","updatedAt":"2023-01-14T06:53:06.951Z","name":"Pneumonia","shortName":"","description":"","color":"#4db6ac","type":"GLOBAL","scope":"INSTANCE","annotationMode":null,"radlexTagIds":[]},{"id":"L_l15oLl","parentId":null,"createdAt":"2023-01-14T06:53:16.971Z","updatedAt":"2023-01-14T06:53:16.979Z","name":"Pneumothorax","shortName":"","description":"","color":"#194D33","type":"GLOBAL","scope":"INSTANCE","annotationMode":null,"radlexTagIds":[]}]},{"id":"G_2AobMd","createdAt":"2023-01-28T16:16:00.777Z","updatedAt":"2023-08-01T21:02:18.717Z","name":"Chexnet Label Group","description":null,"type":"STANDARD","labels":[{"id":"L_lAwEv8","parentId":null,"createdAt":"2023-01-28T16:16:01.341Z","updatedAt":"2023-01-28T16:16:01.348Z","name":"Atelectasis","shortName":"","description":"","color":"#bbdefb","type":"LOCAL","scope":"INSTANCE","annotationMode":"bbox","radlexTagIds":[]},{"id":"L_BOoE3B","parentId":null,"createdAt":"2023-01-28T16:16:15.585Z","updatedAt":"2023-01-28T16:16:15.594Z","name":"Cardiomegaly","shortName":"","description":"","color":"#f57c00","type":"LOCAL","scope":"INSTANCE","annotationMode":"bbox","radlexTagIds":[]},{"id":"L_dpyrP8","parentId":null,"createdAt":"2023-01-28T16:16:29.872Z","updatedAt":"2023-01-28T16:16:29.876Z","name":"Effusion","shortName":"","description":"","color":"#7986cb","type":"LOCAL","scope":"INSTANCE","annotationMode":"bbox","radlexTagIds":[]},{"id":"L_lV7a0d","parentId":null,"createdAt":"2023-01-28T16:16:39.258Z","updatedAt":"2023-01-28T16:16:39.266Z","name":"Infiltration","shortName":"","description":"","color":"#455a64","type":"LOCAL","scope":"INSTANCE","annotationMode":"bbox","radlexTagIds":[]},{"id":"L_83Kpk8","parentId":null,"createdAt":"2023-01-28T16:16:48.118Z","updatedAt":"2023-01-28T16:16:48.128Z","name":"Mass","shortName":"","description":"","color":"#5d4037","type":"LOCAL","scope":"INSTANCE","annotationMode":"bbox","radlexTagIds":[]},{"id":"L_BknvN8","parentId":null,"createdAt":"2023-01-28T16:16:57.834Z","updatedAt":"2023-01-28T16:16:57.876Z","name":"Nodule","shortName":"","description":"","color":"#673ab7","type":"LOCAL","scope":"INSTANCE","annotationMode":"bbox","radlexTagIds":[]},{"id":"L_dDwKDl","parentId":null,"createdAt":"2023-01-28T16:17:07.580Z","updatedAt":"2023-01-28T16:17:07.587Z","name":"Pneumonia","shortName":"","description":"","color":"#388e3c","type":"LOCAL","scope":"INSTANCE","annotationMode":"bbox","radlexTagIds":[]},{"id":"L_lb6zql","parentId":null,"createdAt":"2023-01-28T16:17:14.716Z","updatedAt":"2023-01-28T16:17:14.723Z","name":"Pneumothorax","shortName":"","description":"","color":"#fff9c4","type":"LOCAL","scope":"INSTANCE","annotationMode":"bbox","radlexTagIds":[]},{"id":"L_8KDjDB","parentId":null,"createdAt":"2023-02-09T07:59:00.458Z","updatedAt":"2023-06-03T21:22:34.677Z","name":"Consolidation","shortName":"","description":"","color":"#c5cae9","type":"LOCAL","scope":"INSTANCE","annotationMode":"bbox","radlexTagIds":[]},{"id":"L_Bor0y8","parentId":null,"createdAt":"2023-02-09T07:59:11.914Z","updatedAt":"2023-06-03T21:26:28.461Z","name":"Edema","shortName":"","description":"","color":"#a1887f","type":"LOCAL","scope":"INSTANCE","annotationMode":"bbox","radlexTagIds":[]},{"id":"L_8Ykepl","parentId":null,"createdAt":"2023-02-09T07:59:19.280Z","updatedAt":"2023-06-03T21:22:56.851Z","name":"Emphysema","shortName":"","description":"","color":"#f0f4c3","type":"LOCAL","scope":"INSTANCE","annotationMode":"bbox","radlexTagIds":[]},{"id":"L_8xwgEd","parentId":null,"createdAt":"2023-02-09T07:59:26.490Z","updatedAt":"2023-06-03T21:23:05.927Z","name":"Fibrosis","shortName":"","description":"","color":"#c8e6c9","type":"LOCAL","scope":"INSTANCE","annotationMode":"bbox","radlexTagIds":[]},{"id":"L_d2Kkn8","parentId":null,"createdAt":"2023-02-09T07:59:34.159Z","updatedAt":"2023-06-03T21:27:29.880Z","name":"Pleural_Thickening","shortName":"","description":"","color":"#cfd8dc","type":"LOCAL","scope":"INSTANCE","annotationMode":"bbox","radlexTagIds":[]},{"id":"L_BgPwZl","parentId":null,"createdAt":"2023-02-09T07:59:41.422Z","updatedAt":"2023-06-03T21:23:31.269Z","name":"Hernia","shortName":"","description":"","color":"#00796b","type":"LOCAL","scope":"INSTANCE","annotationMode":"bbox","radlexTagIds":[]},{"id":"L_d2PVkB","parentId":null,"createdAt":"2023-06-05T08:47:48.070Z","updatedAt":"2023-06-05T08:47:48.081Z","name":"No Finding","shortName":"","description":"","color":"#b3e5fc","type":"GLOBAL","scope":"INSTANCE","annotationMode":null,"radlexTagIds":[]}]},{"id":"G_dQ0NbK","createdAt":"2023-05-24T16:33:23.080Z","updatedAt":"2023-06-09T19:23:16.988Z","name":"MURA Label Group AI","description":null,"type":"STANDARD","labels":[{"id":"L_dDLgQd","parentId":null,"createdAt":"2023-05-24T16:33:23.412Z","updatedAt":"2023-05-24T16:33:23.420Z","name":"Normal","shortName":"","description":"","color":"#c8e6c9","type":"GLOBAL","scope":"INSTANCE","annotationMode":null,"radlexTagIds":[]},{"id":"L_lbae3B","parentId":null,"createdAt":"2023-05-24T16:33:40.043Z","updatedAt":"2023-05-24T16:33:40.051Z","name":"Abnormal","shortName":"","description":"","color":"#455a64","type":"GLOBAL","scope":"INSTANCE","annotationMode":null,"radlexTagIds":[]}]},{"id":"G_d01NO5","createdAt":"2023-05-30T23:01:58.641Z","updatedAt":"2023-06-09T19:22:36.566Z","name":"Mammo Label Group AI","description":null,"type":"STANDARD","labels":[{"id":"L_lPkGEB","parentId":null,"createdAt":"2023-05-30T23:01:58.848Z","updatedAt":"2023-05-30T23:01:58.856Z","name":"Normal","shortName":"","description":"Benign calcification or no calcification present","color":"#8bc34a","type":"GLOBAL","scope":"INSTANCE","annotationMode":null,"radlexTagIds":[]},{"id":"L_Bn0pWd","parentId":null,"createdAt":"2023-05-30T23:02:25.390Z","updatedAt":"2023-05-30T23:02:25.397Z","name":"Malignant","shortName":"","description":"Malignant Calcification","color":"#0d47a1","type":"GLOBAL","scope":"INSTANCE","annotationMode":null,"radlexTagIds":[]}]},{"id":"G_5k9D1K","createdAt":"2023-06-09T19:30:01.865Z","updatedAt":"2023-08-01T21:03:54.403Z","name":"Mammo Label Group","description":null,"type":"STANDARD","labels":[{"id":"L_Bme34B","parentId":null,"createdAt":"2023-06-09T19:30:02.281Z","updatedAt":"2023-06-09T19:30:02.290Z","name":"Normal","shortName":"","description":"","color":"#ff6f00","type":"GLOBAL","scope":"INSTANCE","annotationMode":null,"radlexTagIds":[]},{"id":"L_dvM5Al","parentId":null,"createdAt":"2023-06-09T19:30:26.141Z","updatedAt":"2023-06-09T19:30:26.149Z","name":"Benign","shortName":"","description":"","color":"#1a237e","type":"GLOBAL","scope":"INSTANCE","annotationMode":null,"radlexTagIds":[]},{"id":"L_8JoaEB","parentId":null,"createdAt":"2023-06-09T19:30:46.322Z","updatedAt":"2023-06-09T19:30:46.330Z","name":"Probably Benign","shortName":"","description":"","color":"#c2185b","type":"GLOBAL","scope":"INSTANCE","annotationMode":null,"radlexTagIds":[]},{"id":"L_8eZ2pB","parentId":null,"createdAt":"2023-06-09T19:31:58.624Z","updatedAt":"2023-06-09T19:31:58.736Z","name":"Probably Malignant","shortName":"","description":"","color":"#01579b","type":"GLOBAL","scope":"INSTANCE","annotationMode":null,"radlexTagIds":[]},{"id":"L_84ZJ5l","parentId":null,"createdAt":"2023-06-09T19:32:13.546Z","updatedAt":"2023-06-09T19:32:13.629Z","name":"Malignant","shortName":"","description":"","color":"#f57f17","type":"GLOBAL","scope":"INSTANCE","annotationMode":null,"radlexTagIds":[]}]},{"id":"G_5LbkeK","createdAt":"2023-06-28T21:47:15.025Z","updatedAt":"2023-06-28T21:47:15.036Z","name":"Pneumothorax Local Group","description":null,"type":"STANDARD","labels":[{"id":"L_8Wjjvd","parentId":null,"createdAt":"2023-06-28T21:47:15.326Z","updatedAt":"2023-06-28T21:47:15.341Z","name":"Pneumothorax","shortName":"","description":"","color":"#c5cae9","type":"LOCAL","scope":"INSTANCE","annotationMode":"mask","radlexTagIds":[]},{"id":"L_lPppNl","parentId":null,"createdAt":"2023-06-28T21:47:39.977Z","updatedAt":"2023-07-03T22:38:38.540Z","name":"No Pneumothorax","shortName":"","description":"","color":"#00bcd4","type":"GLOBAL","scope":"INSTANCE","annotationMode":null,"radlexTagIds":[]}]}],"models":[{"id":"M_8dMv8e","createdAt":"2023-01-24T03:34:33.233Z","createdById":"U_8nPJeQ","updatedAt":"2023-01-24T04:00:04.239Z","name":"Chexnet Model Test","description":"","scope":"INSTANCE","labelClasses":[{"classIndex":0,"labelId":"L_B7j0z8"},{"classIndex":7,"labelId":"L_l15oLl"},{"classIndex":1,"labelId":"L_Br91a8"},{"classIndex":2,"labelId":"L_By7mad"},{"classIndex":3,"labelId":"L_djoG28"},{"classIndex":4,"labelId":"L_dMrNo8"},{"classIndex":5,"labelId":"L_89vOnB"},{"classIndex":6,"labelId":"L_lzrvwl"}],"versions":[{"id":526,"isDefault":true,"versionNumber":1,"createdAt":"2023-01-24T03:36:01.452Z","dockerImageName":"us-docker.pkg.dev/mdai-artifact-registry/models/public/model-354","dockerImageTag":"v1","config":{"cpuLimit":"1","fileType":"dicom","gpuCount":1,"batchSize":1,"cpuRequest":"0.1","dataSource":"MEMORY","memoryLimit":"10G","memoryRequest":"1G","acceleratorType":"gpu_nvidia-tesla-t4"},"args":[]}],"tasks":[]},{"id":"M_pjxPNj","createdAt":"2023-05-24T16:33:54.998Z","createdById":"U_8bo0zO","updatedAt":"2023-06-02T03:49:21.502Z","name":"MURA","description":"","scope":"INSTANCE","labelClasses":[{"classIndex":0,"labelId":"L_dDLgQd"},{"classIndex":1,"labelId":"L_lbae3B"}],"versions":[{"id":700,"isDefault":true,"versionNumber":21,"createdAt":"2023-05-31T15:57:46.028Z","dockerImageName":"us-docker.pkg.dev/mdai-artifact-registry/models/public/model-429","dockerImageTag":"v21","config":{"isLLM":false,"cpuLimit":"1","fileType":"dicom","gpuCount":1,"batchSize":1,"cpuRequest":"0.1","dataSource":"MEMORY","memoryLimit":"10G","memoryRequest":"1G","acceleratorType":"gpu_nvidia-tesla-t4"},"args":[]}],"tasks":[{"id":1578,"modelVersionId":700,"type":"INFERENCE","config":{"resourceIds":[2318],"resourceType":"DATASET","dicomDatasetId":2318},"args":[],"createdAt":"2023-07-11T02:39:26.187Z","status":"SUCCEEDED","startTime":"2023-07-11T02:39:26.318Z","endTime":"2023-07-11T03:53:47.657Z","progress":100,"summary":{"errorCount":0,"successCount":780}}]},{"id":"M_DevgOj","createdAt":"2023-05-30T23:03:32.895Z","createdById":"U_8bo0zO","updatedAt":"2023-06-02T03:49:06.976Z","name":"Mammography Calcification Model","description":"Identifies Malignant from Benign/Normal ","scope":"INSTANCE","labelClasses":[{"classIndex":0,"labelId":"L_lPkGEB"},{"classIndex":1,"labelId":"L_Bn0pWd"}],"versions":[{"id":699,"isDefault":true,"versionNumber":3,"createdAt":"2023-05-31T01:01:20.778Z","dockerImageName":"us-docker.pkg.dev/mdai-artifact-registry/models/public/model-430","dockerImageTag":"v3","config":{"isLLM":false,"cpuLimit":"1","fileType":"dicom","gpuCount":1,"batchSize":1,"cpuRequest":"0.1","dataSource":"MEMORY","memoryLimit":"10G","memoryRequest":"1G","acceleratorType":"gpu_nvidia-tesla-t4"},"args":[]}],"tasks":[]},{"id":"M_geDa3j","createdAt":"2023-06-05T08:44:09.450Z","createdById":"U_8bo0zO","updatedAt":"2023-07-11T02:37:37.021Z","name":"Chexnet","description":"","scope":"INSTANCE","labelClasses":[{"classIndex":0,"labelId":"L_lAwEv8"},{"classIndex":1,"labelId":"L_BOoE3B"},{"classIndex":7,"labelId":"L_BgPwZl"},{"classIndex":2,"labelId":"L_8KDjDB"},{"classIndex":5,"labelId":"L_8Ykepl"},{"classIndex":3,"labelId":"L_Bor0y8"},{"classIndex":9,"labelId":"L_83Kpk8"},{"classIndex":13,"labelId":"L_dDwKDl"},{"classIndex":4,"labelId":"L_dpyrP8"},{"classIndex":6,"labelId":"L_8xwgEd"},{"classIndex":8,"labelId":"L_lV7a0d"},{"classIndex":12,"labelId":"L_d2Kkn8"},{"classIndex":10,"labelId":"L_d2PVkB"},{"classIndex":11,"labelId":"L_BknvN8"},{"classIndex":14,"labelId":"L_lb6zql"}],"versions":[{"id":830,"isDefault":true,"versionNumber":14,"createdAt":"2023-07-08T00:54:53.320Z","dockerImageName":"us-docker.pkg.dev/mdai-artifact-registry/models/public/model-436","dockerImageTag":"v14","config":{"isLLM":false,"cpuLimit":"1","fileType":"dicom","gpuCount":1,"batchSize":1,"cpuRequest":"0.1","dataSource":"MEMORY","memoryLimit":"10G","memoryRequest":"1G","acceleratorType":"gpu_nvidia-tesla-t4"},"args":[]}],"tasks":[{"id":1577,"modelVersionId":830,"type":"INFERENCE","config":{"resourceIds":[2320],"resourceType":"DATASET","dicomDatasetId":2320},"args":[],"createdAt":"2023-07-11T02:38:52.637Z","status":"SUCCEEDED","startTime":"2023-07-11T02:38:53.181Z","endTime":"2023-07-11T03:53:16.496Z","progress":100,"summary":{"errorCount":2,"successCount":388,"errorMessages":[{"error":"Error running model: Traceback (most recent call last):\n  File \"server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 215, in predict\n    if outputs[0]['class_index'] == 10:\nIndexError: list index out of range\n","resourceId":24132431},{"error":"Error running model: Traceback (most recent call last):\n  File \"server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 215, in predict\n    if outputs[0]['class_index'] == 10:\nIndexError: list index out of range\n","resourceId":24145659}]}}]},{"id":"M_lKwANe","createdAt":"2023-06-28T21:48:01.825Z","createdById":"U_8bo0zO","updatedAt":"2023-07-03T18:25:39.524Z","name":"Pneumothorax","description":"Segmentation of pneumothorax","scope":"INSTANCE","labelClasses":[{"classIndex":1,"labelId":"L_8Wjjvd"},{"classIndex":0,"labelId":"L_lPppNl"}],"versions":[{"id":814,"isDefault":true,"versionNumber":26,"createdAt":"2023-06-29T22:06:08.253Z","dockerImageName":"us-docker.pkg.dev/mdai-artifact-registry/models/public/model-483","dockerImageTag":"v26","config":{"isLLM":false,"cpuLimit":"1","fileType":"dicom","gpuCount":1,"batchSize":1,"cpuRequest":"0.1","dataSource":"MEMORY","memoryLimit":"10G","memoryRequest":"1G","acceleratorType":"gpu_nvidia-tesla-t4"},"args":[]}],"tasks":[{"id":1576,"modelVersionId":814,"type":"INFERENCE","config":{"resourceIds":[2436],"resourceType":"DATASET","dicomDatasetId":2436},"args":[],"createdAt":"2023-07-11T02:38:37.841Z","status":"SUCCEEDED","startTime":"2023-07-11T02:38:37.902Z","endTime":"2023-07-11T03:52:50.275Z","progress":100,"summary":{"errorCount":0,"successCount":390}},{"id":1609,"modelVersionId":814,"type":"INFERENCE","config":{"resourceIds":[2436],"resourceType":"DATASET","dicomDatasetId":2436},"args":[],"createdAt":"2023-08-21T03:57:31.567Z","status":"SUCCEEDED","startTime":"2023-08-21T03:57:31.777Z","endTime":"2023-08-21T04:33:52.033Z","progress":100,"summary":{"errorCount":0,"successCount":480}}]},{"id":"M_3jAxze","createdAt":"2023-07-08T20:04:29.131Z","createdById":"U_8bo0zO","updatedAt":"2023-09-05T15:58:40.464Z","name":"Mammography Calcification Model BIRADS","description":"Mammography Calcification Model New Labels","scope":"INSTANCE","labelClasses":[{"classIndex":0,"labelId":"L_Bme34B"},{"classIndex":1,"labelId":"L_dvM5Al"},{"classIndex":2,"labelId":"L_8JoaEB"},{"classIndex":3,"labelId":"L_8eZ2pB"},{"classIndex":4,"labelId":"L_84ZJ5l"}],"versions":[{"id":831,"isDefault":false,"versionNumber":1,"createdAt":"2023-07-08T20:06:27.804Z","dockerImageName":"us-docker.pkg.dev/mdai-artifact-registry/models/public/model-496","dockerImageTag":"v1","config":{"isLLM":false,"cpuLimit":"1","fileType":"dicom","gpuCount":1,"batchSize":1,"cpuRequest":"0.1","dataSource":"MEMORY","memoryLimit":"10G","memoryRequest":"1G","acceleratorType":"gpu_nvidia-tesla-t4"},"args":[]},{"id":887,"isDefault":false,"versionNumber":12,"createdAt":"2023-09-05T05:13:59.602Z","dockerImageName":"us-docker.pkg.dev/mdai-artifact-registry/models/public/model-496","dockerImageTag":"v12","config":{"isLLM":false,"cpuLimit":"1","fileType":"dicom","gpuCount":1,"batchSize":1,"cpuRequest":"0.1","dataSource":"MEMORY","memoryLimit":"10G","memoryRequest":"1G","acceleratorType":"gpu_nvidia-tesla-t4"},"args":[]},{"id":888,"isDefault":false,"versionNumber":13,"createdAt":"2023-09-05T06:04:37.909Z","dockerImageName":"us-docker.pkg.dev/mdai-artifact-registry/models/public/model-496","dockerImageTag":"v13","config":{"isLLM":false,"cpuLimit":"1","fileType":"dicom","gpuCount":1,"batchSize":1,"cpuRequest":"0.1","dataSource":"MEMORY","memoryLimit":"10G","memoryRequest":"1G","acceleratorType":"gpu_nvidia-tesla-t4"},"args":[]},{"id":889,"isDefault":true,"versionNumber":14,"createdAt":"2023-09-05T15:02:19.012Z","dockerImageName":"us-docker.pkg.dev/mdai-artifact-registry/models/public/model-496","dockerImageTag":"v14","config":{"isLLM":false,"cpuLimit":"1","fileType":"dicom","gpuCount":1,"batchSize":1,"cpuRequest":"0.1","dataSource":"MEMORY","memoryLimit":"10G","memoryRequest":"1G","acceleratorType":"gpu_nvidia-tesla-t4"},"args":[]}],"tasks":[{"id":1575,"modelVersionId":831,"type":"INFERENCE","config":{"resourceIds":[2322],"resourceType":"DATASET","dicomDatasetId":2322},"args":[],"createdAt":"2023-07-11T02:38:27.580Z","status":"SUCCEEDED","startTime":"2023-07-11T02:38:27.979Z","endTime":"2023-07-11T02:47:11.656Z","progress":100,"summary":{"errorCount":0,"successCount":390}},{"id":1610,"modelVersionId":831,"type":"INFERENCE","config":{"resourceIds":[2322],"resourceType":"DATASET","dicomDatasetId":2322},"args":[],"createdAt":"2023-08-21T03:58:11.784Z","status":"SUCCEEDED","startTime":"2023-08-21T04:03:09.266Z","endTime":"2023-08-21T04:33:40.860Z","progress":100,"summary":{"errorCount":0,"successCount":480}},{"id":1654,"modelVersionId":887,"type":"INFERENCE","config":{"resourceIds":[24132396],"resourceType":"INSTANCE","dicomDatasetId":2322},"args":[],"createdAt":"2023-09-05T05:39:06.735Z","status":"SUCCEEDED","startTime":"2023-09-05T05:39:06.860Z","endTime":"2023-09-05T05:41:09.952Z","progress":100,"summary":{"errorCount":0,"successCount":1}},{"id":1655,"modelVersionId":887,"type":"INFERENCE","config":{"resourceIds":[2322],"resourceType":"DATASET","dicomDatasetId":2322},"args":[],"createdAt":"2023-09-05T05:42:35.020Z","status":"SUCCEEDED","startTime":"2023-09-05T05:42:35.101Z","endTime":"2023-09-05T05:51:49.951Z","progress":100,"summary":{"errorCount":414,"successCount":66,"errorMessages":[{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101304},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183294},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101595},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182397},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 162, in forward\n    x = x.mul(self.gamma.reshape(1, -1, 1, 1))\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.53 GiB already allocated; 33.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181183},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181785},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183306},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101298},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183299},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181511},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 162, in forward\n    x = x.mul(self.gamma.reshape(1, -1, 1, 1))\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 17.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145717},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182707},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183589},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 158, in forward\n    x = self.norm(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/norm.py\", line 57, in forward\n    x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/functional.py\", line 2503, in layer_norm\n    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145708},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182107},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182406},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181788},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183295},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181489},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182694},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182989},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 35.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145416},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182683},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182094},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183310},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181487},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183009},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101606},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101584},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181793},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100804},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 158, in forward\n    x = self.norm(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/norm.py\", line 57, in forward\n    x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/functional.py\", line 2503, in layer_norm\n    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145424},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182706},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101603},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181510},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 31.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145702},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 21.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145714},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181210},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101292},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183286},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101287},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183601},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 46, in forward\n    x = self.fc2(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.51 GiB already allocated; 31.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181189},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101586},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181501},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 21.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145404},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100825},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182392},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181488},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181808},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181498},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 15.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145712},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181207},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183003},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100805},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182112},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183599},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182685},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.37 GiB already allocated; 29.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145726},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183298},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 27.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145719},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183002},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183290},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181195},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183005},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 35.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145409},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 13.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145414},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101306},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182391},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101294},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 1.31 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145704},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100801},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181205},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101282},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100806},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 43.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145709},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182382},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182411},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182687},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183602},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182696},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183011},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183289},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183311},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101281},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 3.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145422},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181203},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101299},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181504},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182101},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182104},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182988},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182110},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.46 GiB already allocated; 109.31 MiB free; 13.56 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145725},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183611},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183007},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183605},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100798},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182684},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101290},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182702},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182102},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181794},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182984},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101587},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100824},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181502},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181790},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.47 GiB already allocated; 95.31 MiB free; 13.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145727},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182690},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182099},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101600},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181208},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183287},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.43 GiB already allocated; 123.31 MiB free; 13.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181192},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 46, in forward\n    x = self.fc2(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 1.31 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145700},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182097},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 158, in forward\n    x = self.norm(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/norm.py\", line 57, in forward\n    x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/functional.py\", line 2503, in layer_norm\n    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 5.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145701},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183292},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 162, in forward\n    x = x.mul(self.gamma.reshape(1, -1, 1, 1))\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.61 GiB already allocated; 3.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145406},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100819},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182401},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183595},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183603},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182983},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101604},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182410},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182682},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101279},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181798},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181201},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101589},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183291},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101285},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100823},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181791},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182396},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182993},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.57 GiB already allocated; 27.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145426},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182403},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183304},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183285},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182095},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 46, in forward\n    x = self.fc2(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 19.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145724},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101278},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100813},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181491},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183000},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.39 GiB already allocated; 173.31 MiB free; 13.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181184},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101588},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182405},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101300},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181795},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181496},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182108},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182693},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182387},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182409},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.40 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181186},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183309},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183594},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181490},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181486},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181206},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101293},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101295},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101592},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101301},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100816},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182986},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182084},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183303},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182992},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 46, in forward\n    x = self.fc2(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 1.31 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145707},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100800},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 19.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145412},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183006},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100821},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181484},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 46, in forward\n    x = self.fc2(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 23.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145720},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.30 GiB already allocated; 91.31 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181185},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 158, in forward\n    x = self.norm(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/norm.py\", line 57, in forward\n    x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/functional.py\", line 2503, in layer_norm\n    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.48 GiB already allocated; 43.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181193},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183308},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 7.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145706},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101288},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 27.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145723},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183293},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181482},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101607},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182109},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183302},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183597},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183608},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101302},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.60 GiB already allocated; 5.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145407},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 43.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145415},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 1.31 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145417},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.57 GiB already allocated; 31.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145419},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181199},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100818},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182085},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181493},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181495},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181198},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181797},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182697},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101602},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101605},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100802},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182692},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181509},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181807},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183001},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181782},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182103},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183010},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183610},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181499},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181507},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101305},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182394},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181211},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 23.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145703},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101583},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182998},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182991},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101599},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181786},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182393},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181809},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.57 GiB already allocated; 27.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145418},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182089},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100817},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183584},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181197},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182987},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100809},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182709},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183587},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181805},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101578},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182087},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182686},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101590},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182086},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183300},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181801},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182091},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182994},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101280},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181485},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182407},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100822},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183582},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183586},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183307},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181792},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101286},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183609},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181500},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182389},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100807},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181796},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101596},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 13.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145421},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182395},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182088},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182082},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182404},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.42 GiB already allocated; 117.31 MiB free; 13.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181190},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182695},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 158, in forward\n    x = self.norm(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/norm.py\", line 57, in forward\n    x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/functional.py\", line 2503, in layer_norm\n    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.61 GiB already allocated; 1.31 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145410},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182995},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182701},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183607},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183592},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181804},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183604},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101303},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182399},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181492},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 33.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145718},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.58 GiB total capacity; 13.52 GiB already allocated; 61.31 MiB free; 13.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145715},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182105},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182106},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101601},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182383},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182982},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183296},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100812},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181483},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182400},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101598},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100815},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181806},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182083},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101297},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181196},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181503},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183301},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183588},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 33.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145710},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100827},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100799},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181505},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 13.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145721},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101597},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181784},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181209},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 162, in forward\n    x = x.mul(self.gamma.reshape(1, -1, 1, 1))\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145420},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182700},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181497},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181200},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101581},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 46, in forward\n    x = self.fc2(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145413},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183282},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181789},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.58 GiB total capacity; 13.53 GiB already allocated; 51.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145716},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183305},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 47.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145699},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182999},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145698},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182100},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.50 GiB already allocated; 41.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181188},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101284},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182689},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183593},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182703},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183596},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181783},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182688},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182996},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101594},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181799},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.50 GiB already allocated; 49.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181187},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182390},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183288},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183284},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100803},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 162, in forward\n    x = x.mul(self.gamma.reshape(1, -1, 1, 1))\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 5.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145427},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101307},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101591},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182402},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181802},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181494},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182098},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182385},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182705},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182090},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183008},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182093},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182384},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182711},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182990},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183283},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100808},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182710},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182691},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182698},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183606},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181800},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182704},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181202},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 1.31 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145711},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 29.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145411},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181810},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 35.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145425},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.33 GiB already allocated; 37.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181191},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182092},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101289},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181204},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181803},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183591},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.57 GiB already allocated; 7.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145713},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183004},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101580},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181787},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101291},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100810},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 43.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145408},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101579},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 47.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145423},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183598},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100811},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 7.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145722},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183585},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100820},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.57 GiB already allocated; 7.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145705},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182398},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182997},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182708},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.58 GiB total capacity; 13.61 GiB already allocated; 3.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145405},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183600},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101582},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181811},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 158, in forward\n    x = self.norm(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/norm.py\", line 57, in forward\n    x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/functional.py\", line 2503, in layer_norm\n    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.52 GiB already allocated; 15.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181182},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101593},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100814},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182388},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183297},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 152, in forward\n    x = self.conv_dw(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 457, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 453, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 13.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181194},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183590},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101585},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181506},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182386},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183583},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181508},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100826},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101283},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101296},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182985},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182096},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182699},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182408}]}},{"id":1656,"modelVersionId":888,"type":"INFERENCE","config":{"resourceIds":[2322],"resourceType":"DATASET","dicomDatasetId":2322},"args":[],"createdAt":"2023-09-05T06:28:04.969Z","status":"SUCCEEDED","startTime":"2023-09-05T06:28:05.032Z","endTime":"2023-09-05T06:46:32.548Z","progress":100,"summary":{"errorCount":413,"successCount":67,"errorMessages":[{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101304},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183294},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101595},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182397},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 158, in forward\n    x = self.norm(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/norm.py\", line 57, in forward\n    x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/functional.py\", line 2503, in layer_norm\n    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.52 GiB already allocated; 15.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181183},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181785},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183306},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101298},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183299},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181511},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.58 GiB total capacity; 13.53 GiB already allocated; 51.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145717},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182707},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183589},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 46, in forward\n    x = self.fc2(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 1.31 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145708},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182107},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182406},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181788},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183295},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181489},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182694},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182989},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.60 GiB already allocated; 7.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145416},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182683},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182094},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183310},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181487},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183009},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101606},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101584},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181793},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100804},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 43.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145424},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182706},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101603},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181510},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 158, in forward\n    x = self.norm(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/norm.py\", line 57, in forward\n    x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/functional.py\", line 2503, in layer_norm\n    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145702},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.57 GiB already allocated; 7.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145714},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181210},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101292},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183286},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101287},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183601},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.50 GiB already allocated; 41.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181189},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101586},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181501},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100825},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182392},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181488},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181808},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181498},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 1.31 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145712},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181207},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183003},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100805},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182112},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183599},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182685},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.46 GiB already allocated; 109.31 MiB free; 13.56 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145726},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183298},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 33.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145719},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183002},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183290},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 152, in forward\n    x = self.conv_dw(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 457, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 453, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 13.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181195},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183005},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 162, in forward\n    x = x.mul(self.gamma.reshape(1, -1, 1, 1))\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.60 GiB already allocated; 1.31 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145414},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 47.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145409},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101306},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182391},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101294},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 27.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145704},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100801},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181205},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101282},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100806},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 158, in forward\n    x = self.norm(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/norm.py\", line 57, in forward\n    x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/functional.py\", line 2503, in layer_norm\n    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145709},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182382},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182411},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182687},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183602},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182696},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183011},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183289},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183311},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101281},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 13.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145422},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181203},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101299},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181504},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182101},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182104},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182988},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182110},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 46, in forward\n    x = self.fc2(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 19.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145725},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183611},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183007},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183605},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100798},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182684},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101290},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182702},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182102},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181794},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182984},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101587},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100824},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181502},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181790},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.37 GiB already allocated; 29.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145727},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182690},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182099},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101600},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181208},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183287},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.33 GiB already allocated; 37.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181192},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 3.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145700},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182097},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 46, in forward\n    x = self.fc2(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 5.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145701},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183292},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 162, in forward\n    x = x.mul(self.gamma.reshape(1, -1, 1, 1))\nRuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.58 GiB total capacity; 13.60 GiB already allocated; 11.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145406},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100819},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182401},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183595},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183603},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182983},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101604},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182410},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182682},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101279},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181798},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181201},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101589},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183291},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101285},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100823},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181791},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182396},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182993},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 35.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145426},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182403},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183304},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183285},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182095},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 27.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145724},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101278},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100813},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181491},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183000},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 162, in forward\n    x = x.mul(self.gamma.reshape(1, -1, 1, 1))\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.53 GiB already allocated; 33.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181184},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101588},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182405},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101300},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181795},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181496},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182108},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182693},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182387},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182409},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.30 GiB already allocated; 91.31 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181186},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183309},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183594},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181490},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181486},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181206},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101293},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101295},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101592},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101301},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100816},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182986},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182084},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183303},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182992},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 11.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145707},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100800},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 33.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145412},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183006},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100821},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181484},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 27.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145720},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.39 GiB already allocated; 173.31 MiB free; 13.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181185},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.43 GiB already allocated; 123.31 MiB free; 13.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181193},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183308},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.57 GiB already allocated; 19.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145706},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101288},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 7.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145723},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183293},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181482},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101607},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182109},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183302},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183597},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183608},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101302},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 162, in forward\n    x = x.mul(self.gamma.reshape(1, -1, 1, 1))\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.61 GiB already allocated; 7.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145407},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145415},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 47.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145417},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.57 GiB already allocated; 27.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145419},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181199},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100818},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182085},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181493},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181495},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181198},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181797},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182697},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101602},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101605},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182692},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100802},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181509},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181807},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183001},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181782},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182103},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183010},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183610},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181499},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181507},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101305},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182394},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181211},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 35.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145703},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101583},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182998},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182991},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101599},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181786},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182393},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181809},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 158, in forward\n    x = self.norm(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/norm.py\", line 57, in forward\n    x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/functional.py\", line 2503, in layer_norm\n    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.60 GiB already allocated; 1.31 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145418},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182089},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100817},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183584},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181197},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182987},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100809},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182709},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183587},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181805},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101578},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182087},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182686},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101590},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182086},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183300},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181801},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182091},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182994},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101280},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181485},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182407},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100822},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183582},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183586},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183307},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181792},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101286},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183609},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181500},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182389},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100807},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181796},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101596},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 46, in forward\n    x = self.fc2(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145421},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182395},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182088},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182082},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182404},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 46, in forward\n    x = self.fc2(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.51 GiB already allocated; 31.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181190},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182695},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 39.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145410},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182995},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182701},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183607},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183592},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181804},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183604},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101303},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182399},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181492},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 162, in forward\n    x = x.mul(self.gamma.reshape(1, -1, 1, 1))\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 17.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145718},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 21.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145715},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182105},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182106},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101601},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182383},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182982},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183296},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100812},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181483},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182400},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101598},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100815},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181806},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182083},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101297},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181196},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181503},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183301},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183588},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 43.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145710},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100827},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100799},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181505},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 46, in forward\n    x = self.fc2(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 23.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145721},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101597},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181784},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181209},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.57 GiB already allocated; 19.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145420},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182700},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181497},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181200},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101581},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 23.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145413},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183282},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181789},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.58 GiB total capacity; 13.52 GiB already allocated; 61.31 MiB free; 13.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145716},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183305},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 1.31 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145699},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182999},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 46, in forward\n    x = self.fc2(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.57 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145698},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182100},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.50 GiB already allocated; 49.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181188},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101284},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182689},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183593},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182703},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183596},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181783},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182688},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182996},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101594},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181799},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.40 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181187},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182390},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183288},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183284},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100803},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.57 GiB already allocated; 19.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145427},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101307},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101591},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182402},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181802},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181494},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182098},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182385},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182705},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182090},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183008},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182093},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182384},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182711},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182990},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183283},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100808},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182710},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182691},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182698},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183606},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181800},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182704},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181202},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 33.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145711},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 158, in forward\n    x = self.norm(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/norm.py\", line 57, in forward\n    x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/functional.py\", line 2503, in layer_norm\n    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.61 GiB already allocated; 5.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145411},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181810},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145425},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.42 GiB already allocated; 117.31 MiB free; 13.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181191},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182092},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101289},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181204},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181803},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183591},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 15.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145713},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183004},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101580},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181787},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101291},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100810},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.60 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145408},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101579},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 3.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145423},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183598},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100811},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 13.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145722},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183585},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100820},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 5.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145705},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182398},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182997},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182708},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 5.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145405},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183600},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101582},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181811},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.47 GiB already allocated; 95.31 MiB free; 13.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181182},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101593},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100814},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182388},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183297},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 158, in forward\n    x = self.norm(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/norm.py\", line 57, in forward\n    x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/functional.py\", line 2503, in layer_norm\n    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.48 GiB already allocated; 43.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181194},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183590},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101585},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181506},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182386},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183583},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181508},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100826},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101283},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101296},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182985},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182096},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182699},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 139, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182408}]}},{"id":1657,"modelVersionId":889,"type":"INFERENCE","config":{"resourceIds":[2322],"resourceType":"DATASET","dicomDatasetId":2322},"args":[],"createdAt":"2023-09-05T16:09:03.180Z","status":"SUCCEEDED","startTime":"2023-09-05T16:09:03.322Z","endTime":"2023-09-05T16:20:33.745Z","progress":100,"summary":{"errorCount":413,"successCount":67,"errorMessages":[{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101304},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183294},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101595},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182397},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 158, in forward\n    x = self.norm(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/norm.py\", line 57, in forward\n    x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/functional.py\", line 2503, in layer_norm\n    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.52 GiB already allocated; 15.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181183},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181785},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183306},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101298},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183299},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181511},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.58 GiB total capacity; 13.53 GiB already allocated; 51.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145717},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182707},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183589},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 46, in forward\n    x = self.fc2(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 1.31 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145708},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182107},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182406},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181788},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183295},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181489},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182694},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182989},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.60 GiB already allocated; 3.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145416},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182683},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182094},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183310},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181487},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183009},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101606},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101584},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181793},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100804},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 46, in forward\n    x = self.fc2(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.60 GiB already allocated; 3.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145424},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182706},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101603},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181510},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 1.31 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145702},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.57 GiB already allocated; 7.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145714},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181210},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101292},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183286},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101287},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183601},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.50 GiB already allocated; 41.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181189},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101586},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181501},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100825},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182392},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181488},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181808},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181498},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 1.31 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145712},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181207},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183003},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100805},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182112},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183599},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182685},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.46 GiB already allocated; 109.31 MiB free; 13.56 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145726},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183298},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 33.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145719},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183002},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183290},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 152, in forward\n    x = self.conv_dw(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 457, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 453, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 13.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181195},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183005},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 162, in forward\n    x = x.mul(self.gamma.reshape(1, -1, 1, 1))\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.60 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145414},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.61 GiB already allocated; 3.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145409},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101306},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182391},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101294},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 35.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145704},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100801},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181205},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101282},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100806},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 158, in forward\n    x = self.norm(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/norm.py\", line 57, in forward\n    x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/functional.py\", line 2503, in layer_norm\n    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145709},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182382},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182411},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182687},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183602},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182696},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183011},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183289},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183311},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101281},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145422},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181203},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101299},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181504},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182101},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182104},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182988},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182110},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 46, in forward\n    x = self.fc2(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 19.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145725},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183611},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183007},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183605},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100798},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182684},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101290},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182702},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182102},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181794},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182984},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101587},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100824},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181502},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181790},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.37 GiB already allocated; 29.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145727},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182690},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182099},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101600},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181208},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183287},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.33 GiB already allocated; 37.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181192},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 47.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145700},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182097},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 37.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145701},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183292},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 162, in forward\n    x = x.mul(self.gamma.reshape(1, -1, 1, 1))\nRuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.58 GiB total capacity; 13.60 GiB already allocated; 11.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145406},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100819},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182401},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183595},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183603},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182983},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101604},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182410},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182682},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101279},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181798},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181201},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101589},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183291},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101285},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100823},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181791},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182396},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182993},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 23.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145426},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182403},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183304},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183285},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182095},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 27.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145724},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101278},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100813},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181491},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183000},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 162, in forward\n    x = x.mul(self.gamma.reshape(1, -1, 1, 1))\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.53 GiB already allocated; 33.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181184},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101588},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182405},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101300},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181795},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181496},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182108},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182693},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182387},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182409},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.30 GiB already allocated; 91.31 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181186},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183309},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183594},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181490},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181486},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181206},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101293},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101295},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101592},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101301},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100816},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182986},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182084},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183303},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182992},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 7.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145707},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100800},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 29.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145412},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183006},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100821},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181484},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 27.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145720},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.39 GiB already allocated; 173.31 MiB free; 13.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181185},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.43 GiB already allocated; 123.31 MiB free; 13.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181193},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183308},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.57 GiB already allocated; 15.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145706},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101288},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 7.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145723},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183293},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181482},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101607},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182109},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183302},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183597},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183608},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101302},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 46, in forward\n    x = self.fc2(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 11.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145407},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 13.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145415},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 43.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145417},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.57 GiB already allocated; 23.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145419},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181199},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100818},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182085},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181493},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181495},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181198},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181797},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182697},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101602},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101605},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182692},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100802},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181509},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181807},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183001},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181782},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182103},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183010},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183610},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181499},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181507},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101305},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182394},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181211},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 31.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145703},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101583},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182998},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182991},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101599},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181786},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182393},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181809},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145418},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182089},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100817},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183584},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181197},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182987},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100809},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182709},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183587},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181805},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101578},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182087},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182686},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101590},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182086},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183300},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181801},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182091},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182994},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101280},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181485},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182407},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100822},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183582},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183586},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183307},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181792},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101286},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183609},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181500},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182389},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100807},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181796},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101596},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 162, in forward\n    x = x.mul(self.gamma.reshape(1, -1, 1, 1))\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 5.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145421},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182395},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182088},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182082},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182404},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 46, in forward\n    x = self.fc2(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.51 GiB already allocated; 31.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181190},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182695},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 35.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145410},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182995},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182701},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183607},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183592},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181804},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183604},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101303},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182399},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181492},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 162, in forward\n    x = x.mul(self.gamma.reshape(1, -1, 1, 1))\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 17.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145718},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 21.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145715},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182105},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182106},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101601},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182383},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182982},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183296},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100812},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181483},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182400},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101598},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100815},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181806},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182083},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101297},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181196},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181503},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183301},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183588},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 43.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145710},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100827},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100799},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181505},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 46, in forward\n    x = self.fc2(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 23.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145721},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101597},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181784},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181209},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.57 GiB already allocated; 27.31 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145420},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182700},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181497},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181200},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101581},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 19.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145413},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183282},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181789},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.58 GiB total capacity; 13.52 GiB already allocated; 61.31 MiB free; 13.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145716},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183305},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145699},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182999},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.60 GiB already allocated; 1.31 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145698},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182100},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.50 GiB already allocated; 49.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181188},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101284},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182689},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183593},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182703},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183596},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181783},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182688},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182996},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101594},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181799},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.40 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181187},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182390},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183288},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183284},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100803},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.57 GiB already allocated; 15.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145427},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101307},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101591},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182402},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181802},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181494},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182098},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182385},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182705},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182090},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183008},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182093},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182384},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182711},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182990},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183283},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100808},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182710},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182691},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182698},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183606},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181800},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182704},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181202},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 33.31 MiB free; 13.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145711},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 1.31 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145411},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181810},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.58 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145425},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.42 GiB already allocated; 117.31 MiB free; 13.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181191},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182092},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101289},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181204},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181803},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183591},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.56 GiB already allocated; 15.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145713},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183004},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101580},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181787},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101291},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100810},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.60 GiB already allocated; 13.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145408},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101579},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 47.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145423},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183598},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100811},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 43, in forward\n    x = self.act(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/activations.py\", line 145, in forward\n    return F.gelu(input)\nRuntimeError: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.58 GiB total capacity; 13.55 GiB already allocated; 13.31 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145722},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183585},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100820},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 164, in forward\n    x = self.drop_path(x) + self.shortcut(shortcut)\nRuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 1.31 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145705},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182398},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182997},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182708},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.59 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24145405},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183600},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101582},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181811},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 159, in forward\n    x = self.mlp(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/mlp.py\", line 42, in forward\n    x = self.fc1(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\nRuntimeError: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.58 GiB total capacity; 13.47 GiB already allocated; 95.31 MiB free; 13.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181182},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101593},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100814},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182388},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183297},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 53, in forward\n    logits = fmodel(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 420, in forward\n    x = self.forward_features(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 412, in forward_features\n    x = self.stages(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 233, in forward\n    x = self.blocks(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n    input = module(input)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/models/convnext.py\", line 158, in forward\n    x = self.norm(x)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/timm/layers/norm.py\", line 57, in forward\n    x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/functional.py\", line 2503, in layer_norm\n    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\nRuntimeError: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 14.58 GiB total capacity; 13.48 GiB already allocated; 43.31 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181194},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183590},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101585},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181506},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182386},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24183583},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24181508},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25100826},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101283},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":25101296},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182985},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182096},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182699},{"error":"Error running model: Traceback (most recent call last):\n  File \"/src/server.py\", line 149, in inference\n    results = mdai_model.predict(data)\n  File \"/src/lib/.mdai/mdai_deploy.py\", line 138, in predict\n    predicted_prob = self.modelconv(tensor_image)\n  File \"/opt/conda/envs/mdai-env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/src/lib/.mdai/utils.py\", line 50, in forward\n    x = (x - self.mean) / self.std\nRuntimeError: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.58 GiB total capacity; 13.54 GiB already allocated; 9.31 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","resourceId":24182408}]}}]}],"datasets":[{"id":"D_Ejjw1E","type":"DICOM","createdAt":"2023-06-12T22:28:34.484Z","updatedAt":"2023-08-30T16:42:13.013Z","name":"Dataset_Mammography_AI","description":null,"studies":[{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93303890736000372712007719325496086506","number":1},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13225278160855776395459576364479610926","number":2},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.41584070234430372173765420238622114497","number":3},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12672963102145562289556730996924191933","number":4},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60417888430254618877950024443204458533","number":5},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99043702482538143920588129740411594274","number":6},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.34474459139031442853950131741108777705","number":7},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.37086773353446284773343305804355244033","number":8},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80391050361565627485212451571511025696","number":9},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21002115141957150748930841566364555389","number":10},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85863003054521018766410592665108460266","number":11},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.62118485175692420624795168534752720704","number":12},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16200791959753000368045520417827643884","number":13},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11966720494012221530810110357385190394","number":14},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.88194215698435731274339148094525478530","number":15},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.83839371612285027689003767776763048874","number":16},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79354614957179736401305033596760950615","number":17},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.31239740291001233741518144994772499937","number":18},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13174698018038694457989063228112812057","number":19},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.58800234986092969914664533385227251763","number":20},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11742590162883175875313569897624549552","number":21},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10452841293564474734596795955051241595","number":22},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.14601225381216912562015187533504378930","number":23},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71818230964448383520869831871740477137","number":24},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75745691882473550404320701186704369619","number":25},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.81723814540481517155985033223263347681","number":26},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.66714858276602326840716030031701387403","number":27},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.27082736737155301713931176384015269927","number":28},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11246358655889974431100828608162118475","number":29},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.22218224902210395057541058899085307466","number":30},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16315487813988430812442513983202308536","number":31},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10309035611505216862280722450541246232","number":32},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.81204283658079390355658813400263341728","number":33},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71853771447159478340450787452774678194","number":34},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.50522631466416528481899180495083771271","number":35},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25715243805698149204333256440870824269","number":36},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93526380671520015887492535929546289983","number":37},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11813670086153723206338479337175832552","number":38},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75741878950758353908459159312119136057","number":39},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93133103931352051484402456972107766631","number":40},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11698655628810989540571060069864032034","number":41},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12871879578819679719891901907662686672","number":42},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16540020943180754370807150979085512375","number":43},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.83250421635148946013153519487765464663","number":44},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10580530640190979687559814849138075292","number":45},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12118847365011015605577712214572748362","number":46},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.42930129259682883548149018732626607715","number":47},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79050063903915736280252381017111391036","number":48},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73888411782440722561759697580614855237","number":49},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91308826690545525860536682324342833963","number":50},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80644694338549900893329622765508569613","number":51},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.15759500103559442402170040073604275389","number":52},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.64822063358332988570658054393010790703","number":53},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.37481052888009201018744280876499747199","number":54},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.54813256783534721433738579210618545553","number":55},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.29807737968305150942312177305644885461","number":56},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13804204137716402403051597553324660220","number":57},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12908146249849039920696415050027251666","number":58},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.40344696294075300150160062065838404588","number":59},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.18451356275334181906363016167640641404","number":60},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79429684175445665349654548365684962300","number":61},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48786793299166551538312254431695656485","number":62},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.76866431241353372048397727730980991944","number":63},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25162057972473772604388654527530699966","number":64},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12511642292284168409350105164084473905","number":65},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.64359000099559658156498587464389062687","number":66},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91475997214512458849971662159446837815","number":67},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.83220965703804510231551105964284736952","number":68},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99297510164340936941011196622063805063","number":69},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25131591387333975145518022057168554543","number":70},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.43415918011096851369689698310969695299","number":71},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10269398163012726688315139227627302744","number":72},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.87960338353760541562113659603656910934","number":73},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93941794702315388207128045230732635036","number":74},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.34950116445822285169471448253491900507","number":75},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11297946758809153178514148072457428420","number":76},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13062978036211561299069240064005267195","number":77},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.37098606298536122843303719722803198849","number":78},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.76539434935930371049849985067098053711","number":79},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12201198184926121975568236806981099253","number":80},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.44268840829728327690174755499587977150","number":81},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.28961310214302326532231273556877912120","number":82},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.77431251709614638982573510124749768570","number":83},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.96259627320413423901705795066155407096","number":84},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.65111635762834508920120131926467516731","number":85},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.84996660472077757264400804144701261050","number":86},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.50209215340786337369085202922466155147","number":87},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.34899468821995656624249813465880267896","number":88},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.58757263665798274122180347059712236408","number":89},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.90401611779604220642086223349335055661","number":90},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13094296533556721353726131965937007684","number":91},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99162852402972082368083425716890299707","number":92},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.88842813133748485146442360220032193831","number":93},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.90175357630909062691702607095230942872","number":94},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.82065800443370343732726326749808666975","number":95},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.33248311764250609252926415301703405650","number":96},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.70163847492682589321424188470614095156","number":97},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.51223279862332025344440174436424220303","number":98},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13153704474817987985539323125113701197","number":99},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75113413177483704844125514273651708901","number":100},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11881517514314984013505968608624811672","number":101},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12479133383470513102715792657006746262","number":102},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.18737969147487548994528315487336380564","number":103},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.62468794464308636797243570442447095618","number":104},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10529044756004527076757439580685287766","number":105},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10497713059263035954965182581266888539","number":106},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12682277268613188167675770310610936624","number":107},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75439006953555576665256539968831756533","number":108},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.38484580092993348038032018087013585406","number":109},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60606429992424202487876507733605601408","number":110},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12730579577831327046368885397724528288","number":111},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.46584954119885956346283994543091210633","number":112},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.24404624952910736149480600150644684178","number":113},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60251934293149073128966912026521777543","number":114},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13142499132576174751026176218415717532","number":115},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.77600828108265136899372964304097233849","number":116},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.88579772249474829401016236973636042347","number":117},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91179334808756844348695469309051980050","number":118},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11769359540525537862874431576018276479","number":119},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12827574064170535149289119484389162571","number":120},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48667702885291445669902507988846325851","number":121},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10769802745724450538643262948787807073","number":122},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.33374207865203734098454680982138894732","number":123},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10706026263392395059870653011398151394","number":124},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12937577782669689946792277931916931847","number":125},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79087809092238002623414337728291348333","number":126},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.68048203751906038711439044654305312009","number":127},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48553968299257092382333406848470196004","number":128},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.54852509763302463318412066454050239480","number":129},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.19579800015014953153712165445061942598","number":130},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.82719303693401009244066209414579378801","number":131},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.97265661054012677215681885343727534286","number":132},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.31824021375984433881579660270589439380","number":133},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.94277542651599649459532805564866357367","number":134},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.61962703328727659180847366388601957939","number":135},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11538214069155744425062700188294255086","number":136},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13669211337607017981135488365255070200","number":137},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.92422104028398384503428501981774487624","number":138},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.14010667492459983467337785065886658237","number":139},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.58728885604757549800793485205356758691","number":140},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.78963154647708005973105912285763136687","number":141},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.29193180490340351330488027813403553513","number":142},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.41667346088482396870267319907856641499","number":143},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12631759947916514385698616913359664340","number":144},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.58302373745357182898510440360766794502","number":145},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.54175083796333237627567721352293760733","number":146},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.46957211017584351371542049611698958996","number":147},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.94944875722528554740934894576490558110","number":148},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.14631389727569836237422630163195232893","number":149},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12524938704478986663841724041442866562","number":150},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.30981152963478631799741969031287939322","number":151},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.59081729226565561429160712458722564092","number":152},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.32929637273390205850174187543181904147","number":153},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73412900563664530788354761126442465465","number":154},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13171276746119976852823800924743373657","number":155},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71199407480035134079530841464067493285","number":156},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75425990907273623658495595012412883940","number":157},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12035585989088344570203528477569727096","number":158},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.38909950830625504104530734790341135234","number":159},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.98588023839700561230299299999663784051","number":160},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11661935084270467267558866209196194180","number":161},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12219301736930271960895320249010263529","number":162},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.86442750468046937727434872052719147664","number":163},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.88410047062997336020873520458976966272","number":164},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48488458571845717615028211073336659831","number":165},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.42449797730112047972525232102285888196","number":166},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.49746700633481334519718578814530440980","number":167},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.68095338185768049234084661619349281458","number":168},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.96838411355026197200704816477499293361","number":169},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12463312045291275503446638352822565223","number":170},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11711264641880679039137752946957876910","number":171},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.72100323494150989725902881038246406076","number":172},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85833100118154502901188664566623443551","number":173},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.78327306607253891678694809525141929459","number":174},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.78962764672721315171461513643477142932","number":175},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.23335608960455499055669934998006896823","number":176},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.56524937335200616046430452259560479663","number":177},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80160272628700154954549497860953412879","number":178},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11168787406272086510092278742439802197","number":179},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.96334976999124079902873416682628891886","number":180},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10542307855070644109124731911561287777","number":181},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.32178172824841351458401731463223490318","number":182},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.68204626202021816934598363960248326201","number":183},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12269813405031988146306573291603722979","number":184},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10977839262769118252333916076227719554","number":185},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11480239365571223592709709352332313205","number":186},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12971443830438539807041016165740929169","number":187},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11665916505452990534106657555794678804","number":188},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.50498780213223959370704075229993642002","number":189},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16035601181221102968053430958865489565","number":190},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.40864463878486828650933624660870288100","number":191},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.84491963103261878946370568143388882534","number":192},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11577439546528204106534189654361057985","number":193},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13238001140914487889438852292587840503","number":194},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10901603438220812509119220647864587345","number":195},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16924946062905126532699573983611182176","number":196},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.82237732694913834213318951313079504884","number":197},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.36916173454816630234875479090637449276","number":198},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.78138345567551331375863929654443334848","number":199},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.41200263667241022083875947569958980780","number":200},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11773918497924383372809670281850948456","number":201},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.67909901986578040727665369056691831086","number":202},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.54309862546585469543030534212950422623","number":203},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.41483166791978703437715489424106550670","number":204},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.70505145367538448555686417003156009634","number":205},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.39340451976240637202960314896410800275","number":206},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.15282440823915878381439116676632844170","number":207},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.92657579092748421733842501129710447394","number":208},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85439115945317252300894604134539210565","number":209},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.42627959525372378721271680528626254001","number":210},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12750154983505919567183133232955813145","number":211},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80015468386742411039386774584013239602","number":212},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.47855166296268275879490378125960810885","number":213},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.94803626687748563316729544469829538627","number":214},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11456879303459206608832549852332230190","number":215},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.70621526990377671804197754672847151804","number":216},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79977422225994750876734853132215061729","number":217},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80155946051432180280432788779471390107","number":218},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12582078274025731767580496703780743428","number":219},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.45060944219719548494779896173706450544","number":220},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11062485326477291448433879045062400279","number":221},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.46344264026054168569743333813934274874","number":222},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.77182873577987901019018090957261680871","number":223},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.15150430857597740595536077016420918547","number":224},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16313857558454667463133964724696178927","number":225},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48236253062819492404000057686746909186","number":226},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12625952318616532285718402740396562652","number":227},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.47455675870506572037385367594616312791","number":228},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.59540195178117941120463002665457446145","number":229},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.57430668419465349382839910390771885021","number":230},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.78177363689246304930178481367475554698","number":231},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.31017938691854123763396482052997034208","number":232},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.69031829872322877264662584562762620007","number":233},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11696917568762103250757219495090823342","number":234},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85731099173337779340205781144285712458","number":235},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60973471538762133249252076597767309025","number":236},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99189512140408006328067029114688185968","number":237},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21077073708822822348812286181224530090","number":238},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.43844792424860654229442870194089245662","number":239},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10958627897673706070870737485859672877","number":240},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.35349772926744211187085939072079717266","number":241},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.57329632545929703173546548759157259700","number":242},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.83898146086830430713466638547430782845","number":243},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10315647149032083981199914334786991292","number":244},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.49509138243574502976078459277600261505","number":245},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91597983735914917784584633185215281608","number":246},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.68891812297434884178212253788631066262","number":247},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.37375369150606343695569958067070922694","number":248},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13044809795271970793340086572814832722","number":249},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10966581693714712669534733200018471810","number":250},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48335791833673069860663659950116667950","number":251},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13227939759564927628044221843025711405","number":252},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60458395479499293020484724939933268985","number":253},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.72359723206252261845865896876069421428","number":254},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60217599219722995398584787186854183542","number":255},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99618481906705347793339135324369699955","number":256},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13848424590808186389209893894535032334","number":257},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.40269496293450163028799044053001588273","number":258},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.26752142779010153231279566757804215818","number":259},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.82190439179095202267530336192168171372","number":260},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.58843044960957391812947426997145342262","number":261},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.47119556147001825556697340862207501959","number":262},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48624566651425917347917399177034224625","number":263},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.33614736126311682781603512887995571610","number":264},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.32246029550851696616913808071735432216","number":265},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12838385612691482873960836573390505424","number":266},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75778206960646534112056227180557442730","number":267},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25572854715632835018700797290915589961","number":268},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.76035003944380435988758274649536174092","number":269},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.89821765897402300490745754301228424687","number":270},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13199872161148361503228139669112249354","number":271},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12036075705803389539875450775032967597","number":272},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11371588824163972596643800663171839380","number":273},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12016107447110874469054144786046676902","number":274},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13887917546117893627654317330508186740","number":275},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10129485293993846070584903741834910022","number":276},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99375125889509739000255453445355707578","number":277},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85799969157725544735090344356311053788","number":278},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.20508908524138476106071513366101327791","number":279},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.18012466865260079508523947265688938829","number":280},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13131398542776092224286088214089817997","number":281},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12317724954927402561013144593003960934","number":282},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71980503003038303566110922658657015622","number":283},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73977060266344579565534962764715522631","number":284},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.64999748592463808603272227663341624851","number":285},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11998085386354885581113322343440184457","number":286},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10708327633990641329598159285063740721","number":287},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.15399992324189392253036457447811994741","number":288},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.63867794326687759769976949300183271135","number":289},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.44656752610731358698401307053489020971","number":290},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.92866408024505903755158085388315933265","number":291},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21816129098022674726002765296771481656","number":292},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85256139166896878057873194342438509375","number":293},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71857024290319877004765559302285850875","number":294},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.66552103834543398623260130454288369564","number":295},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11135062509982139033722073268687429401","number":296},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12393523103905000406305547155493372826","number":297},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.14238834685528243427551869594414323154","number":298},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.62609378187177386044343929558354641423","number":299},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.97166254503678497985697723887044072179","number":300},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10485917432429788472580042580580580010","number":301},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13608681572837388841852726222845347807","number":302},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73181279240584602293891079622155400884","number":303},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.34209168570004256029544604981275712252","number":304},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10253267382268765671345526238253521443","number":305},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.72304885611206761666650332079059263792","number":306},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10038057009899620100439590139502832481","number":307},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.84474223029753391381336896453319306066","number":308},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.36743768588217888218325958515254087142","number":309},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13032923775098935974325286058204178304","number":310},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.40790757849688405239694915002630208292","number":311},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13724246864315224052812927542186848941","number":312},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.53554350010870854136629850303645841959","number":313},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.57567968135683618687351498772927393130","number":314},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.56590224054631827659371714020672077503","number":315},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.17235423704436097551033150571011641368","number":316},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80708824757928886775690614782304881714","number":317},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93620857167467296013973886667895641763","number":318},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10649123533840364698238464433715469078","number":319},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.72318042413542606250114036192448862563","number":320},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79116045241778631337851084138825655456","number":321},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12995850359694827080453463369559331557","number":322},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25613212691580359756890914532753630818","number":323},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.51659476997821693666730480646184150730","number":324},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11164625109303416757661899254162144137","number":325},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85261187800780141322768582217787299774","number":326},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10483780139520388432767085374994267319","number":327},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.27923801890829673594303099819797465748","number":328},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.49718226519486957013804228040520217700","number":329},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.94775066503971484677609666694146987407","number":330},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73208816940382883298440187310249101132","number":331},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.28150756080657506706653545700573111477","number":332},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.17767224618901415451826948918657543600","number":333},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.61472730345073680647764752684177347672","number":334},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.45777581710265094863325785436109398806","number":335},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.69461858205065238824388758720236487526","number":336},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.62246056757523244010527833617607879958","number":337},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.67572093718496224437744143586010111656","number":338},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.35937907949315185643094584517153804423","number":339},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11786388650169906050772291337998113311","number":340},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91393075321743891449774151850709139926","number":341},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25092884639081531600991192743207808547","number":342},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.88360110909134076418081578591735176905","number":343},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25180033451217749014235488150218481532","number":344},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.19293628404212733929487994700938328697","number":345},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.82821123123239416143914175106842401302","number":346},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10241974035497383778236307758830459858","number":347},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.64573690754216079413239404098526993895","number":348},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.43061088137138130978940764893065682357","number":349},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.69218935080405138479177348916426445065","number":350},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11258181130803258031610899883779890137","number":351},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.47848519885454752636636136321291135726","number":352},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.84510830332684400920480989934288923818","number":353},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21377393803912004299767384556111210118","number":354},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.61053347298051210392723292408301449888","number":355},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11190554787234919848127325239478519590","number":356},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73499689281329871763891175698407901358","number":357},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12501659463346781411565544872537352542","number":358},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.36909409723083164884354282321728714608","number":359},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.89896977788078633073887999299912054415","number":360},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.61226597695477970385263918743277113520","number":361},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.32029308943673693281458379486508103186","number":362},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.17998633499199966097100826204557645252","number":363},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.68532479715136923151798323246554586024","number":364},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.77272656307938248798960033178921854484","number":365},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.45729633253372074463525706160521519912","number":366},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11209160392598761547660031266151602973","number":367},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48335674810817558371588816282729034633","number":368},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.28325218614026062309405249972608731665","number":369},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91441827783598865420337615221799403565","number":370},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79633379515969915028297840138476891738","number":371},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12842779612931633380636708157194840581","number":372},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.51060347547454219628821978895140686447","number":373},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.31060202731175039991227548165329478684","number":374},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10883199542847308192684203089176494263","number":375},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.22139771314029498055177920517164045395","number":376},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80822167935657771451481208176509564321","number":377},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10534436658757997525104024176930298873","number":378},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.70378448052022113805084699086050912245","number":379},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12924077579550617491456328336599316853","number":380},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11022711610487845302396300293289900291","number":381},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.69540398944457244073015123988486143041","number":382},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.96322445598853397273434599662359793736","number":383},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.35042857868068387620588284736083754265","number":384},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10544259713393837462153269167511008844","number":385},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.36270850915012667676354399931321669825","number":386},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.69955327875037516626102821996107076828","number":387},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48424830583356042442416691172975554279","number":388},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.22677699159307365544525703118737850694","number":389},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.63743700654110698203689222987028310037","number":390},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.51444001104172723111320535593532668813","number":391},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.45451611943227069981803998658376897828","number":392},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.53676121044312473589633621837141335897","number":393},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13073808697947823704076585576666261018","number":394},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.38996554826330969516727430277563624014","number":395},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.31950744889524914630847592969529106228","number":396},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.67293636725396449819725250528284599308","number":397},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.55754641250799848100173390579222641290","number":398},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10380451206963549167998467773572372270","number":399},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25518211441212413548832599748597054061","number":400},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.95249478162832051359951354286981414237","number":401},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11042310934490422669951531073579519747","number":402},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.68729838521474752319883842581152968497","number":403},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.43257965466364586478888814270216801906","number":404},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.35139208759902972997867024561775138192","number":405},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.89552706312202289981386450209680481409","number":406},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13381763471511125427238165640409276148","number":407},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.41108827357129066448069836688814745138","number":408},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10918627205006898155228010708615417303","number":409},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12742625635308835425963945418314320982","number":410},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12174001136204335508243949223895578144","number":411},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99074584825847668977343463788476974017","number":412},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.66914839255851806328299801504801314539","number":413},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.27986411246177431706317268818010455644","number":414},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99195844209740668960811965530575588271","number":415},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.15478465558763747779169117542697291118","number":416},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.24413770758904814760630925262275074575","number":417},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.36867564389966200976019338256058728063","number":418},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11528224972962056302516197690283133911","number":419},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.72061259167073845280042884801716069871","number":420},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.74516002979519783554459948133834803127","number":421},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10398825632721518723603573243822827484","number":422},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.47708833900117803673317214896256966181","number":423},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12816264874592401301145180682829136710","number":424},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10966350621361719674419401232868468976","number":425},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.17540654720542571431329334343244725837","number":426},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.77054032051247923780421869179745133341","number":427},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10714171265004313225560843062551891314","number":428},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71471560959936642538886021420364143524","number":429},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13197066619753113574214041437054126744","number":430},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.30789883245513372263968277346818032715","number":431},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.35457347809309112681151756893784876864","number":432},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.44613500617949028028622641188187135667","number":433},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11441334862203587623269481636775921811","number":434},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.53649670044097743657462222943449045050","number":435},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21122097897037871212268548493481795098","number":436},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.84881872790365372014697313198434622105","number":437},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21400074599115935478325250996032379085","number":438},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.62163571585421150798010542117356325599","number":439},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.61634065904844993081715040290549683596","number":440},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.45854826044894941695514203309029096377","number":441},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10272793534235736165649396393422157082","number":442},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.50888400392275373093277884701345946123","number":443},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.82214954943758538057111149152499879438","number":444},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.29991169787512407345281725247974847063","number":445},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10246889707373953103179618615720757770","number":446},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73999916250634006466650586299120451581","number":447},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12890413566198563811777878086483053426","number":448},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.69327337018147384667885990327165515369","number":449},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.34712358766091473204382913223352482740","number":450},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21132361706015758770437397882646041526","number":451},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.89635633611188763143443269322395463597","number":452},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12772141535050570738466705205446727453","number":453},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.17173546323937767365117126310911196186","number":454},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.35477962850842611325700055089911936925","number":455},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11198832828331639461919093925236014885","number":456},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.70784585704842865168097484838235520254","number":457},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75477508361854394690726148299659792201","number":458},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.94830495021084799903389062871168331615","number":459},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.95141296038681961810341191108604131230","number":460},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.29949963209101918695616385450393584350","number":461},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.47921467984941546304647325624027641826","number":462},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.42213976358922013178414277787367086723","number":463},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.49283050650370045696542560227429084866","number":464},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.38696918948180699134767380212796372554","number":465},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.62495532585226910407315348000002810409","number":466},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60418824225914808230042331250041780756","number":467},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11930344697933749852196158376251264209","number":468},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11146032129881577011874756003168729450","number":469},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.43807116044199121438931937341837226666","number":470},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11439761491260138375427916273108390534","number":471},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.52815459225726718410102259687208386159","number":472},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11024116241144701260606273216410359420","number":473},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.81808136859620043073448891701148743203","number":474},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.53463294955894998327785993824375788640","number":475},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16634533869968662316916023519915825664","number":476},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.23096728411934483288052896587301039585","number":477},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12201135627267172124930298373299468322","number":478},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11499688846838445938719370622798986147","number":479},{"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.27731524556596512314958263895458255078","number":480}],"modelOutputs":[{"id":"O_YgJ1b6","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:13.320Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.41}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93303890736000372712007719325496086506","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.18933131084705356884804381455040439979","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10246470900314949112774779858606715675"},{"id":"O_BQYB9v","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:14.603Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12672963102145562289556730996924191933","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11490451502697619568913745270109712744","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.98524239922985237506822834835772680167"},{"id":"O_zpxlLB","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:15.731Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.41}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13225278160855776395459576364479610926","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10096646229606210096083716017760432173","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.45868000707182667687966934029758973194"},{"id":"O_JRyqpK","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:17.064Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.57}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.41584070234430372173765420238622114497","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.31826698412661834262339279169645209451","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.15781680202415329471961514022336248042"},{"id":"O_4XRmrd","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:18.103Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60417888430254618877950024443204458533","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69047852066263357259921465594099063561","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.20922878054271870966514899514445780327"},{"id":"O_gr3Zba","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:18.983Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.65}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.34474459139031442853950131741108777705","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11054813231011644849954786938460768772","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.51664194736578964583365212788765505610"},{"id":"O_Z5glbR","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:20.524Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99043702482538143920588129740411594274","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.41296222598996201764137126287695545351","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27368894922558052521136085756674613278"},{"id":"O_rb2dLa","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:24.015Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.69}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.37086773353446284773343305804355244033","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25504309998170432288325714639898139564","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.85498951216142733027403015634981447711"},{"id":"O_AzGY06","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:25.112Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.61}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85863003054521018766410592665108460266","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.33353809230574917955127457223438803138","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.82491352139116858893948745915794673159"},{"id":"O_qpAyWK","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:26.742Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.79}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80391050361565627485212451571511025696","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.50818690366043584412449896049120052893","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.14245365400130544363943976862759981972"},{"id":"O_2AjdgB","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:27.783Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.62118485175692420624795168534752720704","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.92535670121750964997127013584522641352","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.43675707932226204557614276481808065118"},{"id":"O_j3Xqbg","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:29.737Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.52}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21002115141957150748930841566364555389","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.36071423266211373286935864717520233130","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.99121928847891260729185171760356813608"},{"id":"O_M1KMk5","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:31.007Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16200791959753000368045520417827643884","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.43805520248639652974150105177454656607","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10938257119716116504763784338743476385"},{"id":"O_eJv4bd","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:32.060Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11966720494012221530810110357385190394","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.37674556826305313919134814226868085489","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11393809490237521859180218293619593731"},{"id":"O_OexObK","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:33.566Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.71}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.88194215698435731274339148094525478530","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.90420738963877449569630462422677876482","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11535277798648419691039880832660825724"},{"id":"O_R0kdbX","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:34.601Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.7}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79354614957179736401305033596760950615","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96993045450219906823069392214070547160","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.72911556529236123897149045055705600678"},{"id":"O_yD1PL5","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:35.503Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.7}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13174698018038694457989063228112812057","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.80167156419858945241544136779618781195","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.83693387504209685519843226597037641407"},{"id":"O_dylJbA","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:36.418Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.29}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.83839371612285027689003767776763048874","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.23371623908036063691186464287385623757","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.73673904472681674416881067950208762932"},{"id":"O_6Km9qj","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:37.785Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.31239740291001233741518144994772499937","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.87176998758634448044544074239265966551","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10080915976742060510467597104574525029"},{"id":"O_mWYMb4","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:38.503Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.8}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.58800234986092969914664533385227251763","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12107791240269769285031008746359707083","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.94505907225716746667228616929116530847"},{"id":"O_06rRJD","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:39.673Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.34}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11742590162883175875313569897624549552","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.75366979216310481072510256303631173633","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.15920889430824388281261828228438821995"},{"id":"O_9Kl1Md","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:41.130Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10452841293564474734596795955051241595","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.64084061604094120653895727153609840018","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13142206345544355701721261741547213782"},{"id":"O_Ky62VP","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:42.247Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.11}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.14601225381216912562015187533504378930","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.71215887896814391983359601432246088018","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.22531274325370344844655522842850992018"},{"id":"O_oz4OXw","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:43.524Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.59}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.66714858276602326840716030031701387403","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25787584734607648992846677997225654240","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27828248411309324213682653629163636974"},{"id":"O_1Vqy4K","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:44.708Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.13}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71818230964448383520869831871740477137","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.82361768772950537728395568849043085858","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10265027780464709418481729507830875317"},{"id":"O_l6GjbP","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:46.102Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.62}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75745691882473550404320701186704369619","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.59014790384606378070085323496289392716","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.28219548975553795025985411050189332134"},{"id":"O_x5KoLk","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:47.662Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.48}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.81723814540481517155985033223263347681","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.58233199964239845938296376506133264789","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11085120079835306365391562000259141695"},{"id":"O_vR69LM","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:49.037Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.74}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.27082736737155301713931176384015269927","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10860201126926665433580896573363442243","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.81806739807882296432081966127449913219"},{"id":"O_QLVybM","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:50.349Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.74}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11246358655889974431100828608162118475","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.91489889384464651956915195105586804452","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11882794108790840046371840696667858615"},{"id":"O_pqZRWR","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:52.479Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.22218224902210395057541058899085307466","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.95243867697103445238216031505700734838","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.98122999398331283914494520137442724726"},{"id":"O_VP59bm","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:53.515Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.19}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71853771447159478340450787452774678194","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13186421011895497478954122190364415328","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10017867533548153747532497999753535032"},{"id":"O_3ae6ZW","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:54.806Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16315487813988430812442513983202308536","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11474507952560515988794477890383486515","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.88970940169374082821043033183053165553"},{"id":"O_kkW2bD","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:56.176Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.43}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10309035611505216862280722450541246232","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.16213998524616414013702809656675880276","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.50544220449549978956833983792017581668"},{"id":"O_Dx4Joo","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:58.025Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.49}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.81204283658079390355658813400263341728","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25176115537973378934460994435321616545","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.76678324666203475756220706198643496226"},{"id":"O_bq9Bbd","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:40:59.319Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.50522631466416528481899180495083771271","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.42385918989460517329468248272105082301","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.94704476797772187673353028789294518981"},{"id":"O_LP0j35","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:00.566Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.12}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25715243805698149204333256440870824269","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13212213007959308019464859229508333156","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.88831760903045414620144157465468172241"},{"id":"O_w20KLM","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:01.855Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.42}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93526380671520015887492535929546289983","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10005721767304978718480772202941307873","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.31228993792611252157157850013794577388"},{"id":"O_X4Bobj","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:02.745Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75741878950758353908459159312119136057","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.52486265608257543978440319061999116036","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.55575346266251085039046951292303623667"},{"id":"O_aNmYbw","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:03.840Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93133103931352051484402456972107766631","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10824053040590274406004252038314270760","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.53488417959807852077074815287977103573"},{"id":"O_WoNKbq","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:05.009Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.45}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11813670086153723206338479337175832552","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.19448540300943212103790837127528957485","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.21944557927725907440899936097843561265"},{"id":"O_PZQRbQ","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:06.102Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.16}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11698655628810989540571060069864032034","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.97669330179071615862903963475056029477","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13298340086429837306155052152328799541"},{"id":"O_5vd0qj","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:07.232Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.29}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12871879578819679719891901907662686672","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12657148488992834772578677746864215026","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.23381370939846181007853412412272540647"},{"id":"O_Gg2Zvg","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:08.282Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.67}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16540020943180754370807150979085512375","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.24204921505048320465935139628168161374","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10312210881795264256469006137882633042"},{"id":"O_N61e5R","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:09.403Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.49}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.83250421635148946013153519487765464663","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12968836314273245640067990758755075610","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.95190610383006262926006802762620160598"},{"id":"O_YgJ1A6","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:10.314Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.62}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10580530640190979687559814849138075292","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.33953834155850580445103913518867312694","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.91745256668337329458596436099891180469"},{"id":"O_BQYBKv","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:11.440Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.63}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79050063903915736280252381017111391036","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.59678276848040851224759355011403206500","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.79111654385317924723837090669238940962"},{"id":"O_zpxl4B","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:12.572Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.55}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73888411782440722561759697580614855237","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.98204450747876117024804960884542660990","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12293403773195911843592382511702039775"},{"id":"O_JRyqVK","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:13.706Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.68}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.42930129259682883548149018732626607715","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.86631893393554574180761603609010258877","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11743366893897588685865573913454870435"},{"id":"O_4XRmAd","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:15.438Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12118847365011015605577712214572748362","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.77728863974209631696222971513121379029","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.52992034446854865578542841618408723227"},{"id":"O_gr3ZKa","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:17.006Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91308826690545525860536682324342833963","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.29039333521885472159126513151084009870","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12735379275548833107390561285864827065"},{"id":"O_Z5glqR","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:18.803Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.61}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80644694338549900893329622765508569613","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12788228873601239619796127903668763309","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.71716263199124676229159869929158875557"},{"id":"O_rb2dDa","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:19.912Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.15759500103559442402170040073604275389","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.72586423663378593077643116249468820298","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11083885680040837201836943833099377862"},{"id":"O_AzGY96","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:20.824Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.05}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.37481052888009201018744280876499747199","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96876074358067414504721273285702630272","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.82145141848899269885251546758736024106"},{"id":"O_5vd0qZ","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:22.204Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.64822063358332988570658054393010790703","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.30610375315508762889093026154499822526","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.40079301320894456412018365670485244716"},{"id":"O_Gg2Zvq","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:23.308Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.54813256783534721433738579210618545553","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.39674660399893628916072993056960804687","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27544197238006600533326101135182607622"},{"id":"O_N61e5g","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:24.456Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.29807737968305150942312177305644885461","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.29097391730926934051949708983048977904","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11679973001512875320227789007313688739"},{"id":"O_YgJ1Aq","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:25.436Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.45}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13804204137716402403051597553324660220","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.72112013191909574272550789892506252726","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.26229398495758888643104039387809388278"},{"id":"O_BQYBKZ","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:26.515Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.24}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12908146249849039920696415050027251666","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10661897929718065158486387010660138735","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.58776135274242633369950600750547980022"},{"id":"O_zpxl4P","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:27.676Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.3}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.40344696294075300150160062065838404588","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.74081199494998751148122642849211336715","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.67265802380419311547634205841088794736"},{"id":"O_JRyqVX","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:28.658Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.18451356275334181906363016167640641404","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.34059071045204310029405237880515168365","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12350461038454527639815577279110964583"},{"id":"O_4XRmA4","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:29.705Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.76866431241353372048397727730980991944","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.89068859028686738606250960097109556160","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.22647559013018053834720695087777100905"},{"id":"O_gr3ZKj","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:30.820Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25162057972473772604388654527530699966","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10812733082985064837902997994614511715","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.80922014075969895930494329681174351244"},{"id":"O_Z5glqP","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:32.607Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.1}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79429684175445665349654548365684962300","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.89285989936669975575370285779211657350","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.52616383798646697772684725581381883719"},{"id":"O_rb2dDq","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:34.605Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.41}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48786793299166551538312254431695656485","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69657075748860896083813103940156853933","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.31381953373007667698017879180314152742"},{"id":"O_AzGY9w","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:35.989Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12511642292284168409350105164084473905","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11160240470202434592122247090643647067","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.47034531066281080749915443657307786118"},{"id":"O_qpAykB","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:38.078Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.1}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.64359000099559658156498587464389062687","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.79144505378977886598368584444379708741","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.43260344447559082999522992855844744194"},{"id":"O_2AjdZ6","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:39.224Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.39}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25131591387333975145518022057168554543","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13276465698620724043087635931978008476","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12733663945463671304358997194184623832"},{"id":"O_j3Xqlw","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:40.452Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.43}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99297510164340936941011196622063805063","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69959497463988290620944485354375794223","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.19187351667789952444397332028023902886"},{"id":"O_M1KMDl","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:41.443Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.83220965703804510231551105964284736952","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.30924747754932728097349795555323724644","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.17674199708150135342293355721654948373"},{"id":"O_eJv40m","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:42.509Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.19}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91475997214512458849971662159446837815","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.52492540355485562030805751941352674033","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10685588105864847630972365330623817549"},{"id":"O_OexOG9","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:43.601Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.16}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.43415918011096851369689698310969695299","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.54503005577893891240009328398439324755","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.43818208008522492465988168354756988060"},{"id":"O_R0kdBZ","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:45.605Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10269398163012726688315139227627302744","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10504141411418594326014852763542092601","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.38780043051639100183160295965106951877"},{"id":"O_yD1PJV","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:46.829Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.87960338353760541562113659603656910934","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12926098564982604923868094385027597664","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.40227315463048490029054205138190565433"},{"id":"O_dylJmJ","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:47.640Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.56}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13062978036211561299069240064005267195","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11796853521684328756800169504528457535","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12872851715966853582021496274529141408"},{"id":"O_6Km920","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:48.548Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.34950116445822285169471448253491900507","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.14316263092570419326730100833459031780","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.70620192896372613680670112041432225345"},{"id":"O_mWYMQg","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:49.730Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93941794702315388207128045230732635036","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13072157702480839318098351383917171317","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.92177106457861773582443143505905627201"},{"id":"O_06rR4z","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:50.928Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11297946758809153178514148072457428420","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.32334981761562751519424822050343597419","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.83881405041527205877794427805142520176"},{"id":"O_9Kl1eM","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:51.979Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.52}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.37098606298536122843303719722803198849","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12153857980808732008181898302207999570","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.87027853787228120806988862994451650105"},{"id":"O_Ky6233","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:53.243Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.63}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.76539434935930371049849985067098053711","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.98624793177010059126077715732272779191","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.46482349274114195761286693463095629575"},{"id":"O_oz4OVk","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:54.372Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12201198184926121975568236806981099253","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.20529083675488674694804710997988445204","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.81488598041954777579013767895252895213"},{"id":"O_1Vqyg0","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:56.356Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.66}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.44268840829728327690174755499587977150","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10725784600827670385514170451367277784","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12315701044027260789754306983217509251"},{"id":"O_l6Gjv3","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:57.402Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.77431251709614638982573510124749768570","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.29886907450887482326498130466530147158","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12339446307314663662932117298407284094"},{"id":"O_x5Koz6","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:58.519Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.96259627320413423901705795066155407096","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.36002200496628321611478352403573808048","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.15894711920364203149789126882456691260"},{"id":"O_vR69YG","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:41:59.854Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.54}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.28961310214302326532231273556877912120","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.64218600427569471684140981202756923627","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.45171851074625271612917272479838208880"},{"id":"O_QLVyYV","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:01.532Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.24}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.65111635762834508920120131926467516731","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13080802737789271334819065432255256759","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10312258263964264497883983774164318566"},{"id":"O_pqZRDp","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:02.407Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.88}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.84996660472077757264400804144701261050","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.85797462824663766964838414854685451251","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.47500539876671104581035456353543062404"},{"id":"O_VP59rP","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:03.371Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.50209215340786337369085202922466155147","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.59126089130886178007157196196483643211","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.25165366551658319227917212240774392691"},{"id":"O_3ae62X","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:04.818Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.48}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.34899468821995656624249813465880267896","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.26660052438273712680250869994162085498","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.56050836864844387782438011100811790008"},{"id":"O_kkW2QG","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:06.268Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.29}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.58757263665798274122180347059712236408","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.80169978925264731492852313825304185980","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.33285116849900775235184876805243180007"},{"id":"O_Dx4Jv0","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:08.152Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.90401611779604220642086223349335055661","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.34542529879558972221134475918625391779","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11444413538279419876382261605855279672"},{"id":"O_bq9Bmg","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:09.175Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.88842813133748485146442360220032193831","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.37510179716281458872685925765007432224","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.32795861355963929406885408361380028244"},{"id":"O_LP0j5y","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:10.333Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.89}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99162852402972082368083425716890299707","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13212168520628710342556415248377814767","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.87597714396599607877271988748779579868"},{"id":"O_w20KX5","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:11.553Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13094296533556721353726131965937007684","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11302619727731756036016107481256214434","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.42977788964245111023830307511616043388"},{"id":"O_X4Boqe","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:12.808Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.90175357630909062691702607095230942872","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.33460607807813112990584240571205796252","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.44663800731226855034727106501219699798"},{"id":"O_aNmY6e","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:14.858Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.5}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.82065800443370343732726326749808666975","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11886097950238604345954439735940223394","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.98454738005228110196748317546811590412"},{"id":"O_WoNKA5","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:16.304Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.33248311764250609252926415301703405650","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.61416628421908271691044065268495311627","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.81183098428569496474218421649007128461"},{"id":"O_PZQRB3","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:17.512Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13153704474817987985539323125113701197","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.36303508305751776940619692018596872477","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.31611382225292940519464648047877638856"},{"id":"O_5vd0MZ","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:19.162Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.38}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.70163847492682589321424188470614095156","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.92186459553692179661557671424499226847","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.18531836611750810055293299946438226200"},{"id":"O_Gg2ZVq","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:20.410Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.4}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75113413177483704844125514273651708901","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11320611754177743647250219409498780523","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.43894604024376893052433762608916158890"},{"id":"O_N61eNg","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:22.042Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.71}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.51223279862332025344440174436424220303","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.78004707093108031396780690389560263087","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12799854955697620810086553004209227900"},{"id":"O_YgJ12q","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:23.905Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11881517514314984013505968608624811672","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25706003650900850109658072065964140763","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12702146740395881867916994790738276321"},{"id":"O_BQYBlZ","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:25.109Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.57}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.18737969147487548994528315487336380564","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.95710141164109815944557873007739247632","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11700288880835974639757293982381566922"},{"id":"O_zpxlXP","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:26.270Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.04}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.62468794464308636797243570442447095618","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10131413975140930064567288758132496130","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12527527616473200663239944820561080335"},{"id":"O_JRyqDX","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:27.231Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.52}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12479133383470513102715792657006746262","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.88954019058913277783394879494702989540","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11658264657794361727992896100404915523"},{"id":"O_4XRmj4","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:28.903Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.4}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10529044756004527076757439580685287766","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.82044617469319871415061168944100534855","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.83565935910898514758299257062092254916"},{"id":"O_gr3Z1j","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:29.944Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10497713059263035954965182581266888539","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.26997946909122595426316372198199315482","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.63688259922018846378994890425983442055"},{"id":"O_Z5gljP","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:31.505Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.51}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12682277268613188167675770310610936624","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10791598616881205091880395746425724231","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.62691871926223409038742665255078390154"},{"id":"O_rb2dXq","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:32.960Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.71}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75439006953555576665256539968831756533","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69775536458535955328230407490889337396","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.72197706717891933392641977651494786167"},{"id":"O_AzGY1w","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:33.817Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.61}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60606429992424202487876507733605601408","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.61353465653009435518200770785302186044","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13194670306626300102087561720216881327"},{"id":"O_qpAybB","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:34.858Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.38484580092993348038032018087013585406","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12285805611440164678966426226891822009","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12360767292998185276834343996442739210"},{"id":"O_2Ajdq6","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:36.239Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.58}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12730579577831327046368885397724528288","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96871842545249272576580228033920038566","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.90684384681788326540106993763643008716"},{"id":"O_j3Xqvw","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:37.357Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.62}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.46584954119885956346283994543091210633","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12806258389809440381470082347457821369","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.97570142858796754887773417999621723731"},{"id":"O_M1KMGl","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:38.842Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.38}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.24404624952910736149480600150644684178","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.44428283512211118396613564930179951421","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.19570689866938454001754644164374234647"},{"id":"O_eJv4Km","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:39.940Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.4}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60251934293149073128966912026521777543","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.62818116722393383875564462638217675394","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.70798079585871997447182533756164563656"},{"id":"O_OexOY9","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:41.202Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13142499132576174751026176218415717532","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11410971643551531169364842122878863808","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.30644773733532981072996325523676815925"},{"id":"O_R0kdJZ","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:42.805Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.61}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.77600828108265136899372964304097233849","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12146015871021696722297573464911142551","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10917706989225665527097065900126833003"},{"id":"O_yD1PXV","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:43.917Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.88579772249474829401016236973636042347","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.67323156910509147705849737750605272894","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.42729716943102628352022695870663394286"},{"id":"O_dylJ9J","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:44.768Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.31}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91179334808756844348695469309051980050","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.93889319426957474700427637761964462194","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.71029581459045668335239451458844941244"},{"id":"O_6Km9e0","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:45.736Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.42}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11769359540525537862874431576018276479","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.40362292845471183478400560900415005751","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.31613297892706864341945546931331496009"},{"id":"O_mWYMVg","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:46.807Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.74}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12827574064170535149289119484389162571","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11113941702320848520564067133854769152","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.24123426154386935333277625097419059060"},{"id":"O_06rRPz","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:47.907Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.33374207865203734098454680982138894732","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.28229825516603199123037604484179305229","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.17859443470451669661873629697841829465"},{"id":"O_9Kl1yM","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:49.077Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.33}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10706026263392395059870653011398151394","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.58707660628303916929605798843393046908","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10307871077826160963032444889811570024"},{"id":"O_Ky62b3","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:49.981Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10769802745724450538643262948787807073","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.61898365462679529570679398903840089515","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.63849716241579032379793224416689506295"},{"id":"O_oz4Okk","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:51.441Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48667702885291445669902507988846325851","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.61546264238425067438419579932884380831","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.51649105735509493524991702277682468034"},{"id":"O_1VqyA0","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:52.257Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.77}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12937577782669689946792277931916931847","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.24745572748056656554638983705512324168","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.93727297104310701506265179330934964862"},{"id":"O_l6Gjp3","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:53.419Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79087809092238002623414337728291348333","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.79155580760095429680355517181351396281","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.74957617785016882560866007973079904131"},{"id":"O_x5KoX6","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:54.904Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.49}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.68048203751906038711439044654305312009","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96683965991413556517539786496577813021","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.14942244667920770426526099350730007768"},{"id":"O_vR69XG","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:55.704Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.54852509763302463318412066454050239480","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.79059902944920413162332104423847302422","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.28566568119994507370260899087096257440"},{"id":"O_QLVyzV","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:56.506Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.45}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.19579800015014953153712165445061942598","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.74720266034929383380902143834065433710","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.25631993807605768864828641298209466807"},{"id":"O_pqZRgp","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:57.413Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48553968299257092382333406848470196004","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.54740071790218219525858991399401644643","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10492701122176645879257973760898021741"},{"id":"O_VP596P","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:58.545Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.43}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.82719303693401009244066209414579378801","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12389241030840346656769636896532765979","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.55621025035482105639017781889716578258"},{"id":"O_3ae6KX","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:42:59.527Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.69}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.97265661054012677215681885343727534286","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10072256251710375479882483398276251460","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.21207036834568895023612315322583346240"},{"id":"O_kkW2YG","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:00.503Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.61}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.31824021375984433881579660270589439380","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.93853616909605495368030565570868312627","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.81242585243272779877179488078702798980"},{"id":"O_Dx4JY0","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:01.806Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.13}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.94277542651599649459532805564866357367","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.37427394919184988501554240379996756732","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.80727693452877744864023734257559756696"},{"id":"O_bq9BVg","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:02.920Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.61962703328727659180847366388601957939","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.97508266180513083367297604509227178338","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11711324968115108213363469774380988867"},{"id":"O_LP0jAy","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:03.884Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.67}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.14010667492459983467337785065886658237","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.58223132871141493068873986663555405677","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13402417959980311689979567992448622957"},{"id":"O_w20KM5","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:04.847Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.22}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.92422104028398384503428501981774487624","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.81675394398366788008268143743809979315","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12284642363774000727055070080159125428"},{"id":"O_X4Bo0e","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:06.060Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.71}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13669211337607017981135488365255070200","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13263793471079234484019821829266732874","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.32759538073958812810008298335281777273"},{"id":"O_aNmYpe","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:07.316Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.51}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11538214069155744425062700188294255086","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.17795313782857909614597916818695616656","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10415279613063280844252277506887113171"},{"id":"O_WoNKm5","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:08.329Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.54}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.58728885604757549800793485205356758691","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.17050880258272989436711932669119999219","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.71818129558084510077091736476252072900"},{"id":"O_PZQRM3","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:09.203Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.78963154647708005973105912285763136687","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.30075707003240503965346093776553288761","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13309905625719845152456832473600155197"},{"id":"O_5vd01Z","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:10.113Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.29193180490340351330488027813403553513","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10978719700325114788072322701236395355","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13346516044096104221521414063058356621"},{"id":"O_Gg2ZJq","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:10.901Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.31}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.58302373745357182898510440360766794502","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.73737134602804608267902321086605050937","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13212310548319829325919493278536623083"},{"id":"O_N61e2g","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:11.652Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.15}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.41667346088482396870267319907856641499","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.50979853110246914218098698554380218751","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11634993898159169350260250637158185423"},{"id":"O_YgJ19q","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:12.503Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.59}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.54175083796333237627567721352293760733","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.53671982153394095431039258718686963506","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.23143380545266730617109867991071290186"},{"id":"O_BQYBGZ","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:13.650Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12631759947916514385698616913359664340","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.24166425740672125645428092183316833665","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.41459355092613757764011106513758065838"},{"id":"O_zpxlRP","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:14.446Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.55}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.46957211017584351371542049611698958996","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.82042450518496381349166714917879365631","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.83129807409025758473682085735711657359"},{"id":"O_JRyqZX","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:15.384Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.59}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.94944875722528554740934894576490558110","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.70842338564548358815054720472750418590","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.42367951722213103717860214112785838219"},{"id":"O_4XRmo4","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:16.363Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.4}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.14631389727569836237422630163195232893","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.40776581059561073100445617464632247635","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.72572296692431183925721156551992471803"},{"id":"O_gr3ZLj","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:17.315Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.74}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12524938704478986663841724041442866562","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.71422975025843428244155624617174822316","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.77063946077335071507164525934828117419"},{"id":"O_Z5glKP","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:18.138Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.30981152963478631799741969031287939322","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.77322961240414482813261164679739825395","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12700615086792496200623310823302811007"},{"id":"O_rb2drq","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:19.641Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.49}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73412900563664530788354761126442465465","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.89333260068847206349632828036163468392","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.78128372034111181295469613988099277142"},{"id":"O_AzGY5w","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:20.906Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.61}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.59081729226565561429160712458722564092","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11827851707757814703070138922159402724","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.68262186958038429790374081576871427930"},{"id":"O_5vd01e","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:22.303Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.5}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.32929637273390205850174187543181904147","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.14998736004562318309572455713728187888","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.26968693863602683216000536851772772617"},{"id":"O_Gg2ZJO","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:23.072Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13171276746119976852823800924743373657","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.55730609830093358306129451798904484912","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.87423910327443141243218077771834433369"},{"id":"O_N61e2l","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:23.750Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.45}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71199407480035134079530841464067493285","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.70498570832743614608090674917993212240","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.89415044782290866243773455717781724064"},{"id":"O_YgJ19k","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:24.646Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12035585989088344570203528477569727096","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11007508793040686058298429688343048598","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.20242487490457422604562815026202235398"},{"id":"O_BQYBGM","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:25.611Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.11}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75425990907273623658495595012412883940","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.78662029986854398991870004060714115944","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.38847928743298178230493616305396412066"},{"id":"O_zpxlRk","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:26.710Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.43}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.38909950830625504104530734790341135234","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.57931672942827094694808807020017448948","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.76060864518095867161313650915304956092"},{"id":"O_JRyqZG","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:27.581Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.69}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.98588023839700561230299299999663784051","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.81807968506931828651509128893422566990","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11790393092655686727304949713969734229"},{"id":"O_4XRmoO","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:28.573Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.62}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11661935084270467267558866209196194180","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.53835593805295173788247148516437410083","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13083516752592649876253543226003955136"},{"id":"O_gr3ZLZ","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:29.436Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12219301736930271960895320249010263529","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11255374717434438762349278447089545312","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27609310825495380012532466487270681266"},{"id":"O_Z5glKo","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:30.215Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48488458571845717615028211073336659831","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.50560191979539285108092536791760662562","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11295943195864931969761384758050053852"},{"id":"O_rb2drP","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:31.137Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.67}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.86442750468046937727434872052719147664","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.41083748052088173993443216769024115802","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.77651251606062141357571425746118450795"},{"id":"O_AzGY5m","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:31.873Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.42449797730112047972525232102285888196","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12675059948328960050147357217797698620","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.95411123458424274852093701622275165224"},{"id":"O_qpAyZW","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:32.808Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.24}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.88410047062997336020873520458976966272","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.70417279696464844308675337351522610140","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.91987308873518318094254286440862840459"},{"id":"O_2Ajd9Z","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:33.602Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.81}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.49746700633481334519718578814530440980","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.78538459279421151892659600107495563396","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.94241596527689890006616882476826419215"},{"id":"O_j3XqNv","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:34.420Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.56}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.68095338185768049234084661619349281458","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96273239239099631599912550903705998596","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.83856751114640069339295771506075769234"},{"id":"O_M1KMqq","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:35.543Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.62}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.96838411355026197200704816477499293361","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.27338622989398501997644528364052597220","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.71961123561106635550471144028601097753"},{"id":"O_eJv4D1","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:36.436Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.38}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12463312045291275503446638352822565223","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13356042498073572460096027847127576884","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12295240008580640787320241377884248340"},{"id":"O_OexOj6","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:37.169Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.25}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11711264641880679039137752946957876910","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.40275198886953578807769750290388911994","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.65133786535378485481347636476246567692"},{"id":"O_R0kdO4","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:38.008Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.72100323494150989725902881038246406076","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.47735806662965822145377566472570167915","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.41713779210234352000367513666488878373"},{"id":"O_yD1PO1","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:39.113Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85833100118154502901188664566623443551","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11481873655297204934082282536049121281","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10459067354162890233926110210110296305"},{"id":"O_dylJoz","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:39.927Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.05}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.78327306607253891678694809525141929459","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.63716452985950331406866684142151088860","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10555804932279541202208764983407553002"},{"id":"O_6Km9dK","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:40.916Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.88}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.78962764672721315171461513643477142932","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.38804904645440393974347206460938232126","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.71190102747650588624667699746848210377"},{"id":"O_mWYMkP","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:41.554Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.13}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.23335608960455499055669934998006896823","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.68097664511405574054281417343815317905","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.88353434352625305161374072518946766951"},{"id":"O_06rRja","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:42.585Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.56524937335200616046430452259560479663","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.49400166451901262089850685389360531380","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10442824048111674905433845311056944066"},{"id":"O_9Kl103","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:43.506Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80160272628700154954549497860953412879","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.48677504794306243538458483410380611242","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.50295939746073240334371705564634962575"},{"id":"O_Ky62Ge","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:44.605Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11168787406272086510092278742439802197","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.78904215021999668906388723472689004107","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12548874818988510170905381159595012448"},{"id":"O_oz4ObQ","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:45.582Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.96334976999124079902873416682628891886","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.27809204521014597195898255576617521643","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.91522731333489671125387599926251364949"},{"id":"O_1VqyM1","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:46.523Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10542307855070644109124731911561287777","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25191527197466546806814031817068218160","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.58948986899327344524439050306140303047"},{"id":"O_l6Gj3a","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:47.377Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.41}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.32178172824841351458401731463223490318","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11044426738378925637611422908589175161","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11615682729650217193223938626729209097"},{"id":"O_x5KoJd","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:48.401Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.51}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.68204626202021816934598363960248326201","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.49368245800988673289327190378357714196","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.72360969283354517355643401853300165315"},{"id":"O_vR69BW","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:49.620Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.71}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12269813405031988146306573291603722979","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12285351624301708541046699919691458782","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.41042120233475866139205874974917489752"},{"id":"O_QLVy42","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:50.637Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.04}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10977839262769118252333916076227719554","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.46288670687925998978291702974816941283","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.35113557194139848023351694420681458780"},{"id":"O_pqZRLK","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:51.938Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11480239365571223592709709352332313205","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12593335937591291424097458878007967394","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10322425140424628959691665575040142176"},{"id":"O_VP59qp","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:52.550Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12971443830438539807041016165740929169","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.93090815267140045957463968996479199197","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10918185512497241144388554144224455324"},{"id":"O_3ae6O0","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:53.267Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.04}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11665916505452990534106657555794678804","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12562613242122206568681116479041786229","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11236453231866499099784846762663541857"},{"id":"O_kkW2Vl","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:54.108Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.50498780213223959370704075229993642002","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.68510202725925249484912747698803675959","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10544251947508101784007516529528337726"},{"id":"O_Dx4J3A","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:55.003Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.66}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16035601181221102968053430958865489565","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.53728604678942336459421091984594538402","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11468247299893545031231175734185928329"},{"id":"O_bq9BPN","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:56.338Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.40864463878486828650933624660870288100","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.98980644788094566449064396672941155918","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.72122992538152108190022556159428885582"},{"id":"O_LP0jNX","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:57.106Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.84491963103261878946370568143388882534","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13403934769590633659410796193254638204","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.87877458370669247967044307250483308568"},{"id":"O_w20KzQ","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:58.083Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.63}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11577439546528204106534189654361057985","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96505309448603275035527457261907986374","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.91064417580149036238079507695776534761"},{"id":"O_X4Bojy","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:58.926Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.53}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13238001140914487889438852292587840503","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13012787920590746897362678932325412245","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.50536419187205916853475309692694565756"},{"id":"O_aNmY0M","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:43:59.914Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.71}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10901603438220812509119220647864587345","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.47897298984452106766140632829916531416","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10847807478230227359519260643043517778"},{"id":"O_WoNK24","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:00.679Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.81}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16924946062905126532699573983611182176","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69986601751064410771663838041659350202","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.19609911609425341761396710006967517206"},{"id":"O_PZQRJw","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:01.636Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.82237732694913834213318951313079504884","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10607571167547674220694890046109918083","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12870963503793994252748021877782156491"},{"id":"O_5vd0ye","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:02.752Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.36916173454816630234875479090637449276","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.17708148953434851415851342150005242991","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.99172595312453395296173731727989894110"},{"id":"O_Gg2ZbO","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:04.006Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.61}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.78138345567551331375863929654443334848","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11647784734801856809545255056084992379","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.86435952904648247127882437667663352128"},{"id":"O_N61eBl","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:05.432Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.41200263667241022083875947569958980780","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.78911702714334138822970011398512335890","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13280242629707455639344486109075303948"},{"id":"O_YgJ1Mk","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:06.183Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11773918497924383372809670281850948456","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.94609889432250375394243297456625745159","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10035620995571013736286889432578287923"},{"id":"O_BQYBpM","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:07.156Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.68}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.67909901986578040727665369056691831086","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.60064237712673937613803968016242114521","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.82566890486248729946120932388659984544"},{"id":"O_zpxlgk","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:07.749Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.14}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.54309862546585469543030534212950422623","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11560779665845190507469539193284559073","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.99088069627723740591708982414305104446"},{"id":"O_JRyq5G","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:08.834Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.41483166791978703437715489424106550670","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.29970146773460337023921243175454946765","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.51225950616283162435192976909324722172"},{"id":"O_4XRmPO","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:09.644Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.70505145367538448555686417003156009634","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.62674142447266952965842952416485492288","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.62081184896492595565514457435229782876"},{"id":"O_gr3ZxZ","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:10.675Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.39340451976240637202960314896410800275","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.92650766924873543769488596742654965555","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11225304723011366791263021553227868416"},{"id":"O_Z5gleo","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:11.663Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.59}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.15282440823915878381439116676632844170","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.21620034909738866984925751821741030967","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.95044138422265622392676759839269330232"},{"id":"O_rb2d5P","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:12.614Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.92657579092748421733842501129710447394","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.85820442973225514022774193940026641595","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.61994480809188971826187803457683426047"},{"id":"O_AzGYQm","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:13.623Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85439115945317252300894604134539210565","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10643103383721631236012228272116849895","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10720656396883542664282945100539210297"},{"id":"O_qpAywW","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:15.307Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.42627959525372378721271680528626254001","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.58032456939844289963813511875589615573","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11763991846443266597226766300901446046"},{"id":"O_2AjdeZ","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:16.257Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.57}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12750154983505919567183133232955813145","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.23998772185024743106870312937755730364","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.29846883635547328450299461727754667749"},{"id":"O_j3Xqpv","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:17.347Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.33}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80015468386742411039386774584013239602","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.75870904864794372102005493189123317121","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.24603948838154878496423549500106249664"},{"id":"O_M1KMYq","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:18.263Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.94803626687748563316729544469829538627","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.80308223162259747723235257160370456638","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.58823145992677040551386688064748195704"},{"id":"O_eJv411","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:19.331Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.57}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.47855166296268275879490378125960810885","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.91078642773231635125822726015020728603","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.70198601852329668548364681141164326191"},{"id":"O_OexOz6","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:20.121Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11456879303459206608832549852332230190","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.59455036310188473236373851980883646485","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.74248597298411250040804242763606144543"},{"id":"O_R0kdg4","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:21.014Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.70621526990377671804197754672847151804","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12481233033840686510791745134756441193","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.23299444752717848920307111806971083596"},{"id":"O_yD1P41","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:21.811Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.65}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79977422225994750876734853132215061729","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12487610066167307490089629992334792927","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11639615735609627089461391936995438500"},{"id":"O_dylJGz","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:22.637Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.69}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80155946051432180280432788779471390107","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.24831016819653828397237869604641986929","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.96521237568637764713221278016286343102"},{"id":"O_6Km9bK","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:23.428Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.13}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12582078274025731767580496703780743428","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11510358117381869520255596727578916243","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12232542793561602312054851932346665452"},{"id":"O_mWYMrP","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:24.741Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.45060944219719548494779896173706450544","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96018277860392303670292216827070241442","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.93677324576507034965820142947312465383"},{"id":"O_06rRQa","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:25.529Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.05}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11062485326477291448433879045062400279","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.92978742473388448299840892598912130864","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12628487666479006705372203844265340320"},{"id":"O_9Kl1X3","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:26.575Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.62}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.46344264026054168569743333813934274874","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11024801004558142522947524684785318971","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.76925035049219034471429745961218125834"},{"id":"O_Ky62Oe","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:27.434Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.22}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.77182873577987901019018090957261680871","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.54211880547369354003933836517414823831","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.45273620162363076586604938424410629033"},{"id":"O_oz4OqQ","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:28.422Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.28}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.15150430857597740595536077016420918547","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.63152654349803198070327823398082156276","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12405758653161425969984744897426591720"},{"id":"O_1Vqyp1","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:29.335Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16313857558454667463133964724696178927","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.48587698345068581479543000712233183798","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.31951024789924929027323932545302231630"},{"id":"O_l6GjZa","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:30.553Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48236253062819492404000057686746909186","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.38345114449409158137538700863261852704","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.23918507458686082883120072098415705057"},{"id":"O_x5Ko6d","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:31.760Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.4}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12625952318616532285718402740396562652","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10873663067222292461383780950097096626","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.46993442427688321461241766381238289097"},{"id":"O_vR69yW","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:32.505Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.04}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.47455675870506572037385367594616312791","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.41287610928081607833505609788059574405","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11843071172529441575998579870570821368"},{"id":"O_QLVy02","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:33.437Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.56}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.59540195178117941120463002665457446145","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.92429137818191758079510310563785831439","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.42342413390885622878443678270236720484"},{"id":"O_pqZR2K","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:34.288Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.57430668419465349382839910390771885021","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.50815584088880378840344665803710454937","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.94090120150179000457089413172559865955"},{"id":"O_VP59lp","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:34.907Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.58}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.78177363689246304930178481367475554698","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.74285174169202816414602019882916833047","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10830543476126918044546753843686059330"},{"id":"O_3ae630","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:36.113Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.31017938691854123763396482052997034208","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10551579300555225037501702412643457443","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.42499155998229495474073430114657189029"},{"id":"O_kkW2gl","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:37.065Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.8}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.69031829872322877264662584562762620007","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.53633959305313843956684171710907804114","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.41456815297058061788354021055930890160"},{"id":"O_Dx4JrA","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:37.877Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.62}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11696917568762103250757219495090823342","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.41641732783260329211847080423791278669","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13268722434372072873888888028049182747"},{"id":"O_bq9BXN","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:38.722Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85731099173337779340205781144285712458","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.78419376771227090377282097724559062851","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.63940739229021856396046765271132066482"},{"id":"O_LP0jRX","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:39.778Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60973471538762133249252076597767309025","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10561566844940358603808660363762335825","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.55187042146636756615899749021592548445"},{"id":"O_w20KdQ","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:40.612Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.88}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99189512140408006328067029114688185968","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.55131915528268941099207484844035701881","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13292916203253468276363089407454801829"},{"id":"O_X4Bovy","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:41.747Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.48}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21077073708822822348812286181224530090","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.93772345193800840166966498375145754848","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.21912785216714575495394868544297317719"},{"id":"O_aNmYwM","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:42.450Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.43844792424860654229442870194089245662","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.78473133492331547377884919976096188139","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.40137320735658902088433505379175043537"},{"id":"O_WoNKx4","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:43.173Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10958627897673706070870737485859672877","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.74389630491429496139895114309886920357","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12793016215145518368718624876188650802"},{"id":"O_PZQRmw","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:44.006Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.13}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.35349772926744211187085939072079717266","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.56841349630654275268816672847092626184","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13158537229160464340720455399512448602"},{"id":"O_5vd0De","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:44.852Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.57329632545929703173546548759157259700","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.74815886619818740028095617638031182524","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.68104251000833816361739720745002790631"},{"id":"O_Gg2ZPO","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:45.904Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.64}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.83898146086830430713466638547430782845","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.79512195059778297050257338734897262077","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.81995237786394885413298490363269080103"},{"id":"O_N61edl","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:46.927Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10315647149032083981199914334786991292","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.85748516159400244002296492537548716880","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11853795439605995682067224948663787422"},{"id":"O_YgJ1Qk","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:48.207Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.49}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.49509138243574502976078459277600261505","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.50893400323234796686818190158845285698","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.40729905621689337984963354394015648258"},{"id":"O_BQYBgM","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:49.026Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91597983735914917784584633185215281608","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.60066919758733179133232720823985192982","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10968750734063619763794825904727421436"},{"id":"O_zpxl0k","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:49.870Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.45}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.68891812297434884178212253788631066262","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.24793158439859336950860968588993915593","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.62151446974528798792101744489615247885"},{"id":"O_JRyqeG","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:50.953Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.11}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.37375369150606343695569958067070922694","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11473837722002509457212391094015531858","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10225962537707348948964111611638066067"},{"id":"O_4XRmkO","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:51.867Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13044809795271970793340086572814832722","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.80702698289192155675981445196935248843","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.76843356138289844843356484124384822864"},{"id":"O_gr3ZBZ","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:52.664Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.43}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10966581693714712669534733200018471810","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12701228773551919665676861494236940785","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.86143265599641899155986637388904716263"},{"id":"O_Z5glpo","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:53.301Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48335791833673069860663659950116667950","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.20558061401796637274484489041589955072","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10733152008147403422921275639197695829"},{"id":"O_rb2dMP","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:54.251Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.62}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13227939759564927628044221843025711405","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.44335128956519309100675234804360831589","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.90732069738821046572483289204617807512"},{"id":"O_AzGY4m","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:55.272Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60458395479499293020484724939933268985","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.27659282246259483442822113866607755733","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.69610709995166417454382691214291987819"},{"id":"O_5vd0DA","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:56.350Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.72359723206252261845865896876069421428","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.24843402922860138554920605371814832924","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.35718230368928389099638276327144044782"},{"id":"O_Gg2ZPv","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:57.365Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.66}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60217599219722995398584787186854183542","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.52361979169152689911652138449104791441","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.17971548982150830408305156844555312619"},{"id":"O_N61edN","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:58.508Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99618481906705347793339135324369699955","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.51192670202269253595486141586499563699","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.41603707864511002575496729392709186513"},{"id":"O_YgJ1Q9","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:44:59.711Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.52}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13848424590808186389209893894535032334","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.61745799900340893657275453684268850419","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12220087993218450344711289738605729977"},{"id":"O_BQYBgp","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:05.424Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.16}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.40269496293450163028799044053001588273","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.19852681269170567480041684641491496366","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.51162462525483381582798929890509225924"},{"id":"O_zpxl00","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:06.830Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.26752142779010153231279566757804215818","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13681840001638269682826805745656685108","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.20620499097822506983999699269753500120"},{"id":"O_JRyqea","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:07.845Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.82190439179095202267530336192168171372","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.77223803931474573234708619306836180409","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.30045325544913991994815981264716970471"},{"id":"O_4XRmkR","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:08.573Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.7}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.58843044960957391812947426997145342262","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10519157972349799623585053568948572266","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.78658023223904850887976981681435378158"},{"id":"O_gr3ZlX","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:09.859Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.46}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.47119556147001825556697340862207501959","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.18654059708748495592214310055851713671","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11343783162439455066785397909525102477"},{"id":"O_Z5glM5","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:10.700Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.56}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48624566651425917347917399177034224625","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10042863998159336967617341844087230802","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.63747679025556914039126911786019900416"},{"id":"O_rb2dwR","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:11.734Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.58}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.33614736126311682781603512887995571610","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.19309347956319041617527795339912370396","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.15452121595735757813972912115877224201"},{"id":"O_AzGYpy","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:12.639Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.51}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.32246029550851696616913808071735432216","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.85321550177973603412511076812716309193","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.22019508871193445127701034488328342753"},{"id":"O_qpAyLz","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:13.384Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.05}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12838385612691482873960836573390505424","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.76482406332245819587746522971686720484","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12360965664062046101732694856863309602"},{"id":"O_2AjdON","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:14.261Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.57}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75778206960646534112056227180557442730","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.67927360650992865917880401637803461363","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.14431320740928221458916347282150392231"},{"id":"O_j3XqQd","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:15.561Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.73}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25572854715632835018700797290915589961","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.92016837703962933123207857304613903889","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.36166222867084535553743245142822158533"},{"id":"O_M1KMNb","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:16.303Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.76035003944380435988758274649536174092","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12392436702610642117748706892430965880","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.72322680864606958121186173031865049988"},{"id":"O_eJv4oa","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:17.101Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.19}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.89821765897402300490745754301228424687","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11983094553420985112594470954371884360","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.57624041721076364968752258796051888437"},{"id":"O_OexOBg","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:17.870Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.41}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13199872161148361503228139669112249354","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13090511924216036462720283284079578626","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10818123632775013192066835241281796516"},{"id":"O_R0kd43","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:18.805Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12036075705803389539875450775032967597","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.61145994344097038458173280695807785169","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27195147325568806890439182886434313259"},{"id":"O_yD1PB3","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:19.773Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11371588824163972596643800663171839380","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.45951976640972641200477816486252123234","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.35085602331317385828661236583664469037"},{"id":"O_dylJKL","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:21.302Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.4}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12016107447110874469054144786046676902","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.41961027439669814449667525909264078994","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10634064730700484146797829449402697716"},{"id":"O_6Km96g","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:22.120Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13887917546117893627654317330508186740","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.72174276217351031456960522357463455063","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.54851262914603591987404049854967425071"},{"id":"O_mWYM3A","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:22.947Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.1}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10129485293993846070584903741834910022","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11316805028056702063471602312397145086","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10482913764117826111072531138380435775"},{"id":"O_06rRMG","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:23.700Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.65}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99375125889509739000255453445355707578","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.70194503571635759064405410360502173197","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.44510912861097272188126021640988947071"},{"id":"O_9Kl195","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:25.107Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.52}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85799969157725544735090344356311053788","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.18163049717741214154879715647975742873","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.95135628234365340467163047009193949098"},{"id":"O_Ky625k","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:26.003Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.57}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.20508908524138476106071513366101327791","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.48016876102974305491983847796501100642","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.76379826561337185067991568439321686538"},{"id":"O_oz4ODG","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:26.908Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.18012466865260079508523947265688938829","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.75367460095982667606162533001883404134","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.61977091077738881081252025669406127010"},{"id":"O_1VqyeB","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:27.728Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13131398542776092224286088214089817997","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.84110984140151589889528457892197603393","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12380356583388527081461919571021247711"},{"id":"O_l6GjVy","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:28.651Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12317724954927402561013144593003960934","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11924517470016139145191589469135932599","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.36787230164364650912329846161767060579"},{"id":"O_x5KoYv","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:29.743Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71980503003038303566110922658657015622","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.34350439283403446426018607087490842658","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.75787175809612322789532651435075602999"},{"id":"O_vR69Ge","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:30.584Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73977060266344579565534962764715522631","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.88450808368964385605856463954181072925","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.82015165100918073417411382448536105691"},{"id":"O_QLVyJw","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:31.850Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.64999748592463808603272227663341624851","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.49696249423213507457925698070105570489","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.36792128377315871443330797276814542064"},{"id":"O_pqZRbY","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:32.661Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.53}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11998085386354885581113322343440184457","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.17128682287646498576161643493631499491","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12696090866933343582777762903691321154"},{"id":"O_VP59Aa","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:33.448Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.68}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10708327633990641329598159285063740721","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.27893992788855417856328167897052759559","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.28726682022719194901566312319826345362"},{"id":"O_3ae6Rx","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:34.255Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.15399992324189392253036457447811994741","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.29672287698695917299804587145498112305","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.70611268880345321799278047621351704860"},{"id":"O_kkW2pN","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:35.078Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.68}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.63867794326687759769976949300183271135","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10696118893155584929015924103288419147","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.85367024312688325537143600390178185748"},{"id":"O_Dx4JkO","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:36.606Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.66}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.44656752610731358698401307053489020971","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.17277600964019284918570110281685746661","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.65843478392953887827895640207068653743"},{"id":"O_bq9B0j","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:37.534Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.54}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.92866408024505903755158085388315933265","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11123169676271348563850381194956780893","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.29709204954855295035286582259611327259"},{"id":"O_LP0jGY","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:39.423Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.58}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21816129098022674726002765296771481656","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.32029132620991642431169604415860028262","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.87961592234283235470180352098373903227"},{"id":"O_w20KNV","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:41.619Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85256139166896878057873194342438509375","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13082635635946250238295616105715281990","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.51145658206066775474338150794318893696"},{"id":"O_X4Bo2o","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:42.652Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.31}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71857024290319877004765559302285850875","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.82143746401988762830180736819684501066","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13122017680121271123240572869112063343"},{"id":"O_aNmYP5","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:43.284Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.8}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.66552103834543398623260130454288369564","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.16479179510542439841952168708095688369","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.64929578593637061384442877480368244161"},{"id":"O_WoNKqd","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:44.038Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.62}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11135062509982139033722073268687429401","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11073310562827980008705383215782154194","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.39420112939115840843272486080640648194"},{"id":"O_PZQRzD","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:44.819Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12393523103905000406305547155493372826","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.23263182853373600046028227895682520659","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.91281333973427971296846863999784095940"},{"id":"O_5vd0PA","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:45.646Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.14238834685528243427551869594414323154","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.87536582607913867238829603876761913076","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.87759481927176979153816177086442782426"},{"id":"O_Gg2ZLv","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:46.563Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.51}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.62609378187177386044343929558354641423","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12079268707035787113839664882696312967","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13157548824213571213070193958861770751"},{"id":"O_N61eYN","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:47.568Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.45}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.97166254503678497985697723887044072179","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12604056698163519107600004881767659284","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.17180619594881258373836845503094814405"},{"id":"O_YgJ1j9","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:48.470Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10485917432429788472580042580580580010","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.15956124641511698605024823290286880992","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10310304111922051392344359109797960791"},{"id":"O_BQYBVp","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:49.757Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.41}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13608681572837388841852726222845347807","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11811363354311528662683458962419526368","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.73437119198176528074851421730684780287"},{"id":"O_zpxlz0","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:50.805Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73181279240584602293891079622155400884","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.78458602802265623515811943291894690291","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.87607385324530557994711815306986801636"},{"id":"O_JRyqaa","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:51.578Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.34209168570004256029544604981275712252","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25808904010208205860905478860867615105","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.87182599833740405971591367488788392723"},{"id":"O_4XRmyR","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:52.360Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10253267382268765671345526238253521443","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11961208145678533338865103205318257593","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.45012300215363936083019859261260025525"},{"id":"O_gr3Z3X","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:53.318Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.72304885611206761666650332079059263792","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.53662365697922361421749966276592445257","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.95366215923977662347781114967200368035"},{"id":"O_Z5glg5","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:54.023Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.29}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10038057009899620100439590139502832481","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.85013066353573870935728663186603076400","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11758533523652448521970003804796707690"},{"id":"O_rb2d2R","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:54.825Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.84474223029753391381336896453319306066","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.49332347847380582165716601509019216931","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11874546409437933634246154707166541799"},{"id":"O_AzGYGy","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:55.544Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.36743768588217888218325958515254087142","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.28239210117880280337970681927861950109","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.54090160943383986972715050775639972515"},{"id":"O_qpAyAz","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:56.628Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.65}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13032923775098935974325286058204178304","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12563955527982764354885037010611724567","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.54770434256653158681161971588045686303"},{"id":"O_2AjdjN","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:57.936Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.40790757849688405239694915002630208292","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.37732559974878000679359932676809940938","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10454445965393075053843806530969937618"},{"id":"O_j3XqXd","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:59.035Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.22}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13724246864315224052812927542186848941","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.32580303838979007839698745366788248102","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.41572951576287103565942148136712661521"},{"id":"O_M1KMKb","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:45:59.858Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.25}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.53554350010870854136629850303645841959","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.47018998702284333951239855175259039337","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.81773446419371813965106750131817474220"},{"id":"O_eJv4va","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:00.583Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.57567968135683618687351498772927393130","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.76154802083752523232365640930201297138","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.23726856850597723904893647782283276819"},{"id":"O_OexOxg","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:01.482Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.56590224054631827659371714020672077503","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.43473824225538594133800479888288920263","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.71161135431269875363538317608087322258"},{"id":"O_R0kdk3","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:02.500Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.51}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.17235423704436097551033150571011641368","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.23225069536503796982206842498169401102","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.85469216103945434090645102023260076992"},{"id":"O_yD1P13","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:03.750Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80708824757928886775690614782304881714","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.65121464076265183663118238154307257376","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10097441553921183391365632797529595953"},{"id":"O_dylJlL","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:04.419Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.63}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93620857167467296013973886667895641763","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.90518752331127029385961496118224866060","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.32950945268228554615354402716562181242"},{"id":"O_6Km9mg","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:05.207Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10649123533840364698238464433715469078","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.19692546765301079445229202553157559988","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.33681747785625876835507909744129428460"},{"id":"O_mWYMYA","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:05.962Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.7}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.72318042413542606250114036192448862563","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.76723755729885860004159291928833845298","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.55837313073240307515765055796456973627"},{"id":"O_06rRrG","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:06.661Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.56}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79116045241778631337851084138825655456","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.30248939330814204575923658425549701186","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10138960580852846459549326905198724421"},{"id":"O_9Kl1l5","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:07.520Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.38}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12995850359694827080453463369559331557","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11912325621000755281238529497288173468","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.23314091891902902181742431522974722154"},{"id":"O_Ky626k","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:08.429Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.25}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25613212691580359756890914532753630818","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.65089640380470659329383787677107409691","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.81967818507078668470140981098020519692"},{"id":"O_oz4O4G","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:09.209Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.51659476997821693666730480646184150730","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10605804308367732784455402589130240319","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13322622031542092421115546772084065306"},{"id":"O_1VqyqB","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:10.159Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.68}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11164625109303416757661899254162144137","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.66251603309948465002166563150117893127","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.67572359123152474559482246676024190393"},{"id":"O_l6GjGy","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:10.750Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.13}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85261187800780141322768582217787299774","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69702535886703969681725221079395605030","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.34443545307031758498784214941157838926"},{"id":"O_x5KoKv","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:11.427Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.31}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10483780139520388432767085374994267319","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69687943965820396675693562431974474377","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.42480579918815113950865412325069977818"},{"id":"O_vR696e","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:12.209Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.27923801890829673594303099819797465748","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.97064736470971301070130722981121685172","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.41290954188742564941808974768317330795"},{"id":"O_QLVyVw","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:13.305Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.4}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.49718226519486957013804228040520217700","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11088908166672740030529241106506330815","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.53098776399954336457614796192995031889"},{"id":"O_pqZRZY","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:14.366Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.94775066503971484677609666694146987407","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.54103607543800888549433145758668238725","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.24038468635566136088374971877204077360"},{"id":"O_VP595a","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:15.206Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21132361706015758770437397882646041526","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12827887963092779134007346379554849742","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.55613857247278945661276878240058412502"},{"id":"O_3ae6ex","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:16.149Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.89635633611188763143443269322395463597","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.73440973263245182554152826703281614241","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.14983916526131099797515169236276713550"},{"id":"O_kkW2WN","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:17.224Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12772141535050570738466705205446727453","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11579994920526146358856021916602770017","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.23072826594896101067612595486527952387"},{"id":"O_Dx4J4O","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:18.149Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.17173546323937767365117126310911196186","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.80967421523909533809431059523119939796","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11569181802943667928318783776165638348"},{"id":"O_bq9B9j","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:19.018Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.11}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.35477962850842611325700055089911936925","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.49813095176153471774602535368712292090","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.18343091092019153199034769849998622075"},{"id":"O_LP0j0Y","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:19.740Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.39}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11198832828331639461919093925236014885","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10309458601242480829559208682849675650","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12381138628765222718787396636287657551"},{"id":"O_w20K0V","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:20.905Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.70784585704842865168097484838235520254","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10259500859058821975259891827661554217","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.53311446969491157431140755095899581018"},{"id":"O_X4BoBo","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:22.056Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.79}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75477508361854394690726148299659792201","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.70749245233141947914705971090364732849","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.22163814129620290968985467912781990758"},{"id":"O_aNmYm5","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:23.361Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.94830495021084799903389062871168331615","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.65890932040180961997039870991662056948","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.21207053008475359773425475080684720172"},{"id":"O_WoNKNd","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:24.204Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.04}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.95141296038681961810341191108604131230","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.44663603908702294794924360799494303526","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.66143756183238932866480951512050350356"},{"id":"O_PZQRQD","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:25.204Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.29949963209101918695616385450393584350","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.75540768840813365868581976786520917946","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.78271346363801001739036492086903619451"},{"id":"O_5vd0dA","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:25.976Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.47921467984941546304647325624027641826","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.31469136352460657553721802819993841250","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12083041417284035868842324951230383918"},{"id":"O_Gg2Z2v","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:27.208Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.67}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.42213976358922013178414277787367086723","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13343862824097317214821816225229810641","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.74843543522489039207978344131266512484"},{"id":"O_N61e1N","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:28.407Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.49283050650370045696542560227429084866","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.34061654164171464742419850105869421182","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.73593583224706175032341655439787943948"},{"id":"O_YgJ1J9","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:29.206Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.38696918948180699134767380212796372554","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.17733489087471838205891871814345426963","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.62005405689358971057196490786572604774"},{"id":"O_BQYBYp","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:30.068Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.58}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.62495532585226910407315348000002810409","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11405886264456712263267303831611135208","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.18273109306781570944429620783280443629"},{"id":"O_zpxlx0","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:30.931Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60418824225914808230042331250041780756","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.68135825560838137216316961994762111739","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.35090967103745446342394970312024721290"},{"id":"O_JRyqya","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:31.682Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11930344697933749852196158376251264209","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.40134412497179592258282775065994764643","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10065118652515481682658127710444115798"},{"id":"O_4XRmRR","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:32.469Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.51}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11146032129881577011874756003168729450","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12660792675524625126211545371291540509","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11412171199778829830383949447760128880"},{"id":"O_gr3JXX","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:33.338Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.43807116044199121438931937341837226666","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.41935419380524176144969283365686235558","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11755857314882904159741369051343719608"},{"id":"O_Z5go65","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:34.226Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11439761491260138375427916273108390534","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.43883584524449180395184523696733397254","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13529043887569324260544715492965666784"},{"id":"O_rb2OJR","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:35.031Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.57}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.52815459225726718410102259687208386159","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.79385275981967082128430519947393282685","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11062755275214594140901322385343962888"},{"id":"O_AzGPqy","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:36.009Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.42}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11024116241144701260606273216410359420","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.24357947863121378124502292348283106892","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.34313937514122315106940415523074146274"},{"id":"O_5vdmjz","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:36.929Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.59}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.81808136859620043073448891701148743203","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.86160100009480498305938741133154460615","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10701002683519008420297027419192593541"},{"id":"O_Gg24Qm","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:37.862Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.53463294955894998327785993824375788640","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.34406499298674216768745190154041849847","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.35152277098566360248629787699903085195"},{"id":"O_N61j3y","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:38.622Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.51}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16634533869968662316916023519915825664","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11738470482527309210323862653414508250","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13060249074177146195246328710120828815"},{"id":"O_YgJKYW","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:39.447Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.55}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.23096728411934483288052896587301039585","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.87173278435362297525973752778545223145","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.44835750530161981811004352832463260425"},{"id":"O_BQYNx2","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:40.525Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.48}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12201135627267172124930298373299468322","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.92024662793101574644925375465795683445","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.22321421111970421941007867026837419965"},{"id":"O_zpxKNm","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:42.114Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.51}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11499688846838445938719370622798986147","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.61798572269511051029404247884859966140","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.78201281481754589335875078899366874105"},{"id":"O_JRyrA3","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:43.956Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.27731524556596512314958263895458255078","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12352213128971319555362552824723529338","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12584769809379617695290038567040451179"},{"id":"O_4XR6pN","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:44.871Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.61226597695477970385263918743277113520","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10652528049526411300224590052357893345","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.19202580003235956126389459243786164398"},{"id":"O_gr3JX0","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:45.713Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.32029308943673693281458379486508103186","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10624010412425635613624867409311031134","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.90623612470435094834707799003235320065"},{"id":"O_Z5go6Q","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:46.760Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.33}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.17998633499199966097100826204557645252","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96354302192485360800106062396531926213","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.73288936971700673745186688387135619566"},{"id":"O_rb2OJN","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:48.324Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.5}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.68532479715136923151798323246554586024","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.50293057033730232428343647555266266367","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.91722724309200196618746423358301951092"},{"id":"O_AzGPqO","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:49.207Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.77272656307938248798960033178921854484","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.30797785655493486007346824463382923867","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13300383713004155861975602274132300977"},{"id":"O_qpAeR1","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:49.941Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.29}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.45729633253372074463525706160521519912","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.58356498941006840433833987277130000280","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.37707355233319179691385523473951620670"},{"id":"O_2AjyXa","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:51.019Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.11}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11209160392598761547660031266151602973","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12306733110323885941555727811855049152","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.39848689288735978485208579088413865926"},{"id":"O_j3XZPj","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:51.945Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.14}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48335674810817558371588816282729034633","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13079349471314452561825640640307276509","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.38074058899288742914822748112579678066"},{"id":"O_M1K2RV","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:52.667Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.28325218614026062309405249972608731665","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.33756188444097826604058436440065342151","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.97742517099492086940378558347225764825"},{"id":"O_eJvBxq","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:53.400Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.04}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91441827783598865420337615221799403565","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10102882891967657723518706090549504979","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.76332607221416451798435505106287195438"},{"id":"O_OexMmP","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:54.323Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79633379515969915028297840138476891738","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69750544737923530726785673384605313666","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.59104713991738647829843995257643385888"},{"id":"O_R0kRQN","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:55.006Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12842779612931633380636708157194840581","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.54274864198027187586523501131054764232","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.43137220035209005736945468487298192662"},{"id":"O_yD19Gr","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:55.862Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.51060347547454219628821978895140686447","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.63219634327258645487686988278041997504","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.14229191023553343677980075087352217061"},{"id":"O_dylYzM","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:56.975Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.41}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.31060202731175039991227548165329478684","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.63643751364085432783394238980767737507","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12509084345702942437665854873022380045"},{"id":"O_6Km0J5","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:57.729Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10883199542847308192684203089176494263","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12134485255065264322671158840913354018","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.98424505819453461279990923244251509312"},{"id":"O_mWYqXw","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:58.539Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.16}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.22139771314029498055177920517164045395","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.15650537427257624767172743156579670819","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.48209363894952809521008182700669567012"},{"id":"O_06rO19","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:46:59.424Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.52}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80822167935657771451481208176509564321","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.87812830794542978928180777490562205922","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.89124482199464685015361454139755580072"},{"id":"O_9Klo2J","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:47:00.251Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.29}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10534436658757997525104024176930298873","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.74993440061750532029535130420056287152","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.46115606911518525615710558688063589293"},{"id":"O_Ky6ARd","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:47:01.064Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.70378448052022113805084699086050912245","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.80978109479538233272559562055776016301","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.45416376575720809560437969274163515968"},{"id":"O_oz4jRg","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:47:01.867Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.7}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12924077579550617491456328336599316853","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25661974517214006202901337899203830529","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.17011494904764660024784500769462959320"},{"id":"O_1VqR6j","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:47:02.718Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.61}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11022711610487845302396300293289900291","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.83438218446753310621291393317929484668","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.19290564432788130491658475567644525930"},{"id":"O_l6GAOj","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:47:03.602Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.69540398944457244073015123988486143041","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.28215154050451491207513505927502488450","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11803761922731279016903173025094280410"},{"id":"O_x5K0P0","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:47:04.824Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.48}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.96322445598853397273434599662359793736","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10237858298717097915104207182782506829","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.65508301432378637709916986488270306275"},{"id":"O_vR6PdO","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:47:05.633Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.8}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.35042857868068387620588284736083754265","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.68260599420568164638256509461995229952","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.16359251071773613545833306800194538990"},{"id":"O_QLVO3D","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:47:06.426Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10544259713393837462153269167511008844","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.68780038099429798355701695358557432717","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.20804836044082541051085537043389550497"},{"id":"O_pqZMpW","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:47:07.462Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.11}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.36270850915012667676354399931321669825","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.64395797654026900253320922759682799038","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.30663987746305133071752409283504676277"},{"id":"O_VP5mQg","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:47:08.436Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.59}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.69955327875037516626102821996107076828","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13499664746755324363497801274695631904","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.64447836327983511756744116073385372131"},{"id":"O_3aedp2","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:47:09.573Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48424830583356042442416691172975554279","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13137992315329075389079396436122794973","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.68585471736981921375588500388473527033"},{"id":"O_kkWrqY","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:47:10.528Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.45}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.22677699159307365544525703118737850694","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.66850143364220691211155989624936861492","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.26202070357902526244172340068063752019"},{"id":"O_Dx4BQ3","modelId":496,"modelVersionId":831,"modelTaskId":1575,"type":"ANNOTATION","createdAt":"2023-07-11T02:47:11.507Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.63743700654110698203689222987028310037","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.87172207030180643925485033782861632984","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11996071167351057677048462005020548764"},{"id":"O_9VaGVM","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:11:41.562Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.41}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93303890736000372712007719325496086506","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.18933131084705356884804381455040439979","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10246470900314949112774779858606715675"},{"id":"O_oaQGak","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:11:44.454Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12672963102145562289556730996924191933","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11490451502697619568913745270109712744","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.98524239922985237506822834835772680167"},{"id":"O_1mOLm0","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:11:45.565Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.41}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13225278160855776395459576364479610926","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10096646229606210096083716017760432173","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.45868000707182667687966934029758973194"},{"id":"O_xa3ra6","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:11:52.044Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.57}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.41584070234430372173765420238622114497","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.31826698412661834262339279169645209451","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.15781680202415329471961514022336248042"},{"id":"O_QR5XRV","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:11:55.630Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60417888430254618877950024443204458533","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69047852066263357259921465594099063561","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.20922878054271870966514899514445780327"},{"id":"O_pJaNkp","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:11:56.801Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.65}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.34474459139031442853950131741108777705","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11054813231011644849954786938460768772","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.51664194736578964583365212788765505610"},{"id":"O_bYzJAg","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:06.599Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99043702482538143920588129740411594274","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.41296222598996201764137126287695545351","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27368894922558052521136085756674613278"},{"id":"O_LdyXLy","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:07.629Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.69}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.37086773353446284773343305804355244033","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25504309998170432288325714639898139564","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.85498951216142733027403015634981447711"},{"id":"O_w6aZD5","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:08.652Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.61}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85863003054521018766410592665108460266","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.33353809230574917955127457223438803138","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.82491352139116858893948745915794673159"},{"id":"O_X3pXOe","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:10.138Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.79}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80391050361565627485212451571511025696","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.50818690366043584412449896049120052893","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.14245365400130544363943976862759981972"},{"id":"O_WJMXQ5","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:12.194Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.62118485175692420624795168534752720704","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.92535670121750964997127013584522641352","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.43675707932226204557614276481808065118"},{"id":"O_56VLoZ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:16.021Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.52}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21002115141957150748930841566364555389","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.36071423266211373286935864717520233130","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.99121928847891260729185171760356813608"},{"id":"O_GR1Moq","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:17.087Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16200791959753000368045520417827643884","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.43805520248639652974150105177454656607","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10938257119716116504763784338743476385"},{"id":"O_NRyXLg","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:18.550Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11966720494012221530810110357385190394","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.37674556826305313919134814226868085489","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11393809490237521859180218293619593731"},{"id":"O_J1KXkX","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:25.232Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.71}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.88194215698435731274339148094525478530","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.90420738963877449569630462422677876482","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11535277798648419691039880832660825724"},{"id":"O_42vLx4","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:26.282Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.7}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79354614957179736401305033596760950615","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96993045450219906823069392214070547160","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.72911556529236123897149045055705600678"},{"id":"O_gYgAOj","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:27.421Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.7}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13174698018038694457989063228112812057","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.80167156419858945241544136779618781195","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.83693387504209685519843226597037641407"},{"id":"O_ZBVXWP","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:28.321Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.29}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.83839371612285027689003767776763048874","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.23371623908036063691186464287385623757","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.73673904472681674416881067950208762932"},{"id":"O_56VLoe","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:33.091Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.31239740291001233741518144994772499937","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.87176998758634448044544074239265966551","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10080915976742060510467597104574525029"},{"id":"O_NRyXLl","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:35.822Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.8}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.58800234986092969914664533385227251763","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12107791240269769285031008746359707083","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.94505907225716746667228616929116530847"},{"id":"O_zDjq1k","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:40.397Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.34}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11742590162883175875313569897624549552","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.75366979216310481072510256303631173633","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.15920889430824388281261828228438821995"},{"id":"O_J1KXkG","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:41.373Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10452841293564474734596795955051241595","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.64084061604094120653895727153609840018","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13142206345544355701721261741547213782"},{"id":"O_AKXZym","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:49.249Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.11}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.14601225381216912562015187533504378930","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.71215887896814391983359601432246088018","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.22531274325370344844655522842850992018"},{"id":"O_MQdXLq","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:54.958Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.59}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.66714858276602326840716030031701387403","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25787584734607648992846677997225654240","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27828248411309324213682653629163636974"},{"id":"O_ergZG1","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:56.300Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.13}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71818230964448383520869831871740477137","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.82361768772950537728395568849043085858","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10265027780464709418481729507830875317"},{"id":"O_RyGXa4","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:12:59.325Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.62}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75745691882473550404320701186704369619","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.59014790384606378070085323496289392716","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.28219548975553795025985411050189332134"},{"id":"O_mPyOdP","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:13:06.168Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.48}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.81723814540481517155985033223263347681","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.58233199964239845938296376506133264789","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11085120079835306365391562000259141695"},{"id":"O_0pVLea","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:13:07.391Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.74}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.27082736737155301713931176384015269927","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10860201126926665433580896573363442243","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.81806739807882296432081966127449913219"},{"id":"O_9VaG33","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:13:08.579Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.74}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11246358655889974431100828608162118475","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.91489889384464651956915195105586804452","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11882794108790840046371840696667858615"},{"id":"O_KxoXqe","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:13:10.707Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.22218224902210395057541058899085307466","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.95243867697103445238216031505700734838","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.98122999398331283914494520137442724726"},{"id":"O_oaQGdQ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:13:11.624Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.19}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71853771447159478340450787452774678194","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13186421011895497478954122190364415328","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10017867533548153747532497999753535032"},{"id":"O_1mOLQ1","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:13:12.689Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16315487813988430812442513983202308536","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11474507952560515988794477890383486515","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.88970940169374082821043033183053165553"},{"id":"O_lgXexa","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:13:13.683Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.43}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10309035611505216862280722450541246232","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.16213998524616414013702809656675880276","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.50544220449549978956833983792017581668"},{"id":"O_vDrgaW","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:13:16.866Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.49}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.81204283658079390355658813400263341728","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25176115537973378934460994435321616545","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.76678324666203475756220706198643496226"},{"id":"O_3XvL90","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:13:25.781Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.50522631466416528481899180495083771271","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.42385918989460517329468248272105082301","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.94704476797772187673353028789294518981"},{"id":"O_ka4M3l","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:13:26.879Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.12}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25715243805698149204333256440870824269","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13212213007959308019464859229508333156","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.88831760903045414620144157465468172241"},{"id":"O_DdDq0A","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:13:27.738Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.42}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93526380671520015887492535929546289983","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10005721767304978718480772202941307873","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.31228993792611252157157850013794577388"},{"id":"O_w6aZyQ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:13:35.821Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75741878950758353908459159312119136057","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.52486265608257543978440319061999116036","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.55575346266251085039046951292303623667"},{"id":"O_aABzrM","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:13:41.025Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93133103931352051484402456972107766631","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10824053040590274406004252038314270760","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.53488417959807852077074815287977103573"},{"id":"O_WJMX34","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:13:42.269Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.45}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11813670086153723206338479337175832552","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.19448540300943212103790837127528957485","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.21944557927725907440899936097843561265"},{"id":"O_56VLze","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:13:49.574Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.16}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11698655628810989540571060069864032034","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.97669330179071615862903963475056029477","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13298340086429837306155052152328799541"},{"id":"O_J1KXMG","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:14:03.897Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.29}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12871879578819679719891901907662686672","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12657148488992834772578677746864215026","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.23381370939846181007853412412272540647"},{"id":"O_gYgAPZ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:14:06.225Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.67}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16540020943180754370807150979085512375","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.24204921505048320465935139628168161374","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10312210881795264256469006137882633042"},{"id":"O_ZBVXZo","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:14:07.060Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.49}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.83250421635148946013153519487765464663","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12968836314273245640067990758755075610","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.95190610383006262926006802762620160598"},{"id":"O_qd2YzW","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:14:12.944Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.62}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10580530640190979687559814849138075292","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.33953834155850580445103913518867312694","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.91745256668337329458596436099891180469"},{"id":"O_2K3LmZ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:14:14.064Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.63}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79050063903915736280252381017111391036","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.59678276848040851224759355011403206500","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.79111654385317924723837090669238940962"},{"id":"O_jydjJv","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:14:15.233Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.55}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73888411782440722561759697580614855237","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.98204450747876117024804960884542660990","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12293403773195911843592382511702039775"},{"id":"O_MQdXjq","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:14:16.506Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.68}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.42930129259682883548149018732626607715","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.86631893393554574180761603609010258877","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11743366893897588685865573913454870435"},{"id":"O_oaQGYQ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:14:34.071Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12118847365011015605577712214572748362","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.77728863974209631696222971513121379029","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.52992034446854865578542841618408723227"},{"id":"O_1mOLG1","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:14:35.329Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91308826690545525860536682324342833963","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.29039333521885472159126513151084009870","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12735379275548833107390561285864827065"},{"id":"O_lgXe5a","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:14:36.702Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.61}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80644694338549900893329622765508569613","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12788228873601239619796127903668763309","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.71716263199124676229159869929158875557"},{"id":"O_xa3rNd","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:14:37.623Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.15759500103559442402170040073604275389","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.72586423663378593077643116249468820298","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11083885680040837201836943833099377862"},{"id":"O_vDrg5W","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:14:38.467Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.05}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.37481052888009201018744280876499747199","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96876074358067414504721273285702630272","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.82145141848899269885251546758736024106"},{"id":"O_QR5Xx2","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:14:39.889Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.64822063358332988570658054393010790703","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.30610375315508762889093026154499822526","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.40079301320894456412018365670485244716"},{"id":"O_WJMXO4","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:14:57.005Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.54813256783534721433738579210618545553","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.39674660399893628916072993056960804687","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27544197238006600533326101135182607622"},{"id":"O_56VLKe","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:14:59.700Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.29807737968305150942312177305644885461","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.29097391730926934051949708983048977904","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11679973001512875320227789007313688739"},{"id":"O_YLOXak","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:03.559Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.45}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13804204137716402403051597553324660220","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.72112013191909574272550789892506252726","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.26229398495758888643104039387809388278"},{"id":"O_J1KXoG","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:09.533Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.24}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12908146249849039920696415050027251666","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10661897929718065158486387010660138735","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.58776135274242633369950600750547980022"},{"id":"O_ZBVX3o","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:13.428Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.3}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.40344696294075300150160062065838404588","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.74081199494998751148122642849211336715","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.67265802380419311547634205841088794736"},{"id":"O_AKXZxm","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:15.437Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.18451356275334181906363016167640641404","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.34059071045204310029405237880515168365","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12350461038454527639815577279110964583"},{"id":"O_YLOXa9","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:20.426Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.76866431241353372048397727730980991944","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.89068859028686738606250960097109556160","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.22647559013018053834720695087777100905"},{"id":"O_BbmrJp","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:21.325Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25162057972473772604388654527530699966","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10812733082985064837902997994614511715","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.80922014075969895930494329681174351244"},{"id":"O_zDjqB0","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:22.762Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.1}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79429684175445665349654548365684962300","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.89285989936669975575370285779211657350","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.52616383798646697772684725581381883719"},{"id":"O_ZBVXV5","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:29.401Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.41}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48786793299166551538312254431695656485","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69657075748860896083813103940156853933","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.31381953373007667698017879180314152742"},{"id":"O_rR3B3R","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:30.299Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12511642292284168409350105164084473905","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11160240470202434592122247090643647067","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.47034531066281080749915443657307786118"},{"id":"O_jydjdd","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:37.071Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.1}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.64359000099559658156498587464389062687","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.79144505378977886598368584444379708741","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.43260344447559082999522992855844744194"},{"id":"O_MQdXdb","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:37.921Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.39}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25131591387333975145518022057168554543","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13276465698620724043087635931978008476","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12733663945463671304358997194184623832"},{"id":"O_ergZga","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:38.791Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.43}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99297510164340936941011196622063805063","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69959497463988290620944485354375794223","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.19187351667789952444397332028023902886"},{"id":"O_OL0X0g","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:39.735Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.83220965703804510231551105964284736952","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.30924747754932728097349795555323724644","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.17674199708150135342293355721654948373"},{"id":"O_RyGXG3","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:40.635Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.19}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91475997214512458849971662159446837815","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.52492540355485562030805751941352674033","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10685588105864847630972365330623817549"},{"id":"O_dx0g0L","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:43.125Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.16}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.43415918011096851369689698310969695299","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.54503005577893891240009328398439324755","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.43818208008522492465988168354756988060"},{"id":"O_6vPLPg","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:44.542Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10269398163012726688315139227627302744","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10504141411418594326014852763542092601","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.38780043051639100183160295965106951877"},{"id":"O_9VaGa5","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:48.227Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.87960338353760541562113659603656910934","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12926098564982604923868094385027597664","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.40227315463048490029054205138190565433"},{"id":"O_oaQGQG","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:50.060Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.56}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13062978036211561299069240064005267195","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11796853521684328756800169504528457535","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12872851715966853582021496274529141408"},{"id":"O_1mOLOB","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:50.841Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.34950116445822285169471448253491900507","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.14316263092570419326730100833459031780","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.70620192896372613680670112041432225345"},{"id":"O_lgXeXy","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:51.721Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93941794702315388207128045230732635036","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13072157702480839318098351383917171317","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.92177106457861773582443143505905627201"},{"id":"O_xa3r3v","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:52.494Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11297946758809153178514148072457428420","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.32334981761562751519424822050343597419","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.83881405041527205877794427805142520176"},{"id":"O_pJaNaY","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:56.457Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.52}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.37098606298536122843303719722803198849","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12153857980808732008181898302207999570","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.87027853787228120806988862994451650105"},{"id":"O_VLzXza","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:15:57.421Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.63}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.76539434935930371049849985067098053711","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.98624793177010059126077715732272779191","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.46482349274114195761286693463095629575"},{"id":"O_ka4M4N","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:16:00.356Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12201198184926121975568236806981099253","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.20529083675488674694804710997988445204","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.81488598041954777579013767895252895213"},{"id":"O_bYzJzj","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:16:03.774Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.66}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.44268840829728327690174755499587977150","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10725784600827670385514170451367277784","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12315701044027260789754306983217509251"},{"id":"O_w6aZaV","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:16:06.625Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.77431251709614638982573510124749768570","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.29886907450887482326498130466530147158","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12339446307314663662932117298407284094"},{"id":"O_WJMXMd","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:16:10.527Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.96259627320413423901705795066155407096","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.36002200496628321611478352403573808048","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.15894711920364203149789126882456691260"},{"id":"O_PLdXdD","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:16:11.542Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.54}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.28961310214302326532231273556877912120","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.64218600427569471684140981202756923627","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.45171851074625271612917272479838208880"},{"id":"O_56VLVA","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:16:12.924Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.24}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.65111635762834508920120131926467516731","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13080802737789271334819065432255256759","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10312258263964264497883983774164318566"},{"id":"O_GR1M1v","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:16:13.690Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.88}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.84996660472077757264400804144701261050","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.85797462824663766964838414854685451251","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.47500539876671104581035456353543062404"},{"id":"O_YLOXO9","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:16:15.699Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.50209215340786337369085202922466155147","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.59126089130886178007157196196483643211","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.25165366551658319227917212240774392691"},{"id":"O_rR3BjR","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:16:26.735Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.48}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.34899468821995656624249813465880267896","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.26660052438273712680250869994162085498","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.56050836864844387782438011100811790008"},{"id":"O_2K3LpN","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:16:33.220Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.29}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.58757263665798274122180347059712236408","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.80169978925264731492852313825304185980","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.33285116849900775235184876805243180007"},{"id":"O_MQdXbb","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:16:36.299Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.90401611779604220642086223349335055661","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.34542529879558972221134475918625391779","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11444413538279419876382261605855279672"},{"id":"O_OL0Xdg","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:16:38.709Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.88842813133748485146442360220032193831","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.37510179716281458872685925765007432224","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.32795861355963929406885408361380028244"},{"id":"O_dx0gZL","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:16:42.360Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.89}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99162852402972082368083425716890299707","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13212168520628710342556415248377814767","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.87597714396599607877271988748779579868"},{"id":"O_0pVLXG","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:16:45.485Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13094296533556721353726131965937007684","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11302619727731756036016107481256214434","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.42977788964245111023830307511616043388"},{"id":"O_9VaGw5","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:16:46.389Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.90175357630909062691702607095230942872","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.33460607807813112990584240571205796252","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.44663800731226855034727106501219699798"},{"id":"O_KxoXKk","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:16:47.881Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.5}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.82065800443370343732726326749808666975","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11886097950238604345954439735940223394","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.98454738005228110196748317546811590412"},{"id":"O_oaQGAG","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:16:49.056Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.33248311764250609252926415301703405650","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.61416628421908271691044065268495311627","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.81183098428569496474218421649007128461"},{"id":"O_1mOL1B","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:16:50.050Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13153704474817987985539323125113701197","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.36303508305751776940619692018596872477","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.31611382225292940519464648047877638856"},{"id":"O_VLzXja","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:16:59.172Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.38}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.70163847492682589321424188470614095156","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.92186459553692179661557671424499226847","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.18531836611750810055293299946438226200"},{"id":"O_LdyXxY","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:17:06.343Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.4}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75113413177483704844125514273651708901","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11320611754177743647250219409498780523","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.43894604024376893052433762608916158890"},{"id":"O_X3pXRo","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:17:08.559Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.71}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.51223279862332025344440174436424220303","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.78004707093108031396780690389560263087","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12799854955697620810086553004209227900"},{"id":"O_aABzX5","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:17:09.839Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11881517514314984013505968608624811672","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25706003650900850109658072065964140763","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12702146740395881867916994790738276321"},{"id":"O_PLdXPD","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:17:12.754Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.57}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.18737969147487548994528315487336380564","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.95710141164109815944557873007739247632","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11700288880835974639757293982381566922"},{"id":"O_56VL3A","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:17:13.828Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.04}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.62468794464308636797243570442447095618","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10131413975140930064567288758132496130","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12527527616473200663239944820561080335"},{"id":"O_J1KXja","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:17:26.523Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.52}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12479133383470513102715792657006746262","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.88954019058913277783394879494702989540","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11658264657794361727992896100404915523"},{"id":"O_42vLdR","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:17:27.862Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.4}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10529044756004527076757439580685287766","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.82044617469319871415061168944100534855","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.83565935910898514758299257062092254916"},{"id":"O_gYgAaX","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:17:28.657Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10497713059263035954965182581266888539","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.26997946909122595426316372198199315482","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.63688259922018846378994890425983442055"},{"id":"O_ZBVXv5","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:17:29.841Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.51}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12682277268613188167675770310610936624","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10791598616881205091880395746425724231","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.62691871926223409038742665255078390154"},{"id":"O_zDjqbm","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:17:48.590Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.71}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75439006953555576665256539968831756533","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69775536458535955328230407490889337396","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.72197706717891933392641977651494786167"},{"id":"O_J1KXx3","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:17:49.437Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.61}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60606429992424202487876507733605601408","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.61353465653009435518200770785302186044","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13194670306626300102087561720216881327"},{"id":"O_rR3B6N","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:00.425Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.38484580092993348038032018087013585406","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12285805611440164678966426226891822009","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12360767292998185276834343996442739210"},{"id":"O_AKXZoO","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:01.347Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.58}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12730579577831327046368885397724528288","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96871842545249272576580228033920038566","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.90684384681788326540106993763643008716"},{"id":"O_qd2Y31","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:02.282Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.62}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.46584954119885956346283994543091210633","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12806258389809440381470082347457821369","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.97570142858796754887773417999621723731"},{"id":"O_2K3Lva","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:03.171Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.38}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.24404624952910736149480600150644684178","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.44428283512211118396613564930179951421","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.19570689866938454001754644164374234647"},{"id":"O_jydjaj","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:04.240Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.4}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60251934293149073128966912026521777543","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.62818116722393383875564462638217675394","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.70798079585871997447182533756164563656"},{"id":"O_MQdXWV","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:05.635Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13142499132576174751026176218415717532","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11410971643551531169364842122878863808","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.30644773733532981072996325523676815925"},{"id":"O_RyGXWN","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:11.762Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.61}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.77600828108265136899372964304097233849","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12146015871021696722297573464911142551","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10917706989225665527097065900126833003"},{"id":"O_dx0gaM","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:14.946Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.88579772249474829401016236973636042347","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.67323156910509147705849737750605272894","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.42729716943102628352022695870663394286"},{"id":"O_mPyOZw","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:17.497Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.31}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91179334808756844348695469309051980050","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.93889319426957474700427637761964462194","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.71029581459045668335239451458844941244"},{"id":"O_9VaGpJ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:20.075Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.42}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11769359540525537862874431576018276479","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.40362292845471183478400560900415005751","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.31613297892706864341945546931331496009"},{"id":"O_KxoXWd","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:20.986Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.74}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12827574064170535149289119484389162571","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11113941702320848520564067133854769152","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.24123426154386935333277625097419059060"},{"id":"O_oaQGyg","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:21.982Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.33374207865203734098454680982138894732","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.28229825516603199123037604484179305229","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.17859443470451669661873629697841829465"},{"id":"O_1mOLvj","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:23.049Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.33}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10706026263392395059870653011398151394","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.58707660628303916929605798843393046908","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10307871077826160963032444889811570024"},{"id":"O_vDrgbO","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:27.124Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10769802745724450538643262948787807073","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.61898365462679529570679398903840089515","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.63849716241579032379793224416689506295"},{"id":"O_QR5XWD","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:27.937Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48667702885291445669902507988846325851","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.61546264238425067438419579932884380831","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.51649105735509493524991702277682468034"},{"id":"O_pJaN6W","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:28.657Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.77}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12937577782669689946792277931916931847","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.24745572748056656554638983705512324168","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.93727297104310701506265179330934964862"},{"id":"O_LdyXWG","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:36.497Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79087809092238002623414337728291348333","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.79155580760095429680355517181351396281","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.74957617785016882560866007973079904131"},{"id":"O_WJMXWJ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:42.160Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.49}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.68048203751906038711439044654305312009","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96683965991413556517539786496577813021","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.14942244667920770426526099350730007768"},{"id":"O_56VL5z","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:44.925Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.54852509763302463318412066454050239480","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.79059902944920413162332104423847302422","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.28566568119994507370260899087096257440"},{"id":"O_NRyX4y","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:46.750Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.45}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.19579800015014953153712165445061942598","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.74720266034929383380902143834065433710","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.25631993807605768864828641298209466807"},{"id":"O_zDjqmm","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:50.776Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48553968299257092382333406848470196004","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.54740071790218219525858991399401644643","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10492701122176645879257973760898021741"},{"id":"O_J1KXY3","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:51.946Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.43}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.82719303693401009244066209414579378801","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12389241030840346656769636896532765979","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.55621025035482105639017781889716578258"},{"id":"O_ZBVXRQ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:55.783Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.69}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.97265661054012677215681885343727534286","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10072256251710375479882483398276251460","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.21207036834568895023612315322583346240"},{"id":"O_rR3ByN","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:56.809Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.61}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.31824021375984433881579660270589439380","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.93853616909605495368030565570868312627","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.81242585243272779877179488078702798980"},{"id":"O_qd2Y61","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:18:59.384Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.13}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.94277542651599649459532805564866357367","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.37427394919184988501554240379996756732","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.80727693452877744864023734257559756696"},{"id":"O_2K3LRa","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:00.497Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.61962703328727659180847366388601957939","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.97508266180513083367297604509227178338","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11711324968115108213363469774380988867"},{"id":"O_MQdXJV","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:03.427Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.67}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.14010667492459983467337785065886658237","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.58223132871141493068873986663555405677","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13402417959980311689979567992448622957"},{"id":"O_OL0XgP","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:05.576Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.22}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.92422104028398384503428501981774487624","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.81675394398366788008268143743809979315","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12284642363774000727055070080159125428"},{"id":"O_yM2A6r","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:07.935Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.71}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13669211337607017981135488365255070200","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13263793471079234484019821829266732874","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.32759538073958812810008298335281777273"},{"id":"O_dx0g2M","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:08.967Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.51}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11538214069155744425062700188294255086","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.17795313782857909614597916818695616656","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10415279613063280844252277506887113171"},{"id":"O_0pVLo9","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:13.021Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.54}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.58728885604757549800793485205356758691","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.17050880258272989436711932669119999219","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.71818129558084510077091736476252072900"},{"id":"O_9VaGBJ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:13.977Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.78963154647708005973105912285763136687","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.30075707003240503965346093776553288761","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13309905625719845152456832473600155197"},{"id":"O_KxoXBd","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:14.998Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.29193180490340351330488027813403553513","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10978719700325114788072322701236395355","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13346516044096104221521414063058356621"},{"id":"O_1mOL9j","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:17.556Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.31}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.58302373745357182898510440360766794502","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.73737134602804608267902321086605050937","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13212310548319829325919493278536623083"},{"id":"O_xa3rd0","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:21.500Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.15}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.41667346088482396870267319907856641499","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.50979853110246914218098698554380218751","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11634993898159169350260250637158185423"},{"id":"O_vDrgQO","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:22.456Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.59}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.54175083796333237627567721352293760733","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.53671982153394095431039258718686963506","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.23143380545266730617109867991071290186"},{"id":"O_QR5X6D","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:23.397Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12631759947916514385698616913359664340","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.24166425740672125645428092183316833665","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.41459355092613757764011106513758065838"},{"id":"O_pJaNyW","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:24.178Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.55}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.46957211017584351371542049611698958996","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.82042450518496381349166714917879365631","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.83129807409025758473682085735711657359"},{"id":"O_VLzXRg","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:25.060Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.59}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.94944875722528554740934894576490558110","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.70842338564548358815054720472750418590","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.42367951722213103717860214112785838219"},{"id":"O_DdDqM3","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:33.003Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.4}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.14631389727569836237422630163195232893","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.40776581059561073100445617464632247635","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.72572296692431183925721156551992471803"},{"id":"O_bYzJaX","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:34.269Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.74}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12524938704478986663841724041442866562","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.71422975025843428244155624617174822316","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.77063946077335071507164525934828117419"},{"id":"O_LdyXzG","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:35.266Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.30981152963478631799741969031287939322","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.77322961240414482813261164679739825395","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12700615086792496200623310823302811007"},{"id":"O_w6aZA0","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:36.424Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.49}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73412900563664530788354761126442465465","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.89333260068847206349632828036163468392","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.78128372034111181295469613988099277142"},{"id":"O_WJMX5J","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:41.154Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.61}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.59081729226565561429160712458722564092","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11827851707757814703070138922159402724","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.68262186958038429790374081576871427930"},{"id":"O_PLdX0O","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:42.451Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.5}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.32929637273390205850174187543181904147","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.14998736004562318309572455713728187888","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.26968693863602683216000536851772772617"},{"id":"O_56VLQz","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:43.289Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13171276746119976852823800924743373657","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.55730609830093358306129451798904484912","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.87423910327443141243218077771834433369"},{"id":"O_GR1M3m","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:43.923Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.45}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71199407480035134079530841464067493285","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.70498570832743614608090674917993212240","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.89415044782290866243773455717781724064"},{"id":"O_NRyXMy","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:44.754Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12035585989088344570203528477569727096","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11007508793040686058298429688343048598","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.20242487490457422604562815026202235398"},{"id":"O_zDjqWm","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:48.629Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.11}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75425990907273623658495595012412883940","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.78662029986854398991870004060714115944","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.38847928743298178230493616305396412066"},{"id":"O_gYgAQ0","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:56.226Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.43}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.38909950830625504104530734790341135234","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.57931672942827094694808807020017448948","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.76060864518095867161313650915304956092"},{"id":"O_ZBVXYQ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:57.232Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.69}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.98588023839700561230299299999663784051","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.81807968506931828651509128893422566990","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11790393092655686727304949713969734229"},{"id":"O_rR3BaN","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:58.221Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.62}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11661935084270467267558866209196194180","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.53835593805295173788247148516437410083","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13083516752592649876253543226003955136"},{"id":"O_AKXZdO","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:58.957Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12219301736930271960895320249010263529","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11255374717434438762349278447089545312","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27609310825495380012532466487270681266"},{"id":"O_56VLQb","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:19:59.797Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48488458571845717615028211073336659831","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.50560191979539285108092536791760662562","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11295943195864931969761384758050053852"},{"id":"O_GR1M3p","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:00.961Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.67}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.86442750468046937727434872052719147664","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.41083748052088173993443216769024115802","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.77651251606062141357571425746118450795"},{"id":"O_NRyXMX","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:01.762Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.42449797730112047972525232102285888196","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12675059948328960050147357217797698620","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.95411123458424274852093701622275165224"},{"id":"O_ZBVXYa","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:09.525Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.24}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.88410047062997336020873520458976966272","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.70417279696464844308675337351522610140","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.91987308873518318094254286440862840459"},{"id":"O_AKXZdl","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:11.807Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.81}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.49746700633481334519718578814530440980","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.78538459279421151892659600107495563396","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.94241596527689890006616882476826419215"},{"id":"O_jydjWY","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:14.958Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.56}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.68095338185768049234084661619349281458","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96273239239099631599912550903705998596","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.83856751114640069339295771506075769234"},{"id":"O_OL0XyM","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:22.824Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.62}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.96838411355026197200704816477499293361","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.27338622989398501997644528364052597220","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.71961123561106635550471144028601097753"},{"id":"O_RyGX3M","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:23.661Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.38}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12463312045291275503446638352822565223","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13356042498073572460096027847127576884","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12295240008580640787320241377884248340"},{"id":"O_dx0gQb","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:27.883Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.25}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11711264641880679039137752946957876910","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.40275198886953578807769750290388911994","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.65133786535378485481347636476246567692"},{"id":"O_6vPLM2","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:28.891Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.72100323494150989725902881038246406076","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.47735806662965822145377566472570167915","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.41713779210234352000367513666488878373"},{"id":"O_0pVL3m","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:33.595Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85833100118154502901188664566623443551","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11481873655297204934082282536049121281","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10459067354162890233926110210110296305"},{"id":"O_9VaGb0","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:34.426Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.05}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.78327306607253891678694809525141929459","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.63716452985950331406866684142151088860","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10555804932279541202208764983407553002"},{"id":"O_KxoXLO","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:35.219Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.88}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.78962764672721315171461513643477142932","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.38804904645440393974347206460938232126","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.71190102747650588624667699746848210377"},{"id":"O_oaQGpD","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:35.793Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.13}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.23335608960455499055669934998006896823","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.68097664511405574054281417343815317905","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.88353434352625305161374072518946766951"},{"id":"O_1mOLXq","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:36.721Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.56524937335200616046430452259560479663","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.49400166451901262089850685389360531380","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10442824048111674905433845311056944066"},{"id":"O_lgXeRO","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:37.532Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80160272628700154954549497860953412879","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.48677504794306243538458483410380611242","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.50295939746073240334371705564634962575"},{"id":"O_xa3rq5","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:38.544Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11168787406272086510092278742439802197","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.78904215021999668906388723472689004107","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12548874818988510170905381159595012448"},{"id":"O_vDrgqD","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:39.392Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.96334976999124079902873416682628891886","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.27809204521014597195898255576617521643","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.91522731333489671125387599926251364949"},{"id":"O_pJaNOd","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:43.398Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10542307855070644109124731911561287777","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25191527197466546806814031817068218160","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.58948986899327344524439050306140303047"},{"id":"O_VLzX3o","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:44.252Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.41}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.32178172824841351458401731463223490318","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11044426738378925637611422908589175161","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11615682729650217193223938626729209097"},{"id":"O_ka4MeO","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:46.239Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.51}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.68204626202021816934598363960248326201","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.49368245800988673289327190378357714196","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.72360969283354517355643401853300165315"},{"id":"O_bYzJpa","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:48.389Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.71}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12269813405031988146306573291603722979","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12285351624301708541046699919691458782","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.41042120233475866139205874974917489752"},{"id":"O_LdyX2D","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:49.328Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.04}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10977839262769118252333916076227719554","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.46288670687925998978291702974816941283","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.35113557194139848023351694420681458780"},{"id":"O_X3pXdQ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:51.724Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11480239365571223592709709352332313205","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12593335937591291424097458878007967394","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10322425140424628959691665575040142176"},{"id":"O_aABza3","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:52.340Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12971443830438539807041016165740929169","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.93090815267140045957463968996479199197","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10918185512497241144388554144224455324"},{"id":"O_WJMXya","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:53.132Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.04}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11665916505452990534106657555794678804","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12562613242122206568681116479041786229","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11236453231866499099784846762663541857"},{"id":"O_56VLYb","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:20:57.740Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.50498780213223959370704075229993642002","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.68510202725925249484912747698803675959","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10544251947508101784007516529528337726"},{"id":"O_Bbmr6O","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:21:09.799Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.66}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16035601181221102968053430958865489565","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.53728604678942336459421091984594538402","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11468247299893545031231175734185928329"},{"id":"O_J1KX6W","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:21:14.238Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.40864463878486828650933624660870288100","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.98980644788094566449064396672941155918","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.72122992538152108190022556159428885582"},{"id":"O_gYgApR","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:21:18.185Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.84491963103261878946370568143388882534","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13403934769590633659410796193254638204","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.87877458370669247967044307250483308568"},{"id":"O_qd2YQJ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:21:21.759Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.63}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11577439546528204106534189654361057985","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96505309448603275035527457261907986374","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.91064417580149036238079507695776534761"},{"id":"O_jydjeY","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:21:24.292Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.53}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13238001140914487889438852292587840503","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13012787920590746897362678932325412245","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.50536419187205916853475309692694565756"},{"id":"O_ergZp4","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:21:26.828Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.71}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10901603438220812509119220647864587345","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.47897298984452106766140632829916531416","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10847807478230227359519260643043517778"},{"id":"O_OL0XQM","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:21:27.534Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.81}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16924946062905126532699573983611182176","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69986601751064410771663838041659350202","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.19609911609425341761396710006967517206"},{"id":"O_RyGXpM","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:21:28.362Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.82237732694913834213318951313079504884","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10607571167547674220694890046109918083","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12870963503793994252748021877782156491"},{"id":"O_mPyOeV","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:21:33.193Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.36916173454816630234875479090637449276","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.17708148953434851415851342150005242991","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.99172595312453395296173731727989894110"},{"id":"O_0pVLZm","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:21:34.433Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.61}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.78138345567551331375863929654443334848","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11647784734801856809545255056084992379","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.86435952904648247127882437667663352128"},{"id":"O_9VaG40","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:21:35.499Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.41200263667241022083875947569958980780","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.78911702714334138822970011398512335890","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13280242629707455639344486109075303948"},{"id":"O_oaQGeD","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:21:37.266Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11773918497924383372809670281850948456","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.94609889432250375394243297456625745159","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10035620995571013736286889432578287923"},{"id":"O_xa3rB5","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:21:45.145Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.68}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.67909901986578040727665369056691831086","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.60064237712673937613803968016242114521","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.82566890486248729946120932388659984544"},{"id":"O_pJaNKd","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:21:53.091Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.14}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.54309862546585469543030534212950422623","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11560779665845190507469539193284559073","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.99088069627723740591708982414305104446"},{"id":"O_3XvL4v","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:21:55.685Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.41483166791978703437715489424106550670","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.29970146773460337023921243175454946765","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.51225950616283162435192976909324722172"},{"id":"O_bYzJva","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:21:59.987Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.70505145367538448555686417003156009634","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.62674142447266952965842952416485492288","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.62081184896492595565514457435229782876"},{"id":"O_LdyXgD","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:01.039Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.39340451976240637202960314896410800275","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.92650766924873543769488596742654965555","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11225304723011366791263021553227868416"},{"id":"O_aABzL3","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:04.681Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.59}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.15282440823915878381439116676632844170","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.21620034909738866984925751821741030967","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.95044138422265622392676759839269330232"},{"id":"O_WJMXVa","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:05.775Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.92657579092748421733842501129710447394","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.85820442973225514022774193940026641595","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.61994480809188971826187803457683426047"},{"id":"O_BbmroO","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:14.925Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85439115945317252300894604134539210565","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10643103383721631236012228272116849895","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10720656396883542664282945100539210297"},{"id":"O_J1KXJW","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:17.666Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.42627959525372378721271680528626254001","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.58032456939844289963813511875589615573","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11763991846443266597226766300901446046"},{"id":"O_42vLgD","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:18.495Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.57}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12750154983505919567183133232955813145","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.23998772185024743106870312937755730364","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.29846883635547328450299461727754667749"},{"id":"O_rR3BKW","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:23.251Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.33}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80015468386742411039386774584013239602","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.75870904864794372102005493189123317121","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.24603948838154878496423549500106249664"},{"id":"O_56VLZN","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:25.827Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.94803626687748563316729544469829538627","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.80308223162259747723235257160370456638","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.58823145992677040551386688064748195704"},{"id":"O_GR1MYe","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:26.842Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.57}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.47855166296268275879490378125960810885","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.91078642773231635125822726015020728603","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.70198601852329668548364681141164326191"},{"id":"O_NRyXrz","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:27.664Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11456879303459206608832549852332230190","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.59455036310188473236373851980883646485","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.74248597298411250040804242763606144543"},{"id":"O_J1KXJ4","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:33.476Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.70621526990377671804197754672847151804","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12481233033840686510791745134756441193","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.23299444752717848920307111806971083596"},{"id":"O_ZBVXmq","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:37.069Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.65}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79977422225994750876734853132215061729","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12487610066167307490089629992334792927","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11639615735609627089461391936995438500"},{"id":"O_rR3BKX","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:37.954Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.69}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80155946051432180280432788779471390107","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.24831016819653828397237869604641986929","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.96521237568637764713221278016286343102"},{"id":"O_AKXZL5","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:38.832Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.13}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12582078274025731767580496703780743428","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11510358117381869520255596727578916243","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12232542793561602312054851932346665452"},{"id":"O_2K3LJV","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:41.158Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.45060944219719548494779896173706450544","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96018277860392303670292216827070241442","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.93677324576507034965820142947312465383"},{"id":"O_jydjKQ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:41.837Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.05}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11062485326477291448433879045062400279","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.92978742473388448299840892598912130864","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12628487666479006705372203844265340320"},{"id":"O_ergZjx","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:44.008Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.62}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.46344264026054168569743333813934274874","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11024801004558142522947524684785318971","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.76925035049219034471429745961218125834"},{"id":"O_RyGXry","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:45.682Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.22}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.77182873577987901019018090957261680871","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.54211880547369354003933836517414823831","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.45273620162363076586604938424410629033"},{"id":"O_yM2A0K","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:46.877Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.28}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.15150430857597740595536077016420918547","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.63152654349803198070327823398082156276","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12405758653161425969984744897426591720"},{"id":"O_dx0gjr","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:47.867Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16313857558454667463133964724696178927","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.48587698345068581479543000712233183798","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.31951024789924929027323932545302231630"},{"id":"O_mPyOjy","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:50.743Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48236253062819492404000057686746909186","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.38345114449409158137538700863261852704","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.23918507458686082883120072098415705057"},{"id":"O_0pVLNX","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:51.938Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.4}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12625952318616532285718402740396562652","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10873663067222292461383780950097096626","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.46993442427688321461241766381238289097"},{"id":"O_1mOLYr","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:57.126Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.04}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.47455675870506572037385367594616312791","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.41287610928081607833505609788059574405","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11843071172529441575998579870570821368"},{"id":"O_lgXeLK","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:57.955Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.56}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.59540195178117941120463002665457446145","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.92429137818191758079510310563785831439","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.42342413390885622878443678270236720484"},{"id":"O_xa3rQQ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:58.865Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.57430668419465349382839910390771885021","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.50815584088880378840344665803710454937","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.94090120150179000457089413172559865955"},{"id":"O_vDrg0J","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:22:59.473Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.58}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.78177363689246304930178481367475554698","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.74285174169202816414602019882916833047","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10830543476126918044546753843686059330"},{"id":"O_VLzXpK","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:23:04.027Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.31017938691854123763396482052997034208","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10551579300555225037501702412643457443","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.42499155998229495474073430114657189029"},{"id":"O_3XvLzL","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:23:04.673Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.8}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.69031829872322877264662584562762620007","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.53633959305313843956684171710907804114","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.41456815297058061788354021055930890160"},{"id":"O_DdDqZy","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:23:07.383Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.62}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11696917568762103250757219495090823342","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.41641732783260329211847080423791278669","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13268722434372072873888888028049182747"},{"id":"O_LdyXBa","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:23:09.787Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85731099173337779340205781144285712458","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.78419376771227090377282097724559062851","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.63940739229021856396046765271132066482"},{"id":"O_X3pXVY","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:23:12.286Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60973471538762133249252076597767309025","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10561566844940358603808660363762335825","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.55187042146636756615899749021592548445"},{"id":"O_WJMX91","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:23:14.168Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.88}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99189512140408006328067029114688185968","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.55131915528268941099207484844035701881","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13292916203253468276363089407454801829"},{"id":"O_56VL4N","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:23:16.555Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.48}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21077073708822822348812286181224530090","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.93772345193800840166966498375145754848","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.21912785216714575495394868544297317719"},{"id":"O_Bbmr4B","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:23:30.804Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.43844792424860654229442870194089245662","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.78473133492331547377884919976096188139","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.40137320735658902088433505379175043537"},{"id":"O_gYgAeb","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:23:38.791Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10958627897673706070870737485859672877","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.74389630491429496139895114309886920357","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12793016215145518368718624876188650802"},{"id":"O_AKXZJ5","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:23:43.626Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.13}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.35349772926744211187085939072079717266","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.56841349630654275268816672847092626184","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13158537229160464340720455399512448602"},{"id":"O_qd2Y0w","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:23:44.501Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.57329632545929703173546548759157259700","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.74815886619818740028095617638031182524","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.68104251000833816361739720745002790631"},{"id":"O_jydjMQ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:23:49.123Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.64}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.83898146086830430713466638547430782845","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.79512195059778297050257338734897262077","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.81995237786394885413298490363269080103"},{"id":"O_RyGXqy","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:23:53.831Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10315647149032083981199914334786991292","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.85748516159400244002296492537548716880","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11853795439605995682067224948663787422"},{"id":"O_dx0gNr","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:23:56.174Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.49}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.49509138243574502976078459277600261505","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.50893400323234796686818190158845285698","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.40729905621689337984963354394015648258"},{"id":"O_6vPLVp","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:23:57.059Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91597983735914917784584633185215281608","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.60066919758733179133232720823985192982","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10968750734063619763794825904727421436"},{"id":"O_mPyOAy","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:23:57.804Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.45}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.68891812297434884178212253788631066262","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.24793158439859336950860968588993915593","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.62151446974528798792101744489615247885"},{"id":"O_oaQG2p","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:02.423Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.11}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.37375369150606343695569958067070922694","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11473837722002509457212391094015531858","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10225962537707348948964111611638066067"},{"id":"O_vDrgJJ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:08.041Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13044809795271970793340086572814832722","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.80702698289192155675981445196935248843","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.76843356138289844843356484124384822864"},{"id":"O_QR5XAB","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:09.060Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.43}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10966581693714712669534733200018471810","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12701228773551919665676861494236940785","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.86143265599641899155986637388904716263"},{"id":"O_3XvL0L","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:13.165Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48335791833673069860663659950116667950","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.20558061401796637274484489041589955072","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10733152008147403422921275639197695829"},{"id":"O_ka4MZ9","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:14.080Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.62}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13227939759564927628044221843025711405","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.44335128956519309100675234804360831589","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.90732069738821046572483289204617807512"},{"id":"O_DdDqRy","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:14.979Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60458395479499293020484724939933268985","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.27659282246259483442822113866607755733","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.69610709995166417454382691214291987819"},{"id":"O_bYzJ5e","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:15.931Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.72359723206252261845865896876069421428","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.24843402922860138554920605371814832924","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.35718230368928389099638276327144044782"},{"id":"O_GR1MGe","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:26.542Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.66}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60217599219722995398584787186854183542","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.52361979169152689911652138449104791441","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.17971548982150830408305156844555312619"},{"id":"O_BbmrRB","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:30.705Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99618481906705347793339135324369699955","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.51192670202269253595486141586499563699","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.41603707864511002575496729392709186513"},{"id":"O_zDjqrK","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:31.908Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.52}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13848424590808186389209893894535032334","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.61745799900340893657275453684268850419","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12220087993218450344711289738605729977"},{"id":"O_J1KXB4","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:32.705Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.16}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.40269496293450163028799044053001588273","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.19852681269170567480041684641491496366","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.51162462525483381582798929890509225924"},{"id":"O_gYgAzb","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:35.462Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.26752142779010153231279566757804215818","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13681840001638269682826805745656685108","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.20620499097822506983999699269753500120"},{"id":"O_rR3BNX","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:38.267Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.82190439179095202267530336192168171372","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.77223803931474573234708619306836180409","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.30045325544913991994815981264716970471"},{"id":"O_56VLpy","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:40.783Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.7}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.58843044960957391812947426997145342262","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10519157972349799623585053568948572266","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.78658023223904850887976981681435378158"},{"id":"O_Bbmrdx","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:46.153Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.46}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.47119556147001825556697340862207501959","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.18654059708748495592214310055851713671","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11343783162439455066785397909525102477"},{"id":"O_J1KXO1","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:48.976Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.56}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48624566651425917347917399177034224625","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10042863998159336967617341844087230802","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.63747679025556914039126911786019900416"},{"id":"O_42vLzx","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:49.853Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.58}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.33614736126311682781603512887995571610","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.19309347956319041617527795339912370396","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.15452121595735757813972912115877224201"},{"id":"O_rR3Bl3","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:53.998Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.51}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.32246029550851696616913808071735432216","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.85321550177973603412511076812716309193","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.22019508871193445127701034488328342753"},{"id":"O_qd2Yl3","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:55.701Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.05}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12838385612691482873960836573390505424","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.76482406332245819587746522971686720484","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12360965664062046101732694856863309602"},{"id":"O_2K3LYR","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:56.523Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.57}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75778206960646534112056227180557442730","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.67927360650992865917880401637803461363","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.14431320740928221458916347282150392231"},{"id":"O_jydj0W","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:24:57.725Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.73}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25572854715632835018700797290915589961","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.92016837703962933123207857304613903889","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.36166222867084535553743245142822158533"},{"id":"O_yM2All","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:25:08.462Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.76035003944380435988758274649536174092","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12392436702610642117748706892430965880","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.72322680864606958121186173031865049988"},{"id":"O_dx0gWX","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:25:09.258Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.19}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.89821765897402300490745754301228424687","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11983094553420985112594470954371884360","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.57624041721076364968752258796051888437"},{"id":"O_oaQGlZ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:25:18.033Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.41}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13199872161148361503228139669112249354","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13090511924216036462720283284079578626","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10818123632775013192066835241281796516"},{"id":"O_xa3rlp","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:25:22.228Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12036075705803389539875450775032967597","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.61145994344097038458173280695807785169","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27195147325568806890439182886434313259"},{"id":"O_VLzXZN","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:25:27.227Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11371588824163972596643800663171839380","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.45951976640972641200477816486252123234","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.35085602331317385828661236583664469037"},{"id":"O_3XvLBk","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:25:28.658Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.4}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12016107447110874469054144786046676902","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.41961027439669814449667525909264078994","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10634064730700484146797829449402697716"},{"id":"O_WJMXrA","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:25:42.177Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13887917546117893627654317330508186740","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.72174276217351031456960522357463455063","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.54851262914603591987404049854967425071"},{"id":"O_BbmrZx","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:25:52.896Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.1}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10129485293993846070584903741834910022","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11316805028056702063471602312397145086","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10482913764117826111072531138380435775"},{"id":"O_zDjq3p","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:25:53.739Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.65}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99375125889509739000255453445355707578","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.70194503571635759064405410360502173197","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.44510912861097272188126021640988947071"},{"id":"O_gYgAdP","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:01.744Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.52}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85799969157725544735090344356311053788","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.18163049717741214154879715647975742873","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.95135628234365340467163047009193949098"},{"id":"O_ZBVXd3","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:02.640Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.57}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.20508908524138476106071513366101327791","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.48016876102974305491983847796501100642","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.76379826561337185067991568439321686538"},{"id":"O_OL0Xv4","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:27.948Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.18012466865260079508523947265688938829","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.75367460095982667606162533001883404134","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.61977091077738881081252025669406127010"},{"id":"O_yM2Aal","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:30.437Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13131398542776092224286088214089817997","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.84110984140151589889528457892197603393","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12380356583388527081461919571021247711"},{"id":"O_dx0gXX","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:31.537Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12317724954927402561013144593003960934","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11924517470016139145191589469135932599","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.36787230164364650912329846161767060579"},{"id":"O_mPyO1O","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:34.151Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71980503003038303566110922658657015622","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.34350439283403446426018607087490842658","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.75787175809612322789532651435075602999"},{"id":"O_0pVLbY","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:35.090Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73977060266344579565534962764715522631","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.88450808368964385605856463954181072925","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.82015165100918073417411382448536105691"},{"id":"O_KxoXv1","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:38.032Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.64999748592463808603272227663341624851","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.49696249423213507457925698070105570489","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.36792128377315871443330797276814542064"},{"id":"O_oaQGxZ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:38.765Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.53}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11998085386354885581113322343440184457","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.17128682287646498576161643493631499491","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12696090866933343582777762903691321154"},{"id":"O_lgXe10","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:41.224Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.68}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10708327633990641329598159285063740721","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.27893992788855417856328167897052759559","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.28726682022719194901566312319826345362"},{"id":"O_xa3r1p","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:42.059Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.15399992324189392253036457447811994741","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.29672287698695917299804587145498112305","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.70611268880345321799278047621351704860"},{"id":"O_QR5Xvk","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:44.602Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.68}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.63867794326687759769976949300183271135","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10696118893155584929015924103288419147","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.85367024312688325537143600390178185748"},{"id":"O_pJaN1z","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:45.782Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.66}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.44656752610731358698401307053489020971","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.17277600964019284918570110281685746661","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.65843478392953887827895640207068653743"},{"id":"O_VLzXvN","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:46.864Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.54}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.92866408024505903755158085388315933265","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11123169676271348563850381194956780893","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.29709204954855295035286582259611327259"},{"id":"O_3XvLbk","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:47.523Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.58}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21816129098022674726002765296771481656","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.32029132620991642431169604415860028262","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.87961592234283235470180352098373903227"},{"id":"O_ka4M1X","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:48.921Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85256139166896878057873194342438509375","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13082635635946250238295616105715281990","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.51145658206066775474338150794318893696"},{"id":"O_DdDqAJ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:49.792Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.31}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71857024290319877004765559302285850875","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.82143746401988762830180736819684501066","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13122017680121271123240572869112063343"},{"id":"O_bYzJoG","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:50.469Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.8}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.66552103834543398623260130454288369564","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.16479179510542439841952168708095688369","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.64929578593637061384442877480368244161"},{"id":"O_LdyXvZ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:51.424Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.62}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11135062509982139033722073268687429401","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11073310562827980008705383215782154194","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.39420112939115840843272486080640648194"},{"id":"O_w6aZ1J","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:52.240Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12393523103905000406305547155493372826","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.23263182853373600046028227895682520659","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.91281333973427971296846863999784095940"},{"id":"O_X3pXab","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:52.965Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.14238834685528243427551869594414323154","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.87536582607913867238829603876761913076","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.87759481927176979153816177086442782426"},{"id":"O_GR1MjP","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:26:59.774Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.51}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.62609378187177386044343929558354641423","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12079268707035787113839664882696312967","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13157548824213571213070193958861770751"},{"id":"O_NRyXvY","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:00.647Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.45}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.97166254503678497985697723887044072179","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12604056698163519107600004881767659284","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.17180619594881258373836845503094814405"},{"id":"O_YLOXdJ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:01.442Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10485917432429788472580042580580580010","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.15956124641511698605024823290286880992","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10310304111922051392344359109797960791"},{"id":"O_zDjqPp","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:03.792Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.41}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13608681572837388841852726222845347807","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11811363354311528662683458962419526368","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.73437119198176528074851421730684780287"},{"id":"O_gYgA4P","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:08.063Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73181279240584602293891079622155400884","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.78458602802265623515811943291894690291","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.87607385324530557994711815306986801636"},{"id":"O_ZBVXw3","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:09.168Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.34209168570004256029544604981275712252","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25808904010208205860905478860867615105","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.87182599833740405971591367488788392723"},{"id":"O_rR3Bx3","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:10.355Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10253267382268765671345526238253521443","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11961208145678533338865103205318257593","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.45012300215363936083019859261260025525"},{"id":"O_AKXZ3N","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:11.275Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.72304885611206761666650332079059263792","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.53662365697922361421749966276592445257","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.95366215923977662347781114967200368035"},{"id":"O_56VLXx","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:12.025Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.29}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10038057009899620100439590139502832481","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.85013066353573870935728663186603076400","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11758533523652448521970003804796707690"},{"id":"O_GR1Mp5","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:12.719Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.84474223029753391381336896453319306066","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.49332347847380582165716601509019216931","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11874546409437933634246154707166541799"},{"id":"O_BbmrXo","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:16.525Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.36743768588217888218325958515254087142","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.28239210117880280337970681927861950109","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.54090160943383986972715050775639972515"},{"id":"O_J1KXLB","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:19.051Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.65}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13032923775098935974325286058204178304","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12563955527982764354885037010611724567","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.54770434256653158681161971588045686303"},{"id":"O_42vL3z","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:20.430Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.40790757849688405239694915002630208292","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.37732559974878000679359932676809940938","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10454445965393075053843806530969937618"},{"id":"O_gYgA4d","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:21.084Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.22}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13724246864315224052812927542186848941","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.32580303838979007839698745366788248102","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.41572951576287103565942148136712661521"},{"id":"O_ZBVXww","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:22.100Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.25}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.53554350010870854136629850303645841959","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.47018998702284333951239855175259039337","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.81773446419371813965106750131817474220"},{"id":"O_ergZze","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:31.049Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.57567968135683618687351498772927393130","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.76154802083752523232365640930201297138","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.23726856850597723904893647782283276819"},{"id":"O_yM2Axe","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:35.081Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.56590224054631827659371714020672077503","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.43473824225538594133800479888288920263","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.71161135431269875363538317608087322258"},{"id":"O_dx0gB6","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:36.322Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.51}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.17235423704436097551033150571011641368","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.23225069536503796982206842498169401102","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.85469216103945434090645102023260076992"},{"id":"O_6vPLQw","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:37.599Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80708824757928886775690614782304881714","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.65121464076265183663118238154307257376","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10097441553921183391365632797529595953"},{"id":"O_mPyO2J","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:38.423Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.63}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93620857167467296013973886667895641763","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.90518752331127029385961496118224866060","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.32950945268228554615354402716562181242"},{"id":"O_0pVLd2","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:39.177Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10649123533840364698238464433715469078","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.19692546765301079445229202553157559988","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.33681747785625876835507909744129428460"},{"id":"O_9VaGL1","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:39.887Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.7}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.72318042413542606250114036192448862563","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.76723755729885860004159291928833845298","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.55837313073240307515765055796456973627"},{"id":"O_KxoXkA","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:40.722Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.56}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79116045241778631337851084138825655456","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.30248939330814204575923658425549701186","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10138960580852846459549326905198724421"},{"id":"O_1mOLaJ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:43.284Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.38}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12995850359694827080453463369559331557","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11912325621000755281238529497288173468","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.23314091891902902181742431522974722154"},{"id":"O_lgXeqb","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:44.189Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.25}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25613212691580359756890914532753630818","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.65089640380470659329383787677107409691","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.81967818507078668470140981098020519692"},{"id":"O_xa3rxz","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:45.035Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.51659476997821693666730480646184150730","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10605804308367732784455402589130240319","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13322622031542092421115546772084065306"},{"id":"O_QR5XKe","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:47.660Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.68}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11164625109303416757661899254162144137","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.66251603309948465002166563150117893127","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.67572359123152474559482246676024190393"},{"id":"O_VLzXKl","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:53.272Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.13}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85261187800780141322768582217787299774","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69702535886703969681725221079395605030","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.34443545307031758498784214941157838926"},{"id":"O_3XvLyR","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:54.262Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.31}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10483780139520388432767085374994267319","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69687943965820396675693562431974474377","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.42480579918815113950865412325069977818"},{"id":"O_bYzJJq","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:27:57.972Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.27923801890829673594303099819797465748","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.97064736470971301070130722981121685172","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.41290954188742564941808974768317330795"},{"id":"O_w6aZZD","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:00.504Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.4}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.49718226519486957013804228040520217700","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11088908166672740030529241106506330815","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.53098776399954336457614796192995031889"},{"id":"O_X3pXXW","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:01.426Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.94775066503971484677609666694146987407","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.54103607543800888549433145758668238725","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.24038468635566136088374971877204077360"},{"id":"O_56VLLx","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:11.466Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21132361706015758770437397882646041526","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12827887963092779134007346379554849742","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.55613857247278945661276878240058412502"},{"id":"O_NRyXXM","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:13.939Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.89635633611188763143443269322395463597","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.73440973263245182554152826703281614241","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.14983916526131099797515169236276713550"},{"id":"O_YLOXXy","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:14.892Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12772141535050570738466705205446727453","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11579994920526146358856021916602770017","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.23072826594896101067612595486527952387"},{"id":"O_Bbmrro","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:15.831Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.17173546323937767365117126310911196186","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.80967421523909533809431059523119939796","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11569181802943667928318783776165638348"},{"id":"O_zDjqqa","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:16.631Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.11}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.35477962850842611325700055089911936925","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.49813095176153471774602535368712292090","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.18343091092019153199034769849998622075"},{"id":"O_42vLLz","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:18.863Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.39}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11198832828331639461919093925236014885","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10309458601242480829559208682849675650","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12381138628765222718787396636287657551"},{"id":"O_gYgAAd","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:19.803Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.70784585704842865168097484838235520254","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10259500859058821975259891827661554217","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.53311446969491157431140755095899581018"},{"id":"O_rR3BBB","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:22.026Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.79}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75477508361854394690726148299659792201","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.70749245233141947914705971090364732849","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.22163814129620290968985467912781990758"},{"id":"O_AKXZZV","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:23.427Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.94830495021084799903389062871168331615","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.65890932040180961997039870991662056948","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.21207053008475359773425475080684720172"},{"id":"O_2K3LLr","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:25.324Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.04}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.95141296038681961810341191108604131230","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.44663603908702294794924360799494303526","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.66143756183238932866480951512050350356"},{"id":"O_MQdXXw","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:27.650Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.29949963209101918695616385450393584350","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.75540768840813365868581976786520917946","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.78271346363801001739036492086903619451"},{"id":"O_ergZZe","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:28.365Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.47921467984941546304647325624027641826","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.31469136352460657553721802819993841250","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12083041417284035868842324951230383918"},{"id":"O_RyGXXx","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:30.307Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.67}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.42213976358922013178414277787367086723","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13343862824097317214821816225229810641","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.74843543522489039207978344131266512484"},{"id":"O_dx0gg6","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:32.955Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.49283050650370045696542560227429084866","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.34061654164171464742419850105869421182","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.73593583224706175032341655439787943948"},{"id":"O_mPyOOJ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:35.421Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.38696918948180699134767380212796372554","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.17733489087471838205891871814345426963","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.62005405689358971057196490786572604774"},{"id":"O_0pVLL2","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:36.747Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.58}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.62495532585226910407315348000002810409","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11405886264456712263267303831611135208","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.18273109306781570944429620783280443629"},{"id":"O_9VaGG1","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:37.648Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60418824225914808230042331250041780756","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.68135825560838137216316961994762111739","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.35090967103745446342394970312024721290"},{"id":"O_KxoXXA","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:38.546Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11930344697933749852196158376251264209","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.40134412497179592258282775065994764643","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10065118652515481682658127710444115798"},{"id":"O_lgXeeb","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:42.449Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.51}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11146032129881577011874756003168729450","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12660792675524625126211545371291540509","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11412171199778829830383949447760128880"},{"id":"O_QR5XXe","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:46.221Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.43807116044199121438931937341837226666","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.41935419380524176144969283365686235558","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11755857314882904159741369051343719608"},{"id":"O_pJaNNL","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:47.239Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11439761491260138375427916273108390534","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.43883584524449180395184523696733397254","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13529043887569324260544715492965666784"},{"id":"O_ka4MMW","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:50.666Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.57}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.52815459225726718410102259687208386159","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.79385275981967082128430519947393282685","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11062755275214594140901322385343962888"},{"id":"O_bYzJMq","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:53.285Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.42}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11024116241144701260606273216410359420","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.24357947863121378124502292348283106892","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.34313937514122315106940415523074146274"},{"id":"O_LdyXbd","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:54.189Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.59}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.81808136859620043073448891701148743203","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.86160100009480498305938741133154460615","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10701002683519008420297027419192593541"},{"id":"O_w6aZQD","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:54.923Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.53463294955894998327785993824375788640","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.34406499298674216768745190154041849847","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.35152277098566360248629787699903085195"},{"id":"O_X3pXzW","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:55.793Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.51}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16634533869968662316916023519915825664","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11738470482527309210323862653414508250","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13060249074177146195246328710120828815"},{"id":"O_aABzj4","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:56.686Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.55}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.23096728411934483288052896587301039585","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.87173278435362297525973752778545223145","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.44835750530161981811004352832463260425"},{"id":"O_PLdXVP","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:28:59.369Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.48}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12201135627267172124930298373299468322","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.92024662793101574644925375465795683445","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.22321421111970421941007867026837419965"},{"id":"O_56VLgx","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:00.673Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.51}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11499688846838445938719370622798986147","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.61798572269511051029404247884859966140","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.78201281481754589335875078899366874105"},{"id":"O_Bbmr3o","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:07.278Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.27731524556596512314958263895458255078","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12352213128971319555362552824723529338","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12584769809379617695290038567040451179"},{"id":"O_42vL4z","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:10.833Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.61226597695477970385263918743277113520","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10652528049526411300224590052357893345","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.19202580003235956126389459243786164398"},{"id":"O_gYgAmd","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:11.606Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.32029308943673693281458379486508103186","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10624010412425635613624867409311031134","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.90623612470435094834707799003235320065"},{"id":"O_ZBVX4w","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:12.397Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.33}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.17998633499199966097100826204557645252","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96354302192485360800106062396531926213","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.73288936971700673745186688387135619566"},{"id":"O_rR3BmB","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:13.690Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.5}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.68532479715136923151798323246554586024","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.50293057033730232428343647555266266367","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.91722724309200196618746423358301951092"},{"id":"O_56VLgB","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:16.091Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.77272656307938248798960033178921854484","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.30797785655493486007346824463382923867","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13300383713004155861975602274132300977"},{"id":"O_zDjqGo","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:22.372Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.29}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.45729633253372074463525706160521519912","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.58356498941006840433833987277130000280","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.37707355233319179691385523473951620670"},{"id":"O_J1KXbm","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:23.260Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.11}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11209160392598761547660031266151602973","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12306733110323885941555727811855049152","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.39848689288735978485208579088413865926"},{"id":"O_42vL4l","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:24.248Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.14}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48335674810817558371588816282729034633","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13079349471314452561825640640307276509","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.38074058899288742914822748112579678066"},{"id":"O_rR3BmA","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:31.980Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.28325218614026062309405249972608731665","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.33756188444097826604058436440065342151","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.97742517099492086940378558347225764825"},{"id":"O_AKXZVv","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:32.742Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.04}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91441827783598865420337615221799403565","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10102882891967657723518706090549504979","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.76332607221416451798435505106287195438"},{"id":"O_qd2Ymy","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:33.579Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79633379515969915028297840138476891738","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69750544737923530726785673384605313666","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.59104713991738647829843995257643385888"},{"id":"O_2K3Lzy","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:34.277Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12842779612931633380636708157194840581","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.54274864198027187586523501131054764232","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.43137220035209005736945468487298192662"},{"id":"O_OL0XVG","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:38.473Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.51060347547454219628821978895140686447","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.63219634327258645487686988278041997504","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.14229191023553343677980075087352217061"},{"id":"O_dx0gOo","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:42.295Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.41}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.31060202731175039991227548165329478684","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.63643751364085432783394238980767737507","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12509084345702942437665854873022380045"},{"id":"O_mPyOm3","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:44.733Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.44}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10883199542847308192684203089176494263","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12134485255065264322671158840913354018","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.98424505819453461279990923244251509312"},{"id":"O_0pVLYr","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:45.963Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.16}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.22139771314029498055177920517164045395","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.15650537427257624767172743156579670819","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.48209363894952809521008182700669567012"},{"id":"O_9VaGg2","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:46.787Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.52}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80822167935657771451481208176509564321","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.87812830794542978928180777490562205922","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.89124482199464685015361454139755580072"},{"id":"O_KxoXJy","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:47.521Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.29}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10534436658757997525104024176930298873","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.74993440061750532029535130420056287152","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.46115606911518525615710558688063589293"},{"id":"O_1mOL53","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:49.833Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.70378448052022113805084699086050912245","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.80978109479538233272559562055776016301","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.45416376575720809560437969274163515968"},{"id":"O_lgXeyx","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:50.476Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.7}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12924077579550617491456328336599316853","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25661974517214006202901337899203830529","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.17011494904764660024784500769462959320"},{"id":"O_xa3r9N","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:51.292Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.61}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11022711610487845302396300293289900291","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.83438218446753310621291393317929484668","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.19290564432788130491658475567644525930"},{"id":"O_vDrgpr","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:52.125Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.69540398944457244073015123988486143041","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.28215154050451491207513505927502488450","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11803761922731279016903173025094280410"},{"id":"O_QR5Xqr","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:29:53.390Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.48}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.96322445598853397273434599662359793736","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10237858298717097915104207182782506829","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.65508301432378637709916986488270306275"},{"id":"O_bYzJZx","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:00.979Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.8}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.35042857868068387620588284736083754265","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.68260599420568164638256509461995229952","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.16359251071773613545833306800194538990"},{"id":"O_w6aZ9l","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:03.274Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10544259713393837462153269167511008844","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.68780038099429798355701695358557432717","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.20804836044082541051085537043389550497"},{"id":"O_aABzgG","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:05.922Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.11}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.36270850915012667676354399931321669825","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.64395797654026900253320922759682799038","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.30663987746305133071752409283504676277"},{"id":"O_PLdXAV","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:08.427Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.59}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.69955327875037516626102821996107076828","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13499664746755324363497801274695631904","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.64447836327983511756744116073385372131"},{"id":"O_NRyXZa","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:12.020Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48424830583356042442416691172975554279","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13137992315329075389079396436122794973","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.68585471736981921375588500388473527033"},{"id":"O_BbmrOz","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:14.501Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.45}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.22677699159307365544525703118737850694","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.66850143364220691211155989624936861492","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.26202070357902526244172340068063752019"},{"id":"O_42vLYl","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:18.323Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.63743700654110698203689222987028310037","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.87172207030180643925485033782861632984","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11996071167351057677048462005020548764"},{"id":"O_ZBVXGJ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:21.119Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.68}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73208816940382883298440187310249101132","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.94530656310511830875881294121799471727","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10586692126566344898276783741843289539"},{"id":"O_rR3B9A","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:22.327Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.4}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.28150756080657506706653545700573111477","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.52121531999758638504547385227680477950","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11257428228754220459773854754368549819"},{"id":"O_AKXZev","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:23.132Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.29}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.17767224618901415451826948918657543600","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.32291974719435298566941163359909386726","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.65002981735005776646476452514081610167"},{"id":"O_jydjOz","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:26.575Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.61472730345073680647764752684177347672","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11259258472240945032260905530699735217","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.40387039149206721088572817685111981990"},{"id":"O_ergZqb","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:29.070Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.1}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.45777581710265094863325785436109398806","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11481941955717458426864959210465458833","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.25298716253882768121396398173937503873"},{"id":"O_OL0XrG","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:30.230Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.65}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.69461858205065238824388758720236487526","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11868880799223294419996822805940582217","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.25269135349101729666425506776537346001"},{"id":"O_RyGX2J","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:31.135Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.13}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.62246056757523244010527833617607879958","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12213341728971908417484577462493022061","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.74593686079059177817687874051873304329"},{"id":"O_dx0gAo","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:34.040Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.67572093718496224437744143586010111656","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.37299313044170485825284641473304132298","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12303167887047796953486678379153232640"},{"id":"O_0pVLlr","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:38.156Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.53}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.35937907949315185643094584517153804423","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.40250305451812828003684621790506493864","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.85337732019147054904891467542898135415"},{"id":"O_9VaGO2","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:38.862Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11786388650169906050772291337998113311","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.95027246702842550498749999655223799604","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.64508102913962545722051432610699585640"},{"id":"O_oaQGva","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:41.268Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91393075321743891449774151850709139926","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11219921475645243715590631355082240630","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.70081048755592574753686018469188120037"},{"id":"O_lgXekx","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:44.128Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25092884639081531600991192743207808547","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10639828375757999657121336190019477219","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11516670911330829333335020129357738083"},{"id":"O_QR5X9r","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:48.302Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.88360110909134076418081578591735176905","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11698019311657287679766257501956959107","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.68826407217382112106941553150505489356"},{"id":"O_pJaNv6","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:30:49.176Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.61}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25180033451217749014235488150218481532","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.88028069636899261855276154356233074822","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.86625937822461559723174215483256201337"},{"id":"O_X3pXJa","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:03.228Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.56}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.19293628404212733929487994700938328697","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10362648968239169587196695985889205303","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.38548075077794905996025364941981697107"},{"id":"O_aABzMG","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:04.131Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.38}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.82821123123239416143914175106842401302","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.72976516928774950452226797197522754624","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.93207574495064899818539323387605713318"},{"id":"O_WJMXzX","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:04.906Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10241974035497383778236307758830459858","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.55223733586838452107207121109700218804","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.47814819303778684322562370060439150245"},{"id":"O_GR1M99","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:08.258Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.04}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.64573690754216079413239404098526993895","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11435970163928351707767363101512646327","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.67254516799221884308969092314001227865"},{"id":"O_YLOX4G","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:11.301Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.66}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.43061088137138130978940764893065682357","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.32604876911326057324738512058415305445","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11397812590119852889232981752453518253"},{"id":"O_zDjqvo","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:13.255Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.63}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.69218935080405138479177348916426445065","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10148078817203611862973793692747540215","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.32049238121221073408065600755527265290"},{"id":"O_J1KX9m","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:14.322Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.55}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11258181130803258031610899883779890137","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.92728586449670695955148426901152953015","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.75191202799227236650850441705822695728"},{"id":"O_42vLql","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:14.933Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.8}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.47848519885454752636636136321291135726","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.99566124680609037050266333182883305205","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.76243880674578059196180426487959250920"},{"id":"O_rR3BvA","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:18.770Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.24}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.84510830332684400920480989934288923818","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10916113068363149327324705772176222032","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.54177408500391555264123495484716397175"},{"id":"O_AKXZbv","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:19.475Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.15}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21377393803912004299767384556111210118","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.40227164220373264309748725101777922647","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.65006178126019409645052794678210714897"},{"id":"O_NRyXKA","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:22.862Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.61053347298051210392723292408301449888","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.72168456049800570299311838390001976339","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.40332559152932009972086112317158239468"},{"id":"O_YLOX4D","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:23.665Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.34}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11190554787234919848127325239478519590","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13051649239386021572433567716174478315","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.40734290647574210127467682995997571389"},{"id":"O_BbmrD9","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:24.350Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.57}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73499689281329871763891175698407901358","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.59465577047863550321295865850188542459","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.45924689632195800455280948410419454291"},{"id":"O_zDjqv4","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:25.526Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.53}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12501659463346781411565544872537352542","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69845706403749419999190259419326032142","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.22402927494784179102406278301589931667"},{"id":"O_gYgAvx","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:29.626Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.3}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.36909409723083164884354282321728714608","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10380321523553392596431620033694556467","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.63728467061618197067803710966625819397"},{"id":"O_ZBVXPp","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:30.326Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.47}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.89896977788078633073887999299912054415","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.82702914673969478775572658299794761297","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.41942560518627028950379724617226710684"},{"id":"O_rR3Bvw","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:31.228Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.13}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.51444001104172723111320535593532668813","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.74451189606123266636470604469299955480","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.65084750490938478418198810573347036593"},{"id":"O_jydjBy","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:35.761Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.45451611943227069981803998658376897828","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.87685833713015462514938511115856745138","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27219663387902719705489255774350377355"},{"id":"O_OL0Xao","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:39.984Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.64}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.53676121044312473589633621837141335897","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.46276453279894427694069928159013657347","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.98196469741392894167333203682671149245"},{"id":"O_yM2AyN","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:42.380Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13073808697947823704076585576666261018","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.55266822514585942734815030234228074211","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.45828355207997703963694326153029362594"},{"id":"O_dx0gda","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:43.301Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.38996554826330969516727430277563624014","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.63970226221802595249844893084381986534","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.18329262361336006490753138091009887814"},{"id":"O_6vPLRG","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:44.001Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.31950744889524914630847592969529106228","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10521998562902537788867905198448268868","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13345169650833297445348939308880640236"},{"id":"O_0pVLqZ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:45.959Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.43}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.67293636725396449819725250528284599308","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.89591082753645368612605362695318087408","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.66754313262998168570351321430658922795"},{"id":"O_9VaG6v","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:46.856Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.69}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.55754641250799848100173390579222641290","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.94870729456516491587425935431410424928","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10684846390436031697619559681652181825"},{"id":"O_oaQGZ2","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:49.745Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10380451206963549167998467773572372270","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.99265525037805492786558240955129703699","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.14300701419255455588705790141483215996"},{"id":"O_1mOL2N","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:50.938Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.66}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25518211441212413548832599748597054061","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10074157873222695557113046118057603371","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.66293993201858668652365536375522289571"},{"id":"O_xa3rRx","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:53.474Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.22}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.95249478162832051359951354286981414237","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.71435458542342763957868655083198966078","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.87430377333185634715922381180713211522"},{"id":"O_vDrgeg","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:54.422Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.57}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11042310934490422669951531073579519747","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13823082291343621520369844802065623487","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.57248651359415252915443809744714337512"},{"id":"O_QR5XGP","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:55.228Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.68729838521474752319883842581152968497","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.62769631339005549461815520722538144541","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.28141806438045551963359353854091664609"},{"id":"O_pJaNr9","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:56.334Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.52}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.43257965466364586478888814270216801906","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.43948797018742579574502779576582507353","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11419296253430805035085489053863836316"},{"id":"O_VLzXJB","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:56.861Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.15}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.35139208759902972997867024561775138192","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.50337930604968122959727288758018893749","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.22474258862013963761107430994817350063"},{"id":"O_3XvLMM","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:57.641Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.89552706312202289981386450209680481409","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.49676480790490606633018898521858946053","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.14399473300271801515201267482238279715"},{"id":"O_ka4Mzy","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:58.351Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.7}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13381763471511125427238165640409276148","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.50177439915165027949523542326168282656","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.18968149197374271012278881088317218579"},{"id":"O_DdDqaP","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:31:59.260Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.81}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.41108827357129066448069836688814745138","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12086705988784393734804992556379946748","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.82895471179603126414682231789788761480"},{"id":"O_bYzJRl","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:00.122Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.62}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10918627205006898155228010708615417303","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10353124095928265776524767520126226628","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.19687185264116712140637273050240983151"},{"id":"O_X3pXgZ","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:03.955Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.4}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12742625635308835425963945418314320982","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10784738996676818072878841250205054613","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.47690156024631378406578941858789683385"},{"id":"O_aABzO2","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:04.656Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12174001136204335508243949223895578144","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12935121766695086086361464355351967515","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.63064563573495515969240896186866244491"},{"id":"O_YLOXZD","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:13.226Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.2}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99074584825847668977343463788476974017","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.53713066097351644873605149772981154410","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11351158690012528001359187536901001570"},{"id":"O_zDjqd4","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:15.230Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.66914839255851806328299801504801314539","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10460800178924176971354390626720388295","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.23029804350737550127432067109825955549"},{"id":"O_42vLeo","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:17.534Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.27986411246177431706317268818010455644","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11027848514431717980632085888194801036","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.84503997688572204495437871461842658527"},{"id":"O_ZBVXrp","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:19.961Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.68}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99195844209740668960811965530575588271","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.91356396118757010098706373291088133005","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.96215735520048019766263781393779797267"},{"id":"O_AKXZaG","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:22.625Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.15478465558763747779169117542697291118","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96382507090891535287533011679573810664","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.28456242957330496644177930703620414898"},{"id":"O_2K3LDA","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:24.879Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.37}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.24413770758904814760630925262275074575","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.78056365338776198294009955357894423353","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.25543840007576675957023433408145725135"},{"id":"O_MQdXwL","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:27.188Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.36867564389966200976019338256058728063","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.73749015836749576582028727875507718880","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.89547753266738290393964457753546185960"},{"id":"O_OL0Xwo","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:29.532Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.51}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11528224972962056302516197690283133911","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10188523587240702891702440165833434601","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12481986647808462973513751202323526938"},{"id":"O_dx0gqa","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:33.767Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.3}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.72061259167073845280042884801716069871","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11009040757367668343964787578768948442","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.66556966951865315111423962009914585555"},{"id":"O_6vPLDG","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:35.335Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.5}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.74516002979519783554459948133834803127","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11810998307185889292097736388662752628","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10348175113692767283444426318768160710"},{"id":"O_mPyO6p","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:36.206Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.41}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10398825632721518723603573243822827484","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12737051568471333026488289604698126834","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.23272505407312507185841375245347531501"},{"id":"O_1mOLDN","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:45.991Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.15}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.47708833900117803673317214896256966181","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.50651039273181038157224443275535886749","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12455344096353755015561673621249481338"},{"id":"O_lgXed1","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:46.658Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12816264874592401301145180682829136710","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.67901723922505523174631963547213151707","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.69710993320325529806279380483172615014"},{"id":"O_vDrg4g","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:48.884Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.45}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10966350621361719674419401232868468976","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10928265974398795393376574356312754066","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.65835175893777324687536450520316684138"},{"id":"O_pJaNG9","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:51.525Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.71}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.17540654720542571431329334343244725837","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.72950504524884423006757057764041698496","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12697385036895501417099892816927341335"},{"id":"O_VLzXwB","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:52.320Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.16}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.77054032051247923780421869179745133341","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12373704725218725978672531376107238958","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.80078070728600341870461390752717215965"},{"id":"O_3XvLDM","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:53.331Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.43}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10714171265004313225560843062551891314","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.58679527922693107050454969069254730307","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.58280213321197192648340889696910573348"},{"id":"O_ka4Myy","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:54.115Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71471560959936642538886021420364143524","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.94146888760930953394108938195572706382","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.86972466455692679435771183711361577838"},{"id":"O_DdDqwP","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:55.103Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.45}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13197066619753113574214041437054126744","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69081182458298917334115479360746131137","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.19482379942572759343113249214729491775"},{"id":"O_bYzJrl","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:55.975Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.49}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.30789883245513372263968277346818032715","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.88056066611446978935352430649824087315","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.71038977090351552937379611425723373367"},{"id":"O_w6aZgj","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:32:58.497Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.35457347809309112681151756893784876864","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.44025931498797332813158498795908867829","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.72545178443870359202881089955933887683"},{"id":"O_56VLa0","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:33:05.161Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.44613500617949028028622641188187135667","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.77194119050073719657019489936986504665","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.82359699750971372448604891667858062438"},{"id":"O_GR1Mw4","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:33:06.025Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.46}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11441334862203587623269481636775921811","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.55625068681624106183158477815630888547","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.45446554479230485555683492560939982029"},{"id":"O_zDjqA4","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:33:11.061Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.53649670044097743657462222943449045050","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.23062237443621085537870887451174876269","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11766538530980582514711109694194968814"},{"id":"O_gYgAMx","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:33:15.542Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.71}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21122097897037871212268548493481795098","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.59648289093459476986380487745801259543","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11489311058324989099844546091072912795"},{"id":"O_AKXZwG","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:33:19.119Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.29}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.84881872790365372014697313198434622105","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.80114124014650471677617474798983756350","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.73671417308886073789308028889553638285"},{"id":"O_56VLej","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:33:20.130Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21400074599115935478325250996032379085","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.76315355689415193687433490344740450796","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.25424499907745106143735241226460049171"},{"id":"O_GR1Mrg","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:33:20.827Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.56}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.62163571585421150798010542117356325599","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.41246814479297417569316857521166116105","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.63258006418563728382114558473631893596"},{"id":"O_YLOXB6","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:33:22.959Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.58}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.61634065904844993081715040290549683596","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10646258012818079130538797387142378379","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.22053765702714875688747057311033955055"},{"id":"O_Bbmrzv","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:33:23.866Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.45854826044894941695514203309029096377","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.50487860328775944605475567379338760672","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.57285049325468708407842565827936893790"},{"id":"O_42vLMd","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:33:27.894Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.7}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10272793534235736165649396393422157082","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.20741311217902393833873574461912775832","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11777104613359942233289702796877202241"},{"id":"O_ZBVXzR","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:33:30.495Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.50888400392275373093277884701345946123","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.85182424981142509986706092023652044222","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.16879384016721838427313765692880049924"},{"id":"O_rR3Bza","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:33:31.722Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.59}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.82214954943758538057111149152499879438","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11471522846456573325606002380195435135","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11433261556438177509318981568794997170"},{"id":"O_AKXZB6","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:33:32.347Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.8}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.29991169787512407345281725247974847063","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.20196603840841907816456567399811937139","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.30391854284244064991020531384453422572"},{"id":"O_qd2YBK","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:33:33.103Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.13}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10246889707373953103179618615720757770","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25091305844238660404608667251770327255","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11839707767721804463230196277186697642"},{"id":"O_2K3L2B","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:33:33.955Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.57}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73999916250634006466650586299120451581","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.26133292136821192840775444479898511507","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.24729952917045509786673063867947903934"},{"id":"O_OL0XRK","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:33:39.233Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.42}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12890413566198563811777878086483053426","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11802055295020592994086922159408848092","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27055438575004170602528082753389666291"},{"id":"O_RyGX6X","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:33:39.846Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.6}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.69327337018147384667885990327165515369","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.51416802145885990475651608764225493096","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11619078558763687578254320217075467426"},{"id":"O_yM2Aq5","modelId":496,"modelVersionId":831,"modelTaskId":1610,"type":"ANNOTATION","createdAt":"2023-08-21T04:33:40.701Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.34712358766091473204382913223352482740","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.51100607246253661974775200693624464120","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.61779766242274976794883398198376693132"},{"id":"O_AKXZ15","modelId":496,"modelVersionId":887,"modelTaskId":1654,"type":"ANNOTATION","createdAt":"2023-09-05T05:41:09.832Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.49}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93303890736000372712007719325496086506","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.18933131084705356884804381455040439979","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10246470900314949112774779858606715675"},{"id":"O_qd2Ybw","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:42:45.821Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.49}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93303890736000372712007719325496086506","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.18933131084705356884804381455040439979","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10246470900314949112774779858606715675"},{"id":"O_2K3LqV","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:42:47.344Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12672963102145562289556730996924191933","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11490451502697619568913745270109712744","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.98524239922985237506822834835772680167"},{"id":"O_jydjvQ","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:42:48.789Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.26}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13225278160855776395459576364479610926","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10096646229606210096083716017760432173","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.45868000707182667687966934029758973194"},{"id":"O_MQdXGK","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:42:50.649Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.15}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.41584070234430372173765420238622114497","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.31826698412661834262339279169645209451","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.15781680202415329471961514022336248042"},{"id":"O_ergZDx","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:42:52.053Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.9}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60417888430254618877950024443204458533","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69047852066263357259921465594099063561","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.20922878054271870966514899514445780327"},{"id":"O_OL0Xje","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:42:53.588Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.67}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.34474459139031442853950131741108777705","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11054813231011644849954786938460768772","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.51664194736578964583365212788765505610"},{"id":"O_RyGXOy","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:42:55.080Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99043702482538143920588129740411594274","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.41296222598996201764137126287695545351","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27368894922558052521136085756674613278"},{"id":"O_yM2AOK","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:42:56.590Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.38}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.37086773353446284773343305804355244033","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25504309998170432288325714639898139564","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.85498951216142733027403015634981447711"},{"id":"O_dx0gkr","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:42:58.091Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.68}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85863003054521018766410592665108460266","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.33353809230574917955127457223438803138","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.82491352139116858893948745915794673159"},{"id":"O_6vPLlp","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:00.159Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80391050361565627485212451571511025696","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.50818690366043584412449896049120052893","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.14245365400130544363943976862759981972"},{"id":"O_mPyOzy","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:01.381Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.33}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.62118485175692420624795168534752720704","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.92535670121750964997127013584522641352","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.43675707932226204557614276481808065118"},{"id":"O_0pVLmX","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:03.686Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21002115141957150748930841566364555389","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.36071423266211373286935864717520233130","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.99121928847891260729185171760356813608"},{"id":"O_9VaGQp","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:05.255Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.11}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16200791959753000368045520417827643884","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.43805520248639652974150105177454656607","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10938257119716116504763784338743476385"},{"id":"O_KxoXrB","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:06.853Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.92}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11966720494012221530810110357385190394","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.37674556826305313919134814226868085489","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11393809490237521859180218293619593731"},{"id":"O_oaQGPp","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:08.813Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.84}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.88194215698435731274339148094525478530","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.90420738963877449569630462422677876482","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11535277798648419691039880832660825724"},{"id":"O_1mOL0r","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:10.209Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79354614957179736401305033596760950615","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96993045450219906823069392214070547160","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.72911556529236123897149045055705600678"},{"id":"O_lgXeBK","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:11.489Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.91}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13174698018038694457989063228112812057","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.80167156419858945241544136779618781195","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.83693387504209685519843226597037641407"},{"id":"O_xa3reQ","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:13.050Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.3}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.83839371612285027689003767776763048874","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.23371623908036063691186464287385623757","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.73673904472681674416881067950208762932"},{"id":"O_vDrgjJ","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:14.994Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.19}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.31239740291001233741518144994772499937","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.87176998758634448044544074239265966551","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10080915976742060510467597104574525029"},{"id":"O_QR5XeB","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:16.466Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.84}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.58800234986092969914664533385227251763","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12107791240269769285031008746359707083","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.94505907225716746667228616929116530847"},{"id":"O_pJaNg1","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:18.014Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.25}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11742590162883175875313569897624549552","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.75366979216310481072510256303631173633","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.15920889430824388281261828228438821995"},{"id":"O_VLzX6K","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:19.599Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.93}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10452841293564474734596795955051241595","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.64084061604094120653895727153609840018","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13142206345544355701721261741547213782"},{"id":"O_3XvLKL","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:21.171Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.81}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.14601225381216912562015187533504378930","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.71215887896814391983359601432246088018","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.22531274325370344844655522842850992018"},{"id":"O_ka4MY9","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:22.811Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.58}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.66714858276602326840716030031701387403","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25787584734607648992846677997225654240","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27828248411309324213682653629163636974"},{"id":"O_DdDqYy","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:24.404Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71818230964448383520869831871740477137","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.82361768772950537728395568849043085858","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10265027780464709418481729507830875317"},{"id":"O_bYzJVe","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:26.116Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.13}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75745691882473550404320701186704369619","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.59014790384606378070085323496289392716","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.28219548975553795025985411050189332134"},{"id":"O_LdyXAa","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:27.992Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.64}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.81723814540481517155985033223263347681","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.58233199964239845938296376506133264789","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11085120079835306365391562000259141695"},{"id":"O_w6aZMg","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:29.603Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.85}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.27082736737155301713931176384015269927","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10860201126926665433580896573363442243","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.81806739807882296432081966127449913219"},{"id":"O_X3pX0Y","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:31.185Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.93}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11246358655889974431100828608162118475","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.91489889384464651956915195105586804452","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11882794108790840046371840696667858615"},{"id":"O_aABzpl","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:33.887Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.22218224902210395057541058899085307466","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.95243867697103445238216031505700734838","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.98122999398331283914494520137442724726"},{"id":"O_WJMXm1","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:35.399Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.21}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71853771447159478340450787452774678194","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13186421011895497478954122190364415328","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10017867533548153747532497999753535032"},{"id":"O_PLdXMk","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:36.920Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.16}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16315487813988430812442513983202308536","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11474507952560515988794477890383486515","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.88970940169374082821043033183053165553"},{"id":"O_56VL1N","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:38.377Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10309035611505216862280722450541246232","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.16213998524616414013702809656675880276","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.50544220449549978956833983792017581668"},{"id":"O_GR1MJe","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:40.522Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.81204283658079390355658813400263341728","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25176115537973378934460994435321616545","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.76678324666203475756220706198643496226"},{"id":"O_NRyX2z","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:42.112Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.50522631466416528481899180495083771271","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.42385918989460517329468248272105082301","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.94704476797772187673353028789294518981"},{"id":"O_YLOX90","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:43.496Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.34}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25715243805698149204333256440870824269","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13212213007959308019464859229508333156","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.88831760903045414620144157465468172241"},{"id":"O_BbmrGB","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:44.909Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.12}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93526380671520015887492535929546289983","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10005721767304978718480772202941307873","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.31228993792611252157157850013794577388"},{"id":"O_zDjqRK","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:46.310Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.33}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75741878950758353908459159312119136057","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.52486265608257543978440319061999116036","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.55575346266251085039046951292303623667"},{"id":"O_J1KXZ4","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:47.757Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93133103931352051484402456972107766631","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10824053040590274406004252038314270760","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.53488417959807852077074815287977103573"},{"id":"O_42vLoZ","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:49.406Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11813670086153723206338479337175832552","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.19448540300943212103790837127528957485","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.21944557927725907440899936097843561265"},{"id":"O_gYgALb","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:50.992Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.84}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11698655628810989540571060069864032034","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.97669330179071615862903963475056029477","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13298340086429837306155052152328799541"},{"id":"O_ZBVXKq","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:52.410Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.3}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12871879578819679719891901907662686672","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12657148488992834772578677746864215026","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.23381370939846181007853412412272540647"},{"id":"O_rR3BrX","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:54.186Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.33}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16540020943180754370807150979085512375","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.24204921505048320465935139628168161374","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10312210881795264256469006137882633042"},{"id":"O_AKXZ55","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:55.690Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.83250421635148946013153519487765464663","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12968836314273245640067990758755075610","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.95190610383006262926006802762620160598"},{"id":"O_56VL1y","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:57.317Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.05}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10580530640190979687559814849138075292","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.33953834155850580445103913518867312694","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.91745256668337329458596436099891180469"},{"id":"O_GR1MJP","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:43:58.915Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.19}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79050063903915736280252381017111391036","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.59678276848040851224759355011403206500","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.79111654385317924723837090669238940962"},{"id":"O_NRyX2Y","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:00.729Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.91}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73888411782440722561759697580614855237","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.98204450747876117024804960884542660990","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12293403773195911843592382511702039775"},{"id":"O_YLOX9J","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:02.315Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.04}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.42930129259682883548149018732626607715","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.86631893393554574180761603609010258877","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11743366893897588685865573913454870435"},{"id":"O_Bbmrpx","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:04.331Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.59}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12118847365011015605577712214572748362","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.77728863974209631696222971513121379029","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.52992034446854865578542841618408723227"},{"id":"O_zDjqgp","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:06.312Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.89}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91308826690545525860536682324342833963","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.29039333521885472159126513151084009870","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12735379275548833107390561285864827065"},{"id":"O_J1KX51","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:08.428Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80644694338549900893329622765508569613","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12788228873601239619796127903668763309","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.71716263199124676229159869929158875557"},{"id":"O_42vLPx","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:10.095Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.15759500103559442402170040073604275389","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.72586423663378593077643116249468820298","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11083885680040837201836943833099377862"},{"id":"O_gYgAxP","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:11.704Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.37481052888009201018744280876499747199","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96876074358067414504721273285702630272","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.82145141848899269885251546758736024106"},{"id":"O_ZBVXe3","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:13.711Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.14}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.64822063358332988570658054393010790703","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.30610375315508762889093026154499822526","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.40079301320894456412018365670485244716"},{"id":"O_rR3B53","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:15.198Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.27}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.54813256783534721433738579210618545553","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.39674660399893628916072993056960804687","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27544197238006600533326101135182607622"},{"id":"O_AKXZQN","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:16.809Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.29807737968305150942312177305644885461","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.29097391730926934051949708983048977904","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11679973001512875320227789007313688739"},{"id":"O_qd2Yw3","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:18.472Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.83}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13804204137716402403051597553324660220","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.72112013191909574272550789892506252726","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.26229398495758888643104039387809388278"},{"id":"O_2K3LeR","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:20.017Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12908146249849039920696415050027251666","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10661897929718065158486387010660138735","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.58776135274242633369950600750547980022"},{"id":"O_jydjpW","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:21.721Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.25}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.40344696294075300150160062065838404588","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.74081199494998751148122642849211336715","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.67265802380419311547634205841088794736"},{"id":"O_MQdXYx","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:23.010Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.81}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.18451356275334181906363016167640641404","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.34059071045204310029405237880515168365","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12350461038454527639815577279110964583"},{"id":"O_ergZ1M","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:24.526Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.76866431241353372048397727730980991944","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.89068859028686738606250960097109556160","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.22647559013018053834720695087777100905"},{"id":"O_OL0Xz4","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:25.977Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.04}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25162057972473772604388654527530699966","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10812733082985064837902997994614511715","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.80922014075969895930494329681174351244"},{"id":"O_RyGXgq","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:28.039Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.15}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79429684175445665349654548365684962300","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.89285989936669975575370285779211657350","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.52616383798646697772684725581381883719"},{"id":"O_yM2A4l","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:30.321Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.79}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48786793299166551538312254431695656485","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69657075748860896083813103940156853933","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.31381953373007667698017879180314152742"},{"id":"O_dx0goX","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:32.006Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12511642292284168409350105164084473905","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11160240470202434592122247090643647067","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.47034531066281080749915443657307786118"},{"id":"O_6vPLdQ","modelId":496,"modelVersionId":887,"modelTaskId":1655,"type":"ANNOTATION","createdAt":"2023-09-05T05:44:34.014Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.37}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.64359000099559658156498587464389062687","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.79144505378977886598368584444379708741","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.43260344447559082999522992855844744194"},{"id":"O_mPyOkO","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:25.575Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.49}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93303890736000372712007719325496086506","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.18933131084705356884804381455040439979","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10246470900314949112774779858606715675"},{"id":"O_0pVLjY","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:27.208Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12672963102145562289556730996924191933","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11490451502697619568913745270109712744","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.98524239922985237506822834835772680167"},{"id":"O_9VaG0g","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:28.732Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.26}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13225278160855776395459576364479610926","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10096646229606210096083716017760432173","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.45868000707182667687966934029758973194"},{"id":"O_KxoXG1","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:30.607Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.15}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.41584070234430372173765420238622114497","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.31826698412661834262339279169645209451","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.15781680202415329471961514022336248042"},{"id":"O_oaQGbZ","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:32.006Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.9}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60417888430254618877950024443204458533","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69047852066263357259921465594099063561","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.20922878054271870966514899514445780327"},{"id":"O_1mOLMD","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:33.675Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.67}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.34474459139031442853950131741108777705","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11054813231011644849954786938460768772","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.51664194736578964583365212788765505610"},{"id":"O_lgXe30","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:35.237Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99043702482538143920588129740411594274","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.41296222598996201764137126287695545351","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27368894922558052521136085756674613278"},{"id":"O_xa3rJp","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:36.823Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.38}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.37086773353446284773343305804355244033","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25504309998170432288325714639898139564","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.85498951216142733027403015634981447711"},{"id":"O_vDrgBw","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:38.312Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.68}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85863003054521018766410592665108460266","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.33353809230574917955127457223438803138","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.82491352139116858893948745915794673159"},{"id":"O_QR5X4k","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:41.601Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80391050361565627485212451571511025696","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.50818690366043584412449896049120052893","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.14245365400130544363943976862759981972"},{"id":"O_pJaNLz","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:42.994Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.33}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.62118485175692420624795168534752720704","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.92535670121750964997127013584522641352","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.43675707932226204557614276481808065118"},{"id":"O_VLzXqN","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:45.656Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21002115141957150748930841566364555389","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.36071423266211373286935864717520233130","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.99121928847891260729185171760356813608"},{"id":"O_3XvLOk","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:47.100Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.11}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16200791959753000368045520417827643884","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.43805520248639652974150105177454656607","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10938257119716116504763784338743476385"},{"id":"O_ka4MVX","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:48.626Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.92}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11966720494012221530810110357385190394","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.37674556826305313919134814226868085489","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11393809490237521859180218293619593731"},{"id":"O_DdDq3J","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:50.830Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.84}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.88194215698435731274339148094525478530","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.90420738963877449569630462422677876482","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11535277798648419691039880832660825724"},{"id":"O_bYzJPG","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:52.301Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79354614957179736401305033596760950615","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96993045450219906823069392214070547160","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.72911556529236123897149045055705600678"},{"id":"O_LdyXNZ","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:53.525Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.91}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13174698018038694457989063228112812057","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.80167156419858945241544136779618781195","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.83693387504209685519843226597037641407"},{"id":"O_w6aZzJ","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:54.903Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.3}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.83839371612285027689003767776763048874","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.23371623908036063691186464287385623757","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.73673904472681674416881067950208762932"},{"id":"O_X3pXjb","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:57.004Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.19}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.31239740291001233741518144994772499937","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.87176998758634448044544074239265966551","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10080915976742060510467597104574525029"},{"id":"O_aABz0y","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:37:58.337Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.84}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.58800234986092969914664533385227251763","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12107791240269769285031008746359707083","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.94505907225716746667228616929116530847"},{"id":"O_WJMX2A","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:00.030Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.25}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11742590162883175875313569897624549552","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.75366979216310481072510256303631173633","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.15920889430824388281261828228438821995"},{"id":"O_PLdXJM","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:01.629Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.93}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10452841293564474734596795955051241595","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.64084061604094120653895727153609840018","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13142206345544355701721261741547213782"},{"id":"O_56VLyy","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:03.406Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.81}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.14601225381216912562015187533504378930","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.71215887896814391983359601432246088018","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.22531274325370344844655522842850992018"},{"id":"O_GR1MbP","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:04.927Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.58}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.66714858276602326840716030031701387403","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25787584734607648992846677997225654240","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27828248411309324213682653629163636974"},{"id":"O_NRyXBY","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:06.341Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71818230964448383520869831871740477137","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.82361768772950537728395568849043085858","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10265027780464709418481729507830875317"},{"id":"O_YLOXMJ","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:07.606Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.13}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75745691882473550404320701186704369619","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.59014790384606378070085323496289392716","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.28219548975553795025985411050189332134"},{"id":"O_Bbmrgx","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:09.520Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.64}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.81723814540481517155985033223263347681","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.58233199964239845938296376506133264789","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11085120079835306365391562000259141695"},{"id":"O_zDjq0p","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:10.930Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.85}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.27082736737155301713931176384015269927","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10860201126926665433580896573363442243","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.81806739807882296432081966127449913219"},{"id":"O_J1KXe1","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:12.339Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.93}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11246358655889974431100828608162118475","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.91489889384464651956915195105586804452","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11882794108790840046371840696667858615"},{"id":"O_42vLkx","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:15.260Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.22218224902210395057541058899085307466","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.95243867697103445238216031505700734838","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.98122999398331283914494520137442724726"},{"id":"O_gYgABP","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:16.629Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.21}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71853771447159478340450787452774678194","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13186421011895497478954122190364415328","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10017867533548153747532497999753535032"},{"id":"O_ZBVXp3","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:18.106Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.16}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16315487813988430812442513983202308536","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11474507952560515988794477890383486515","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.88970940169374082821043033183053165553"},{"id":"O_rR3BM3","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:19.539Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10309035611505216862280722450541246232","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.16213998524616414013702809656675880276","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.50544220449549978956833983792017581668"},{"id":"O_AKXZ4N","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:21.771Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.81204283658079390355658813400263341728","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25176115537973378934460994435321616545","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.76678324666203475756220706198643496226"},{"id":"O_qd2Yj3","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:23.322Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.50522631466416528481899180495083771271","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.42385918989460517329468248272105082301","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.94704476797772187673353028789294518981"},{"id":"O_2K3LVR","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:24.641Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.34}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25715243805698149204333256440870824269","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13212213007959308019464859229508333156","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.88831760903045414620144157465468172241"},{"id":"O_jydj4W","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:25.953Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.12}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93526380671520015887492535929546289983","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10005721767304978718480772202941307873","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.31228993792611252157157850013794577388"},{"id":"O_MQdXyx","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:27.318Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.33}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75741878950758353908459159312119136057","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.52486265608257543978440319061999116036","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.55575346266251085039046951292303623667"},{"id":"O_ergZNM","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:28.703Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93133103931352051484402456972107766631","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10824053040590274406004252038314270760","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.53488417959807852077074815287977103573"},{"id":"O_OL0X64","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:30.155Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11813670086153723206338479337175832552","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.19448540300943212103790837127528957485","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.21944557927725907440899936097843561265"},{"id":"O_RyGX9q","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:31.751Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.84}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11698655628810989540571060069864032034","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.97669330179071615862903963475056029477","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13298340086429837306155052152328799541"},{"id":"O_yM2Aml","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:33.286Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.3}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12871879578819679719891901907662686672","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12657148488992834772578677746864215026","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.23381370939846181007853412412272540647"},{"id":"O_dx0gGX","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:34.854Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.33}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16540020943180754370807150979085512375","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.24204921505048320465935139628168161374","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10312210881795264256469006137882633042"},{"id":"O_6vPLbQ","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:36.090Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.83250421635148946013153519487765464663","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12968836314273245640067990758755075610","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.95190610383006262926006802762620160598"},{"id":"O_mPyOrO","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:37.690Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.05}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10580530640190979687559814849138075292","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.33953834155850580445103913518867312694","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.91745256668337329458596436099891180469"},{"id":"O_0pVLQY","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:39.240Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.19}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79050063903915736280252381017111391036","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.59678276848040851224759355011403206500","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.79111654385317924723837090669238940962"},{"id":"O_9VaGXg","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:41.023Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.91}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73888411782440722561759697580614855237","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.98204450747876117024804960884542660990","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12293403773195911843592382511702039775"},{"id":"O_KxoXO1","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:42.611Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.04}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.42930129259682883548149018732626607715","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.86631893393554574180761603609010258877","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11743366893897588685865573913454870435"},{"id":"O_oaQGqZ","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:44.532Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.59}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12118847365011015605577712214572748362","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.77728863974209631696222971513121379029","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.52992034446854865578542841618408723227"},{"id":"O_1mOLpD","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:46.416Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.89}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91308826690545525860536682324342833963","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.29039333521885472159126513151084009870","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12735379275548833107390561285864827065"},{"id":"O_lgXeZ0","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:48.258Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80644694338549900893329622765508569613","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12788228873601239619796127903668763309","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.71716263199124676229159869929158875557"},{"id":"O_xa3r6p","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:49.855Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.15759500103559442402170040073604275389","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.72586423663378593077643116249468820298","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11083885680040837201836943833099377862"},{"id":"O_vDrgyw","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:51.254Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.37481052888009201018744280876499747199","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96876074358067414504721273285702630272","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.82145141848899269885251546758736024106"},{"id":"O_QR5X0k","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:53.429Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.14}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.64822063358332988570658054393010790703","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.30610375315508762889093026154499822526","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.40079301320894456412018365670485244716"},{"id":"O_pJaN2z","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:55.262Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.27}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.54813256783534721433738579210618545553","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.39674660399893628916072993056960804687","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27544197238006600533326101135182607622"},{"id":"O_VLzXlN","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:56.837Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.29807737968305150942312177305644885461","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.29097391730926934051949708983048977904","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11679973001512875320227789007313688739"},{"id":"O_3XvL3k","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:58.344Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.83}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13804204137716402403051597553324660220","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.72112013191909574272550789892506252726","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.26229398495758888643104039387809388278"},{"id":"O_ka4MgX","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:38:59.750Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12908146249849039920696415050027251666","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10661897929718065158486387010660138735","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.58776135274242633369950600750547980022"},{"id":"O_DdDqrJ","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:39:01.509Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.25}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.40344696294075300150160062065838404588","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.74081199494998751148122642849211336715","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.67265802380419311547634205841088794736"},{"id":"O_bYzJXG","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:39:02.947Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.81}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.18451356275334181906363016167640641404","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.34059071045204310029405237880515168365","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12350461038454527639815577279110964583"},{"id":"O_LdyXRZ","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:39:04.334Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.76866431241353372048397727730980991944","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.89068859028686738606250960097109556160","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.22647559013018053834720695087777100905"},{"id":"O_w6aZdJ","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:39:05.634Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.04}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25162057972473772604388654527530699966","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10812733082985064837902997994614511715","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.80922014075969895930494329681174351244"},{"id":"O_X3pXvb","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:39:07.446Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.15}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79429684175445665349654548365684962300","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.89285989936669975575370285779211657350","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.52616383798646697772684725581381883719"},{"id":"O_aABzwy","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:39:09.659Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.79}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48786793299166551538312254431695656485","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69657075748860896083813103940156853933","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.31381953373007667698017879180314152742"},{"id":"O_WJMXxA","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:39:11.245Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12511642292284168409350105164084473905","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11160240470202434592122247090643647067","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.47034531066281080749915443657307786118"},{"id":"O_PLdXmM","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:39:13.236Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.37}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.64359000099559658156498587464389062687","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.79144505378977886598368584444379708741","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.43260344447559082999522992855844744194"},{"id":"O_56VLDy","modelId":496,"modelVersionId":888,"modelTaskId":1656,"type":"ANNOTATION","createdAt":"2023-09-05T06:39:14.504Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.74}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25131591387333975145518022057168554543","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13276465698620724043087635931978008476","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12733663945463671304358997194184623832"},{"id":"O_GR1MPP","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:17.450Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.49}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93303890736000372712007719325496086506","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.18933131084705356884804381455040439979","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10246470900314949112774779858606715675"},{"id":"O_NRyXdY","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:19.025Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12672963102145562289556730996924191933","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11490451502697619568913745270109712744","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.98524239922985237506822834835772680167"},{"id":"O_YLOXQJ","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:20.675Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.26}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13225278160855776395459576364479610926","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10096646229606210096083716017760432173","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.45868000707182667687966934029758973194"},{"id":"O_BbmrVx","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:22.941Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.15}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.41584070234430372173765420238622114497","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.31826698412661834262339279169645209451","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.15781680202415329471961514022336248042"},{"id":"O_zDjqzp","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:24.444Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.9}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.60417888430254618877950024443204458533","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69047852066263357259921465594099063561","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.20922878054271870966514899514445780327"},{"id":"O_J1KXa1","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:26.167Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.67}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.34474459139031442853950131741108777705","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11054813231011644849954786938460768772","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.51664194736578964583365212788765505610"},{"id":"O_42vLyx","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:27.766Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.99043702482538143920588129740411594274","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.41296222598996201764137126287695545351","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27368894922558052521136085756674613278"},{"id":"O_gYgAlP","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:29.471Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.38}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.37086773353446284773343305804355244033","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25504309998170432288325714639898139564","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.85498951216142733027403015634981447711"},{"id":"O_ZBVXM3","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:31.148Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.68}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.85863003054521018766410592665108460266","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.33353809230574917955127457223438803138","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.82491352139116858893948745915794673159"},{"id":"O_rR3Bw3","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:33.192Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80391050361565627485212451571511025696","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.50818690366043584412449896049120052893","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.14245365400130544363943976862759981972"},{"id":"O_AKXZpN","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:34.749Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.33}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.62118485175692420624795168534752720704","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.92535670121750964997127013584522641352","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.43675707932226204557614276481808065118"},{"id":"O_56VLPx","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:37.077Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.21002115141957150748930841566364555389","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.36071423266211373286935864717520233130","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.99121928847891260729185171760356813608"},{"id":"O_GR1ML5","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:38.645Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.11}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16200791959753000368045520417827643884","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.43805520248639652974150105177454656607","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10938257119716116504763784338743476385"},{"id":"O_NRyXYM","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:40.463Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.92}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11966720494012221530810110357385190394","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.37674556826305313919134814226868085489","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11393809490237521859180218293619593731"},{"id":"O_YLOXjy","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:42.379Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.84}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.88194215698435731274339148094525478530","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.90420738963877449569630462422677876482","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11535277798648419691039880832660825724"},{"id":"O_BbmrVo","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:43.954Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79354614957179736401305033596760950615","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96993045450219906823069392214070547160","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.72911556529236123897149045055705600678"},{"id":"O_zDjqza","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:45.473Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.91}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13174698018038694457989063228112812057","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.80167156419858945241544136779618781195","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.83693387504209685519843226597037641407"},{"id":"O_J1KXaB","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:47.032Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.3}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.83839371612285027689003767776763048874","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.23371623908036063691186464287385623757","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.73673904472681674416881067950208762932"},{"id":"O_42vLyz","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:49.043Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.19}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.31239740291001233741518144994772499937","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.87176998758634448044544074239265966551","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10080915976742060510467597104574525029"},{"id":"O_gYgAld","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:50.674Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.84}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.58800234986092969914664533385227251763","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12107791240269769285031008746359707083","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.94505907225716746667228616929116530847"},{"id":"O_ZBVXMw","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:52.478Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.25}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11742590162883175875313569897624549552","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.75366979216310481072510256303631173633","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.15920889430824388281261828228438821995"},{"id":"O_rR3BwB","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:54.070Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.93}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10452841293564474734596795955051241595","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.64084061604094120653895727153609840018","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13142206345544355701721261741547213782"},{"id":"O_AKXZpV","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:55.753Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.81}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.14601225381216912562015187533504378930","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.71215887896814391983359601432246088018","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.22531274325370344844655522842850992018"},{"id":"O_qd2YL9","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:57.566Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.58}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.66714858276602326840716030031701387403","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25787584734607648992846677997225654240","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27828248411309324213682653629163636974"},{"id":"O_2K3LOr","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:11:59.359Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71818230964448383520869831871740477137","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.82361768772950537728395568849043085858","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10265027780464709418481729507830875317"},{"id":"O_jydjQB","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:00.949Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.13}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75745691882473550404320701186704369619","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.59014790384606378070085323496289392716","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.28219548975553795025985411050189332134"},{"id":"O_MQdXNw","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:02.975Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.64}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.81723814540481517155985033223263347681","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.58233199964239845938296376506133264789","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11085120079835306365391562000259141695"},{"id":"O_ergZoe","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:04.932Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.85}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.27082736737155301713931176384015269927","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10860201126926665433580896573363442243","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.81806739807882296432081966127449913219"},{"id":"O_OL0XBl","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:06.868Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.93}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11246358655889974431100828608162118475","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.91489889384464651956915195105586804452","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11882794108790840046371840696667858615"},{"id":"O_RyGX4x","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:09.916Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.18}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.22218224902210395057541058899085307466","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.95243867697103445238216031505700734838","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.98122999398331283914494520137442724726"},{"id":"O_yM2ABe","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:11.582Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.21}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.71853771447159478340450787452774678194","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13186421011895497478954122190364415328","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10017867533548153747532497999753535032"},{"id":"O_dx0gK6","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:13.475Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.16}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16315487813988430812442513983202308536","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11474507952560515988794477890383486515","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.88970940169374082821043033183053165553"},{"id":"O_6vPL6w","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:15.356Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.03}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10309035611505216862280722450541246232","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.16213998524616414013702809656675880276","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.50544220449549978956833983792017581668"},{"id":"O_mPyO3J","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:17.590Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.32}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.81204283658079390355658813400263341728","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.25176115537973378934460994435321616545","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.76678324666203475756220706198643496226"},{"id":"O_0pVLM2","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:19.284Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.50522631466416528481899180495083771271","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.42385918989460517329468248272105082301","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.94704476797772187673353028789294518981"},{"id":"O_9VaG91","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:20.926Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.34}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25715243805698149204333256440870824269","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13212213007959308019464859229508333156","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.88831760903045414620144157465468172241"},{"id":"O_KxoX5A","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:22.582Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.12}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93526380671520015887492535929546289983","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10005721767304978718480772202941307873","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.31228993792611252157157850013794577388"},{"id":"O_oaQGDr","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:24.038Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.33}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.75741878950758353908459159312119136057","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.52486265608257543978440319061999116036","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.55575346266251085039046951292303623667"},{"id":"O_1mOLeJ","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:25.635Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.08}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.93133103931352051484402456972107766631","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10824053040590274406004252038314270760","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.53488417959807852077074815287977103573"},{"id":"O_lgXeVb","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:27.375Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11813670086153723206338479337175832552","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.19448540300943212103790837127528957485","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.21944557927725907440899936097843561265"},{"id":"O_xa3rYz","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:28.975Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.84}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.11698655628810989540571060069864032034","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.97669330179071615862903963475056029477","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.13298340086429837306155052152328799541"},{"id":"O_vDrgGX","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:31.073Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.3}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12871879578819679719891901907662686672","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12657148488992834772578677746864215026","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.23381370939846181007853412412272540647"},{"id":"O_QR5XJe","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:32.766Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.33}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.16540020943180754370807150979085512375","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.24204921505048320465935139628168161374","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.10312210881795264256469006137882633042"},{"id":"O_pJaNbL","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:34.286Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.83250421635148946013153519487765464663","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12968836314273245640067990758755075610","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.95190610383006262926006802762620160598"},{"id":"O_VLzXAl","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:35.966Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.05}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.10580530640190979687559814849138075292","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.33953834155850580445103913518867312694","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.91745256668337329458596436099891180469"},{"id":"O_3XvLRR","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:37.966Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.19}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79050063903915736280252381017111391036","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.59678276848040851224759355011403206500","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.79111654385317924723837090669238940962"},{"id":"O_ka4MpW","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:39.897Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.91}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.73888411782440722561759697580614855237","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.98204450747876117024804960884542660990","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12293403773195911843592382511702039775"},{"id":"O_DdDq4Q","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:41.651Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.04}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.42930129259682883548149018732626607715","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.86631893393554574180761603609010258877","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11743366893897588685865573913454870435"},{"id":"O_bYzJ9q","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:43.639Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.59}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12118847365011015605577712214572748362","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.77728863974209631696222971513121379029","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.52992034446854865578542841618408723227"},{"id":"O_LdyX0d","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:45.786Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.89}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.91308826690545525860536682324342833963","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.29039333521885472159126513151084009870","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12735379275548833107390561285864827065"},{"id":"O_w6aZ0D","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:48.043Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.36}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.80644694338549900893329622765508569613","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.12788228873601239619796127903668763309","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.71716263199124676229159869929158875557"},{"id":"O_X3pXBW","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:49.870Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.09}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.15759500103559442402170040073604275389","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.72586423663378593077643116249468820298","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11083885680040837201836943833099377862"},{"id":"O_aABzm4","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:51.537Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.06}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.37481052888009201018744280876499747199","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.96876074358067414504721273285702630272","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.82145141848899269885251546758736024106"},{"id":"O_WJMXNM","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:53.862Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.14}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.64822063358332988570658054393010790703","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.30610375315508762889093026154499822526","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.40079301320894456412018365670485244716"},{"id":"O_PLdXQP","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:55.726Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.27}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.54813256783534721433738579210618545553","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.39674660399893628916072993056960804687","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.27544197238006600533326101135182607622"},{"id":"O_56VLdx","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:57.389Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.07}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.29807737968305150942312177305644885461","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.29097391730926934051949708983048977904","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.11679973001512875320227789007313688739"},{"id":"O_GR1M25","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:12:59.195Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.83}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.13804204137716402403051597553324660220","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.72112013191909574272550789892506252726","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.26229398495758888643104039387809388278"},{"id":"O_NRyX1M","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:13:00.800Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.17}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12908146249849039920696415050027251666","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10661897929718065158486387010660138735","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.58776135274242633369950600750547980022"},{"id":"O_YLOXJy","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:13:02.638Z","labelId":"L_8JoaEB","data":null,"note":null,"probability":[{"labelId":"L_8JoaEB","probability":0.25}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.40344696294075300150160062065838404588","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.74081199494998751148122642849211336715","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.67265802380419311547634205841088794736"},{"id":"O_BbmrYo","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:13:04.248Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.81}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.18451356275334181906363016167640641404","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.34059071045204310029405237880515168365","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12350461038454527639815577279110964583"},{"id":"O_zDjqxa","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:13:05.885Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.01}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.76866431241353372048397727730980991944","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.89068859028686738606250960097109556160","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.22647559013018053834720695087777100905"},{"id":"O_J1KXyB","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:13:07.565Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.04}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25162057972473772604388654527530699966","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.10812733082985064837902997994614511715","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.80922014075969895930494329681174351244"},{"id":"O_42vLRz","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:13:09.704Z","labelId":"L_dvM5Al","data":null,"note":null,"probability":[{"labelId":"L_dvM5Al","probability":0.15}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.79429684175445665349654548365684962300","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.89285989936669975575370285779211657350","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.52616383798646697772684725581381883719"},{"id":"O_gYgA3d","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:13:11.876Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.79}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.48786793299166551538312254431695656485","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.69657075748860896083813103940156853933","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.31381953373007667698017879180314152742"},{"id":"O_ZBVXgw","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:13:13.582Z","labelId":"L_Bme34B","data":null,"note":null,"probability":[{"labelId":"L_Bme34B","probability":0.02}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.12511642292284168409350105164084473905","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.11160240470202434592122247090643647067","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.47034531066281080749915443657307786118"},{"id":"O_rR3B2B","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:13:15.786Z","labelId":"L_8eZ2pB","data":null,"note":null,"probability":[{"labelId":"L_8eZ2pB","probability":0.37}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.64359000099559658156498587464389062687","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.79144505378977886598368584444379708741","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.43260344447559082999522992855844744194"},{"id":"O_AKXZGV","modelId":496,"modelVersionId":889,"modelTaskId":1657,"type":"ANNOTATION","createdAt":"2023-09-05T16:13:17.453Z","labelId":"L_84ZJ5l","data":null,"note":null,"probability":[{"labelId":"L_84ZJ5l","probability":0.74}],"StudyInstanceUID":"1.2.826.0.1.3680043.8.498.25131591387333975145518022057168554543","SeriesInstanceUID":"1.2.826.0.1.3680043.8.498.13276465698620724043087635931978008476","SOPInstanceUID":"1.2.826.0.1.3680043.8.498.12733663945463671304358997194184623832"}]}]}